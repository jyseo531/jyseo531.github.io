[
  
  {
    "title": "Graphics-Ch8. Graphics Pipeline",
    "url": "/posts/ch8-Graphics_pipeline/",
    "categories": "Graphics, Study",
    "tags": "Graphics",
    "date": "2025-02-15 12:04:00 +0900",
    





    
    "snippet": "Intro  Graphics Pipeline : objectì—ì„œ ì‹œì‘í•´ì„œ pixelì´ ì—…ë°ì´íŠ¸ë˜ê¸°ê¹Œì§€ì˜ ì¼ë ¨ì˜ operations sequence  object-order rendering = rendering by â€œrasterizationâ€  ê·¸ë˜í”½ìŠ¤ íŒŒì´í”„ë¼ì¸ ê³¼ì •ë“¤ ì¤‘ì—ì„œ â€œvertex processingâ€, â€œRasterizationâ€, â€œF...",
    "content": "Intro  Graphics Pipeline : objectì—ì„œ ì‹œì‘í•´ì„œ pixelì´ ì—…ë°ì´íŠ¸ë˜ê¸°ê¹Œì§€ì˜ ì¼ë ¨ì˜ operations sequence  object-order rendering = rendering by â€œrasterizationâ€  ê·¸ë˜í”½ìŠ¤ íŒŒì´í”„ë¼ì¸ ê³¼ì •ë“¤ ì¤‘ì—ì„œ â€œvertex processingâ€, â€œRasterizationâ€, â€œFragment Processingâ€, â€œBlendingâ€ ì´ë ‡ê²Œ í•µì‹¬ ë„¤ ìŠ¤í…ì— ëŒ€í•´ì„œ ì´ë²ˆ ë‹¨ì›ì— ë‹¤ë£¨ë„ë¡ í•˜ê² ë‹¤          Vertex processing : vertices(ê¼­ì§“ì )ë“¤ì´ ì—°ì‚°ë˜ëŠ” ê³¼ì •      Rasterziation stage : ê·¸ ê¼­ì§“ì ë“¤ì„ ì´ìš©í•œ primitivesê°€ ë³´ë‚´ì ¸ì„œ ì—°ì‚°ë˜ê³ , ê°ê°ì˜ Primitiveë¥¼ fragmentë¡œ ìª¼ê°¬      Fragment processing : ìª¼ê°œì§„ fragmentë“¤ì´ ì—°ì‚°ë˜ëŠ” ê³¼ì •      Blending : ë‹¤ì–‘í•œ Fragmentë“¤ì´ ëŒ€ì‘ë˜ëŠ” í”½ì…€ì— ë”°ë¼ì„œ í˜¼í•©ë¨      1. Rasterization  ê·¸ë˜í”½ìŠ¤ íŒŒì´í”„ë¼ì¸ ì¤‘ ê°€ì¥ í•µì‹¬ì´ ë˜ëŠ” ê³¼ì •  rasterizerëŠ” ë‹¤ìŒì˜ ë‘ ê°€ì§€ ì¼ì„ ìˆ˜í–‰í•¨          í”½ì…€ì„ ìˆœíšŒí•¨, ê° í”½ì…€ì€ primitiveë¡œ ë®ì—¬ìˆìŒ      ê·¸ primitiveë“¤ì„ ë³´ê°„(Interpolate)í•¨      1.1. Line Drawing  ì˜¤ë“  ê·¸ë˜í”½ìŠ¤ íŒ¨í‚¤ì§€ë“¤ì€ line drawingê´€ë ¨ëœ ëª…ë ¹ì„ í¬í•¨í•˜ê³  ìˆìŒ  ì‹œì‘ì  $(x_0, y_0)$ê³¼ ëì  $(x_1, y_1)$ì„ ì—°ê²°í•˜ëŠ” ì§ì„  ê·¸ë¦¬ê¸°  í¬ê²Œ implicit line equationì„ ì´ìš©í•˜ëŠ” ë°©ë²•ê³¼ parametricí•œ line equationì„ ì´ìš©í•˜ëŠ” ë°©ë²•ìœ¼ë¡œ 2ê°€ì§€ ë°©ë²•ì´ ìˆìŒ1.1.1. Implicit Line Equations  Midpoint alogrithm ì´ìš©: ì§ì„ ì˜ ë°©ì •ì‹ $f(x,y)$ê°€ ì´ midpointë³´ë‹¤ ìœ„ì— ìˆëŠ”ì§€ ì•„ë˜ì— ìˆëŠ”ì§€ì— ë”°ë¼ì„œ í”½ì…€ ì„ íƒí•˜ëŠ” ì•Œê³ ë¦¬ì¦˜  ì‹œì‘ì  ëì ì„ ì‡ëŠ” ì§ì„ ì˜ ë°©ì •ì‹ $f(x,y)$ì¼ ë–„, ê¸°ìš¸ê¸° $m = \\frac{y_1 - y_o}{x_1 - x_0}$  ì§ì„  ìœ„ì— ìˆëŠ” ì ë“¤ì— ëŒ€í•´ì„œëŠ” $f(x,y)=0$ì„ ë§Œì¡±í•œë‹¤ëŠ” ì„±ì§ˆ ì´ìš©  $(x, y)$ì—ì„œ ë‹¤ìŒìœ¼ë¡œ ì´ë™í•  í”½ì…€ì˜ í›„ë³´êµ°(ì•„ë˜ ê·¸ë¦¼ì—ì„œ ì£¼í™©ìƒ‰ í”½ì…€ë“¤)ì„ ë‹¤ìŒì˜ ë‘ ê°€ì§€ë¡œ ì„¤ì •í•¨ : $(x+1, y)$ ë˜ëŠ” $(x+1, y+1)$          í‰í–‰í•˜ê²Œ ì˜¤ë¥¸ìª½ í•œ ì¹¸ìœ¼ë¡œ ì›€ì§ì´ê±°ë‚˜, ëŒ€ê°ì„  ë°©í–¥ìœ¼ë¡œ ì´ë™í•˜ëŠ” ê²½ìš°ì˜ ìˆ˜        Midpoint = $(x+1, y+0.5)$  $f$ê°€ midpointë³´ë‹¤ aboveí•œì§€, belowí•œì§€ ë¶„ë¥˜í•˜ëŠ” ë°©ë²•       : $d = f(x+1, y+0.5)$ë¼ê³  í•  ë•Œ,        1. if $d &lt; 0$ì´ë¼ë©´          ëŒ€ê°ì„  ë°©í–¥ìœ¼ë¡œ ì¦‰, $(x+1, y+1)$ ìœ¼ë¡œ í”½ì…€ ê²°ì •       2. else $d &gt; 0$ì´ë¼ë©´,           í‰í–‰í•œ ë°©í–¥ìœ¼ë¡œ ì¦‰, $(x+1)$ ìœ¼ë¡œ í”½ì…€ ê²°ì •1.2. Triangle Rasterization  2D pointsë¡œ 2D ì‚¼ê°í˜• ê·¸ë¦¬ëŠ” ë°©ë²•          Given points $p_0 = (x_0, y_0)$ , $p_1 = (x_1, y_1)$, $p_2 = (x_2, y_2)$ in screen space      ê° ê¼­ì§“ì ì´ color $c_0, c_1, c_2$ë¥¼ ì €ì¥í•˜ê³  ìˆë‹¤ëŠ” ê°€ì •í•˜ì—, ì‚¼ê°í˜• ìœ„ì˜ í•œ ì ì„ $(\\alpha, \\beta, \\gamma)$ê³„ìˆ˜ë¥´ ì´ìš©í•˜ì—¬ í‘œí˜„ ê°€ëŠ¥ ( barycentric ì¢Œí‘œê³„ë¥¼ ì´ìš©):     \\[\\begin{align} c = \\alpha c_0 + \\beta c_1 + \\gamma c_2. \\end{align}\\]          ìœ„ ë°©ë²•ì˜ interpolationì„ â€œGouraud interpolationâ€œ(ê³ ëŸ¬ë“œ ë³´ê°„, ê³ ëŸ¬ë“œ ì‰ë”©ì´ë‘ ì°¨ì´ì  ê³µë¶€í•˜ê¸°)ì´ë¼ê³ ë„ ë¶€ë¦„        line drawingì´ë‘ ì‚¼ê°í˜• rasterizationì˜ ë¯¸ë¬˜í•œ ì°¨ì´ì ì¤‘ì— í•˜ë‚˜ëŠ” vertices and edgesì— ìˆë‹¤.          â€œHole problemâ€: ì¸ì ‘í•œ ì‚¼ê°í˜•ì„ ê·¸ë¦´ ë–„, holeì´ ìƒê¸°ë©´ ì•ˆë¨      â€œOrder problemâ€ : ë§Œì•½ ì¸ì ‘í•œ ì‚¼ê°í˜•ë“¤ì´ ë‹¤ë¥¸ ìƒ‰ìƒì„ ê°–ê³  ìˆë‹¤ë©´ ê·¸ë ¤ì§€ëŠ” ìˆœì„œì— ë”°ë¼ì„œ ì´ë¯¸ì§€ ìƒ‰ìƒì´ ë‹¬ë¼ì§      ì´ ë‘ê°€ì§€ ë¬¸ì œë¥¼ ì™„í™”í•˜ê¸° ìœ„í•´, ì‚¼ê°í˜•ì˜ centerê°€ ì‚¼ê°í˜• ë‚´ë¶€ì— ì¡´ì¬í• ë•Œë§Œ í”½ì…€ì„ ê·¸ë¦¬ëŠ” ì„±ì§ˆì„ ì´ìš©í•¨ (ë‹¹ì—°í•œê±° ì•„ë‹˜?)  ê°™ì€ ë§ë¡œ, barycentric coordinateìƒì—ì„œ ì‚¼ê°í˜•ì˜ ì¤‘ì‹¬ì (center)ì´ (0,1)ê°„ê²© ì‚¬ì´ì— ì¡´ì¬í•´ì•¼ í•œë‹¤ëŠ” ì˜ë¯¸      ë§Œì•½, centerê°€ ì‚¼ê°í˜•ì˜ edgeì— ì •í™•í•˜ê²Œ ì¡´ì¬í•˜ë©´ ì–´ë–»ê²Œ í•˜ëŠ”ê°€?? ì´ ì§ˆë¬¸ì— ëŒ€í•œ ë‚´ìš©ì€ í›„ì— ë‹¤ë£¬ë‹¤    Barycentric Coordinateì„ í†µí•´ ì‚¼ê°í˜•ê°™ì€ ë‹¤ë©´ì²´ì˜ â€œê¼­ì§“ì â€ì´ ì£¼ì–´ì§€ëŠ” ìƒí™©ì—ì„œ ì–´ë–¤ ìœ„ì¹˜ì˜ í”½ì…€ì— ê·¸ë¦´ì§€ì™€ ê·¸ í”½ì…€ì˜ ìƒ‰ìƒë˜í•œ ê²°ì •í•˜ëŠ” keyê°€ ëœë‹¤.  ëª¨ë“  í”½ì…€ì— ëŒ€í•´ì„œ ê³ ëŸ¬ë“œ ë³´ê°„ì„ ì´ìš©í•˜ë©´ ê³„ì‚° ë³µì¡ì„±ì´ í¬ê¸° ë•Œë¬¸ì—, ì•„ë˜ì˜ ê°„ë‹¨í•œ ë°©ë²•ìœ¼ë¡œ íš¨ìœ¨ì„± ì¦ê°€ì‹œí‚¬ ìˆ˜ ìˆìŒ          ì‚¼ê°í˜•ì˜ ì„¸ ê¼­ì§“ì ì„ ê¸°ì¤€ìœ¼ë¡œ í•œ bounding rectangleì„ ì°¾ì•„ì„œ ì´ ì§ì‚¬ê°í˜• ë‚´ë¶€ì— ì¡´ì¬í•˜ëŠ” í›„ë³´ í”½ì…€ë“¤ì— ëŒ€í•´ì„œë§Œ ê³„ì‚° Loopingì„ ì§„í–‰í•œë‹¤      ì•Œê³ ë¦¬ì¦˜x_min = floor(x_i)x_max = ceiling(x_i)y_min = floor(y_i)y_max = ceiling(y_i)for y in range(y_min, y_max + 1):    for x in range(x_min, x_max + 1):        Î± = f_12(x, y) / f_12(x_0, y_0)        Î² = f_20(x, y) / f_20(x_1, y_1)        Î³ = f_01(x, y) / f_01(x_2, y_2)        if Î± &gt; 0 and Î² &gt; 0 and Î³ &gt; 0:s            c = Î± * c_0 + Î² * c_1 + Î³ * c_2            drawpixel(x, y, color=c)      ì—¬ê¸°ì„œ $f_{ij}$ëŠ” ê¼­ì§“ì ì„ ì‡ëŠ” ì§ì„ ì˜ ë°©ì •ì‹(line drawing ì„¹ì…˜)ì´ê³  ì•„ë˜ì²˜ëŸ¼ í‘œí˜„í•¨\\(\\begin{align} f_{01}(x,y) &amp;= (y_0 - y_1)x + (x_1 - x_0)y + x_0y_1 - x_1y_0 , \\\\                f_{12}(x,y) &amp;= (y_1 - y_2)x + (x_2 - x_1)y + x_1y_2 - x_2y_1 , \\\\                f_{20}(x,y) &amp;= (y_2 - y_0)x + (x_0 - x_2)y + x_2y_0 - x_0y_2 . \\end{align}\\)      Dealing with Pixels on Triangle Edges  ì‚¼ê°í˜•ì˜ ì¤‘ì‹¬(center)ì´ Edgeì— ì •í™•í•˜ê²Œ ì¡´ì¬í•˜ëŠ” ê²½ìš°ì˜ í”½ì…€ì€ ì–´ë–»ê²Œ ê²°ì •í•  ê²ƒì¸ì§€ì— ëŒ€í•œ ë‚´ìš©  ì‚¼ê°í˜• ì¤‘ì‹¬ì´ ì‚¼ê°í˜• ë³€ì— ìœ„ì¹˜í•˜ëŠ” ëŒ€í‘œì ì¸ ì˜ˆì‹œê°€ ì§ê°-ì‚¼ê°í˜•ì„ \"off-screen point\"ëŠ” ë‘ ì‚¼ê°í˜•ì˜ ê³µìœ ëœ ë³€ì˜ ì •í™•íˆ í•œìª½ì— ìœ„ì¹˜í•˜ë©°,  ìš°ë¦¬ê°€ ê·¸ë¦´ edgeëŠ” ë°”ë¡œ ê·¸ ë³€ì„,  ê³µìœ  ë³€ ìœ„ì— ìˆì§€ ì•Šì€ ì •ì ë“¤ì€ í•´ë‹¹ ë³€ ê¸°ì¤€ìœ¼ë¡œ ì„œë¡œ ë°˜ëŒ€ìª½ì— ìœ„ì¹˜í•œë‹¤.   ë”°ë¼ì„œ, ê·¸ë¦¼ ìƒ a ë˜ëŠ” b ì •ì  ì¤‘ í•˜ë‚˜ëŠ” off-screen pointì™€ shared edgeê¸°ì¤€ ê°™ì€ ë¶€í˜¸ë©´ì„ ê°€ì§„ë‹¤ëŠ” ì„±ì§ˆì´ìš©  $pq &gt; 0$ì•Œê³ ë¦¬ì¦˜y_max = ceiling(y_i)f_Î± = f_12(x_0, y_0)f_Î² = f_20(x_1, y_1)f_Î³ = f_01(x_2, y_2)for y in range(y_min, y_max + 1):    for x in range(x_min, x_max + 1):        Î± = f_12(x, y) / f_Î±        Î² = f_20(x, y) / f_Î²        Î³ = f_01(x, y) / f_Î³        if Î± &gt;= 0 and Î² &gt;= 0 and Î³ &gt;= 0:            if (Î± &gt; 0 or f_Î± * f_12(-1, -1) &gt; 0) and \\  # ë¶€í˜¸               (Î² &gt; 0 or f_Î² * f_20(-1, -1) &gt; 0) and \\  # ë¶€í˜¸               (Î³ &gt; 0 or f_Î³ * f_01(-1, -1) &gt; 0):       # ë¶€í˜¸                c = Î± * c_0 + Î² * c_1 + Î³ * c_2                drawpixel(x, y, color=c)1.3. CLipping  ëˆˆì˜ ë’¤(behind)ì— ì¡´ì¬í•˜ëŠ” ê³µê°„ í˜¹ì€ view volumeì˜ ë°”ê¹¥ì— ì¡´ì¬í•˜ëŠ” primitiveë¥¼ clippingí•´ì£¼ëŠ” ê³¼ì •ë“¤ì´ ìˆì–´ì•¼ ì •í™•í•œ Rasterizingì„ ìˆ˜í–‰í•  ìˆ˜ ìˆë‹¤.  ì‚¼ê°í˜•ì—ì„œ ë‘ ì •ì ì€ view volume ë‚´ë¶€ì— ì¡´ì¬í•˜ì§€ë§Œ, í•˜ë‚˜ì˜ ì •ì ì´ behind the eyeì— ìˆë‹¤ëŠ” ìƒí™©ì„ ìƒê°í•´ë³´ì.          perspective transformationì„ í•˜ê²Œ ë˜ë©´, depth $z$ê°€ $zâ€™$ë¡œ ë³€í™˜ë˜ê³  ë¶€í˜¸ë„ ë°˜ëŒ€ë¡œ ë°”ë€œ      ì´ë–„ ëª¨ë“  ì •ì ì´ view volumeì— ìˆì§€ ì•ŠëŠ”ë‹¤ë©´ ì œëŒ€ë¡œ transformationì´ ì´ë£¨ì–´ì§€ì§€ ì•Šì•„ì„œ ì‚¼ê°í˜• ëª¨ì–‘ë„ ë³€í˜•ë˜ëŠ” incorrect resultê°€ ì´ˆë˜ë¨        Clipping : removes part of primitives that could extend behind the eye (ì‹œì•¼ì— ë³´ì´ì§€ ì•ŠëŠ” primitivesë“¤ì„ ì œê±°í•˜ëŠ” ì—­í• )  transformë˜ê¸° ì´ì „ ë‹¨ê³„ì˜ 6ê°œì˜ í‰ë©´ì„ ì´ìš©í•˜ì—¬ í‘œí˜„ëœ world coordinateë“¤ì—ì„œ ìˆ˜í–‰ë˜ëŠ” clipping module  homogeneous coordinateì„ ì´ìš©í•˜ì—¬ 4D transformëœ spaceì—ì„œ ìˆ˜í–‰ë˜ëŠ” clipping module          ìœ„ì˜ ë‘ ê°€ì§€ ì˜µì…˜ì„ í†µí•´ clipping ì‘ì—…ì´ ìˆ˜í–‰ëœë‹¤.      1.4. Clipping against a Plane      í‰ë©´ì˜ ë°©ì •ì‹ : $f(\\mathrm{p}) = \\mathrm{n} \\cdot (\\mathrm{p}-\\mathrm{q}) = 0$ ì´ implicit equationì„ ë‹¤ì‹œ ì“°ë©´ ì•„ë˜ì²˜ëŸ¼ ì¬í‘œí˜„ ê°€ëŠ¥:\\[\\begin{align} f(\\mathrm{p}) = \\mathrm{n} \\cdot \\mathrm{p} + D = 0, \\end{align}\\]    points $a$ì™€ $b$ë¥¼ ì‡ëŠ” line segmentê°€ ìˆëŠ” ìƒí™©ì—ì„œ, ì´ ì„ ë¶„ì€ í‰ë©´ì— ì˜í•´ clippingë˜ì–´ì§  í‰ë©´ $f(\\mathrm{p}) &gt; 0$ ì´ë©´ í‰ë©´ì˜ ë‚´ë¶€(inside)ì— ì¡´ì¬í•˜ëŠ” ê²ƒì´ê³ , $f(\\mathrm{p}) &lt; 0$ì´ë©´ í‰ë©´ì˜ ì™¸ë¶€(outside)ì— ì¡´ì¬í•˜ëŠ” ê²ƒì„          clippingëœ ì„ ë¶„ì˜ ì–‘ë ì§€ì ì— ëŒ€í•œ ë¶€í˜¸ê°€ ë‹¤ë¥´ë‹¤ëŠ” ì„±ì§ˆ        ì„ ë¶„ê³¼ í‰ë©´ì´ ë§Œë‚˜ëŠ” intersection point $\\mathrm{p}$ ($\\mathrm{p} = a + t(b-a)$)ì—ì„œì˜ $f(\\mathrm{p}) = 0$ì´ë¼ëŠ” ì„±ì§ˆ ì´ìš©í•´ì„œ ì•„ë˜ ê·¸ë¦¼ì²˜ëŸ¼ êµì°¨ì ì—ì„œì˜ $t$ê°’ì„ ë„ì¶œí•  ìˆ˜ ìˆë‹¤.2. Operations Before and After Rasterization  Graphics pipelineì„ recall          Rasterization ì´ì „ì— â€œVertex processingâ€ ë‹¨ê³„ë¥¼ í†µí•´ geometryë“¤ì´ ì ì ˆí•˜ê²Œ transformedë˜ì–´ primitivesë¡œ ë„ì¶œë˜ì–´ì•¼ í•¨                  ì´ ë•Œ, viewing transformationsì„ ì´ìš©í•´ì„œ world coordinateì—ì„œ screen spaceë¡œ ë³€í™˜ë˜ëŠ” ì •ë³´ë“¤ + colors, surface normals, texture coordinate ê°™ì€ ì •ë³´ë“¤ë„ ë³€í™˜ë˜ì–´ì•¼í•¨          ì „ìëŠ” chapter 7ì—ì„œ ë‹¤ë£¨ì—ˆê¸° ë•Œë¬¸ì— í›„ìì˜ ë‚´ìš©ì„ ì´ë²ˆ ì±•í„°ì—ì„œ ì–´ë–»ê²Œ ë³€í™˜ì‹œí‚¤ëŠ”ì§€ ë‹¤ë£¨ë„ë¡ í•œë‹¤.                    Rasterization ì´í›„ì—ëŠ” â€œFragment processingâ€ ë‹¨ê³„ë¥¼ í†µí•´ rasterizationìœ¼ë¡œ ë‚˜ì˜¨ interpolated colorì™€ depthë¥¼ ê·¸ëŒ€ë¡œ í†µê³¼ì‹œí‚¤ë˜ê°€,ì•„ë‹ˆë©´ ë³µì¡í•œ shading operationìœ¼ë¡œ ê°ê°ì˜ fragmentì— ëŒ€í•œ colorì™€ depthë¥¼ ê³„ì‚°í•œë‹¤.      ê·¸ í›„, â€œBlendingâ€ ë‹¨ê³„ë¥¼ í†µí•´ ê° í”½ì…€ë§ˆë‹¤ ê²¹ì³ìˆëŠ” primitiveì—ì„œ final colorë¥¼ í˜¼í•©ì‹œì¼œ ê²°ì •í•œë‹¤.                  ê°€ì¥ ì‰½ê³  í”í•œ ë°©ë²•ìœ¼ë¡œëŠ” depthê°€ ê°€ì¥ ì‘ì€, ì¦‰ eyeì™€ ê°€ì¥ ê°€ê¹Œìš´ fragmentì˜ colorë¡œ ì„ íƒí•˜ëŠ” ê²ƒ                    2.1. Simple 2D Drawing  ê°€ì¥ ê°„ë‹¨í•œ íŒŒì´í”„ë¼ì¸ì€, vertexì™€ fragments stage, ê·¸ë¦¬ê³  blending stage ì—ì„œ ì•„ë¬´ê²ƒë„ ìˆ˜í–‰ë˜ì§€ ì•Šê³  ì˜¤ë¡œì§€ rasterizationì—ì„œ pixel coordinateì— ì§ì ‘ì ìœ¼ë¡œ ì—°ì‚°ë“¤ì´ ëª¨ë‘ ìˆ˜í–‰ë˜ëŠ” ê²ƒ2.2. A Minimal 3D Pipeline  3D ê³µê°„ì— ë¬¼ì²´ë¥¼ ê·¸ë¦¬ê¸° ìœ„í•´ì„œëŠ” 2D Drawing pipelineì—ì„œ matrix transformationì´ í¬í•¨ë˜ì–´ vertex processingì´ ì´ë£¨ì–´ì§„ë‹¤.          vertex-processingì—ì„œ ì¸í’‹ìœ¼ë¡œ ë“¤ì–´ì˜¤ëŠ” vertex positionì—ë‹¤ê°€ camera, projection, ê·¸ë¦¬ê³  viewport transformationê°™ì€ í–‰ë ¬ì„ ê³±í•¨ìœ¼ë¡œì¨ í–‰ë ¬ ë³€í™˜ì´ ìˆ˜í–‰ë¨            ì´ ê²°ê³¼ë¡œ ì‚¼ê°í˜•ì´ screen spaceì— ë„ì›Œì§ˆ ìˆ˜ ìˆê³ , ì´ê²ƒì€ 2Dìƒì— ì§ì ‘ì ìœ¼ë¡œ ê·¸ë ¤ì§€ëŠ” ê²ƒê³¼ ê°™ì€ ê²°ê³¼ì„    Occlusion problem : back-to-front ìˆœì„œë¡œ ë¬¼ì²´ë“¤ì„ ê·¸ë¦¬ì§€ ì•Šìœ¼ë©´, ë” ê°€ê¹Œì´ ìˆëŠ” ë¬¼ì²´ê°€ ë©€ë¦¬ ìˆëŠ” ë¬¼ì²´ì— ê°€ë ¤ì§€ëŠ” incorrect resultê°€ ì´ˆë˜ë¨          ì´ back-to-front ìˆœì„œë¡œ ë¬¼ì²´ ê·¸ë¦¬ëŠ” ê±¸ Painterâ€™s algorithmì´ë¼ê³ ë„ ë¶€ë¦„      hidden surfaceë¥¼ ì œê±°í•˜ëŠ” ê°€ì¥ íƒ€ë‹¹í•œ ë°©ë²•ì„      í•˜ì§€ë§Œ, Occlusion cycleê°™ì€ ì–´ë–¤ ë¬¼ì²´ê°€ ë” ì•ì— ìˆê³  ë’¤ì—ìˆëŠ”ì§€ ì´ ìƒëŒ€ì ì¸ ê¹Šì´ë¥¼ í‰ê°€í•  ìˆ˜ ì—†ëŠ” ê²½ìš°ê°€ ì¡´ì¬í•¨                  ì´ëŸ´ë•ŒëŠ” painterâ€™s algorithmìœ¼ë¡œ back-to-front orderë¥¼ ì„¤ì •í•  ìˆ˜ê°€ ì—†ë‹¤.          ë˜í•œ, depth ê¸°ì¤€ìœ¼ë¡œ primitivesë¥¼ ì •ë ¬í•˜ëŠ” ê²ƒì€ ì‹œê°„ì†Œìš”ì ì´ë¼ì„œ í° ì”¬ì— ëŒ€í•´ì„œëŠ” ì• ì´ˆì— painterâ€™s algorithmì„ ì‚¬ìš©í•˜ê¸°ê°€ ê±°ì˜ ì–´ë ¤ì›€                     2.3. Using a Z-Buffer for Hidden Surfaces  ì•ì„  occlusion problemì—ì„œ í•„ìš”í•œ depth sortingì´ ì‹œê°„ì†Œìš”ì ì´ë¼ëŠ” ì¸¡ë©´ì—ì„œ, painterâ€™s algorithmì´ ê±°ì˜ ì‚¬ìš©ë˜ì§€ ì•Šê¸° ë–„ë¬¸ì— ë‚˜ì˜¨ ë°©ë²•  ì•„ì´ë””ì–´ = ê° í”½ì…€ì—ì„œ ì§€ê¸ˆê¹Œì§€ ë Œë”ë§ëœ ê°€ì¥ ê°€ê¹Œìš´ í‘œë©´ê¹Œì§€ì˜ ê±°ë¦¬(depth)ë¥¼ ê¸°ë¡í•˜ê³ , ê·¸ ê±°ë¦¬ë³´ë‹¤ ë” ë©€ë¦¬ ìˆëŠ” fragmentëŠ” íê¸°í•œë‹¤.          ì´ ê±°ë¦¬ë¥¼ RGB color ì„¸ ê°’ì— ì¶”ê°€ì ìœ¼ë¡œ bufferë¥¼ ë‘ì–´ zê°’ì„ ì €ì¥í•˜ê³  zì°¨ì›ì—ì„œ gridë¥¼ ìƒì„±í•¨        buffer algorithmì€ Fragment blending phaseì—ì„œ êµ¬í˜„ë¨  í˜„ì¬ z-bufferì— ì €ì¥ëœ depth valueë‘ ê° fragmentë³„ë¡œ depthë¥¼ ë¹„êµí•˜ë©´ì„œ, ë§Œì•½ í•´ë‹¹ fragment valueê°’ì´ ë” ì‘ë‹¤ë©´ colorì™€ depth valueë¥¼ ë®ì–´ì”Œìš´ë‹¤.2.4. Per-vertex Shading  rasterizationìœ¼ë¡œ interpolatedëœ colorì™€ ê³„ì‚°ëœ depthë¡œë§Œ 3D ê³µê°„ì—ì„œ objectë¥¼ ë‚˜íƒ€ë‚´ëŠ” ê²ƒìœ¼ë¡œ ì¶©ë¶„í•  ìˆ˜ë„ ìˆì§€ë§Œ, ëŒ€ë¶€ë¶„ì€ objects with shadingì„ êµ¬í˜„í•˜ê³  ì‹¶ì–´í•¨  light direction, eye direction, surface normal ê°™ì€ ì¡°ëª…ê³¼ ê´€ë ¨í•œ ë³€ìˆ˜ë“¤ í•„ìš”ë¡œ í•¨  vertex stageì—ì„œ shading computationì„ ìˆ˜í–‰í•˜ëŠ” ë°©ë²• ì†Œê°œ          â€œê³ ëŸ¬ë“œ ì‰ì´ë”©â€      ì¹´ë©”ë¼ poistion, lights, vertexì— ì˜í•´ì„œ ë¹›ì˜ ë°©í–¥ê³¼ viewerì˜ gaze directionì´ ê³„ì‚°ë˜ëŠ” ë°©ë²•      ì´ shading equationì„ í†µí•´ ê³„ì‚°ëœ vertex colorëŠ” rasterizerì—ê²Œ ë„˜ì–´ê° (ì¦‰, rasterizer ì´ì „ ë‹¨ê³„ì—ì„œ ìˆ˜í–‰ë˜ëŠ” shading equationì´ë‹¤)        ê°ê°ì˜ vertexì—ì„œ shadingì„ ë‹¤ë£¨ê³  vertexë¼ë¦¬ëŠ” ë‹¤ë£¨ì§€ ì•Šì•„ì„œ ì•„ë¬´ë˜ë„ ë””í…Œì¼ì´ ì¢€ ë–¨ì–´ì§„ë‹¤ëŠ” ë‹¨ì ì´ ìˆë‹¤.2.5. Per-fragment Shading  Rasterization ì´í›„ì— ë‚˜ì˜¨ interpolated colorë¥¼ ì´ìš©í•´ì„œ fragment stageì—ì„œ ìˆ˜í–‰ë˜ëŠ” shading  â€œPhong shadingâ€ (Phong illumination modelì´ë‘ ë‹¤ë¥¸ ê°œë…ì„)  shading equationìì²´ëŠ” ë˜‘ê°™ì§€ë§Œ, ì •ì  ê°ê°ì— í–‰í•´ì§€ëŠ” ê²ƒì´ ì•„ë‹ˆë¼ rasterziationìœ¼ë¡œ ë‚˜ì˜¨ ë³´ê°„ëœ ìƒ‰ìƒì„ ì´ìš©í•œ fragmentê°ê°ì— ìˆ˜í–‰ëœë‹¤ëŠ” ì ì´ ë‹¤ë¦„          ì´ê²ƒì„ ìœ„í•´ì„œ vertex stage ì¢Œí‘œê³„ê°€ fragment stageì™€ ì¼ë ¨ë˜ê²Œ ì¡´ì¬í•´ì•¼ ë°ì´í„°ê°€ ì ì ˆí•˜ê²Œ ì‚¬ìš©ë  ìˆ˜ ìˆìŒ      2.6. Texture Mapping  Textureì— ëŒ€í•œ ë””í…Œì¼ì€ chapter-11ì—ì„œ ë” ìì„¸í•˜ê²Œ ë‹¤ë£° ì˜ˆì •  Textures : í‘œë©´ì˜ ìŒì˜(shading)ì— ì¶”ê°€ì ì¸ ë””í…Œì¼ì„ ë”í•˜ê¸° ìœ„í•´ ì‚¬ìš©ë˜ëŠ” ì´ë¯¸ì§€ë¡œ, ì¶”ê°€ë˜ì§€ ì•Šìœ¼ë©´ ì§€ë‚˜ì¹˜ê²Œ ê· ì¼í•˜ê³  ì¸ê³µì ìœ¼ë¡œ ë³´ì´ê²Œ ë  ìˆ˜ ìˆìŒ2.7. Shading Frequency  shading computationë“¤ì„ ì–´ë–¤ ìŠ¤í…ì— ìœ„ì¹˜ì‹œí‚¬ì§€ë¥¼ color changeê°€ ì–¼ë§ˆë‚˜ ë¹ ë¥¸ì§€ì— ë”°ë¼ ê²°ì •í•  ìˆ˜ ìˆë‹¤.  ì´ ë³€í•˜ëŠ” ì •ë„ë¥¼ â€œscaleâ€ë¡œ í™•ì¸í•  ìˆ˜ ìˆìŒ          large-scale features(e.g., diffuse shading(ë‚œë°˜ì‚¬ëœ ë¹›) on curved surfaces)                  low shading frequencyë¡œ ê³„ì‚°ë˜ì–´ì•¼ í•¨          vertex stage                    small-scale features(e.g., sharp highlightsor detailed textures)                  high shading frequencyë¡œ ê³„ì‚°ë¨          vertex stage  &amp; fragment stage ëª¨ë‘ ê°€ëŠ¥                    simple anti-aliasing, culling primitives ë‚´ìš© êµì¬ ì°¸ê³ "
  },
  
  {
    "title": "Graphics-Ch7. Viewing",
    "url": "/posts/ch7-Viewing/",
    "categories": "Graphics, Study",
    "tags": "Graphics",
    "date": "2025-02-13 12:04:00 +0900",
    





    
    "snippet": "Intro  3D to 2D mappingì„ í†µí•´ objectë¥¼ 3d locationê³¼ 2D view ì‚¬ì´ì—ì„œ ì´ë™ì‹œí‚¤ëŠ” ê²ƒì„ â€œviewing Transformationâ€œì´ë¼ê³  í•¨  object-order renderingì—ì„œ ì¤‘ìš”í•¨  ch4(Ray-Tracing)ë‹¨ì›ì—ì„œ orthographic(paralled) viewì™€ perspective vie...",
    "content": "Intro  3D to 2D mappingì„ í†µí•´ objectë¥¼ 3d locationê³¼ 2D view ì‚¬ì´ì—ì„œ ì´ë™ì‹œí‚¤ëŠ” ê²ƒì„ â€œviewing Transformationâ€œì´ë¼ê³  í•¨  object-order renderingì—ì„œ ì¤‘ìš”í•¨  ch4(Ray-Tracing)ë‹¨ì›ì—ì„œ orthographic(paralled) viewì™€ perspective viewì—ì„œ vieweing rayê°€ ì–´ë–»ê²Œ ìƒì„±ë˜ëŠ”ì§€ì— ëŒ€í•´ ê°„ë‹¨í•˜ê²Œ ë‹¤ë£¨ì—ˆìŒ          ray-tracerëŠ” rayì™€ ë§Œë‚˜ëŠ” ê°€ì¥ ê°€ê¹Œìš´ êµì°¨ì ì— ëŒ€í•œ surfaceë¥¼ ì°¾ëŠ” ê²ƒì´ê³ , object-order rendererëŠ” solid-looking objectì—ì„œ ì–´ë–¤ í‘œë©´ì´ screen space(pixcel space)ì˜ ì–´ë–¤ ì ë“¤ì— ë§¤ì¹­ë˜ì–´ ê·¸ë ¤ì§€ëŠ”ì§€ì— ëŒ€í•´ ë‹¤ë£¨ëŠ” ê²ƒ      1. Viewing Transformations  Viewing Transformationì„ í†µí•´ Canonical Coordinate Systemì—ì„œì˜ $(x, y, z)$ë¡œ í‘œê¸°ë˜ëŠ” 3D locationì„ ì´ë¯¸ì§€ í”½ì…€ ë‹¨ìœ„ì˜ screen space ë§¤í•‘í•˜ëŠ” ê²ƒì´ í•„ìš”í•¨          ê³ ë ¤ë˜ì–´ì•¼ í•  ê²ƒ : projectionì˜ ì¢…ë¥˜, FOV(Field of View, ì‹œì•¼ê°), ì´ë¯¸ì§€ í•´ìƒë„ ë“±        ì•„ë˜ ì„¸ ê°€ì§€ì˜ transformation ê³¼ì •ìœ¼ë¡œ World Spaceì— ìˆëŠ” ë¬¼ì²´ê°€ Screen Spaceë¡œ View Transformedëœë‹¤.          Camera Transformation (Eye Transformation) :                  cameraì˜ pose(position, oriendtation)ì—ë§Œ ì˜ì¡´          World Coordinate -&gt; Camera Coordinate                    Projection Tranformation :                  projection ì¢…ë¥˜ì— ì˜í•´ì„œë§Œ ì˜ì¡´          Camera space -&gt; Canonical View Volume          -1ì—ì„œ +1 ë²”ìœ„ì˜ points                    Viewpoint Transformation (Windowing Transformation) :                  output ì´ë¯¸ì§€ì˜ sizeì™€ positionì— ì˜ì¡´          Canonical view volume -&gt; Screen space                    1.1. The Viewport Transformation  canonical view volumeì— ìˆëŠ” viewë¥¼ ê°€ì •í•´ì•„ í•¨, inputì²˜ëŸ¼ ìƒê°      $(x, y, z) \\in [-1, +1]^3$\\[\\begin{bmatrix} x_{\\text{screen}} \\\\ y_{\\text{screen}} \\\\ 1 \\end{bmatrix} =  \\begin{bmatrix} \\frac{n_x}{2} &amp; 0 &amp; \\frac{n_x - 1}{2} \\\\ 0 &amp; \\frac{n_y}{2} &amp; \\frac{n_y - 1}{2} \\\\ 0 &amp; 0 &amp; 1 \\end{bmatrix}  \\begin{bmatrix} x_{\\text{canonical}} \\\\ y_{\\text{canonical}} \\\\ 1 \\end{bmatrix} .\\]    Viewport Transformation Matrix :          ì•ì„  ì‹ì˜ ë³€í™˜í–‰ë ¬ì—ë‹¤ê°€ $z$ coordinateì˜ í–‰ê³¼ ì—´ì— $ [0 \\quad 0 \\quad 0 \\quad 1]$ ë¥¼ ì¶”ê°€ì‹œí‚´      \\[\\begin{align}M_{\\text{vp}} = \\begin{bmatrix}  \\frac{n_x}{2} &amp; 0 &amp; 0 &amp; \\frac{n_x - 1}{2} \\\\  0 &amp; \\frac{n_y}{2} &amp; 0 &amp; \\frac{n_y - 1}{2} \\\\  0 &amp; 0 &amp; 1 &amp; 0 \\\\  0 &amp; 0 &amp; 0 &amp; 1 \\end{bmatrix}.\\end{align}\\]1.2. Orthographic Projection Transformation  canonical view volume ì¢Œí‘œê³„ë¡œ ì˜®ê¸°ëŠ” ë³€í™˜ ê³¼ì •  input : camera coordinate (orthographic view)  orthographic view volumeì„ ì•„ë˜ì˜ 3D spaceë¡œ ì •ì˜í•  ìˆ˜ ìˆìŒ   = $[l,r]$ x $[b,t]$ x $[f,n]$          ì¢Œìš°, ìƒí•˜, ì•ë’¤ ì ˆë‹¨ë©´ì„ ì •ì˜í•˜ëŠ” í´ë¦¬í•‘ íŒŒë¼ë¯¸í„°        ì•„ë˜ ê·¸ë¦¼ì²˜ëŸ¼ orthorgraphic view volumeì—ì„œ $-z$ë°©í–¥ìœ¼ë¡œ ë°”ë¼ë³´ê³  ìˆë‹¤ê³  ê°€ì •í•˜ê¸° ë•Œë¬¸ì—(ìƒí™©ë§ˆë‹¤ ë‹¤ë¥´ê²Œ ì„¤ì •ê°€ëŠ¥í•˜ê¸´ í•˜ë‹¤) $f$(far)ê°€ $n$(near)ë³´ë‹¤ ì‘ì€ ê°’ì„  \\[\\begin{align}M_{\\text{orth}} =  \\begin{bmatrix}  \\frac{2}{r - l} &amp; 0 &amp; 0 &amp; -\\frac{r + l}{r - l} \\\\  0 &amp; \\frac{2}{t - b} &amp; 0 &amp; -\\frac{t + b}{t - b} \\\\  0 &amp; 0 &amp; \\frac{2}{n - f} &amp; -\\frac{n + f}{n - f} \\\\  0 &amp; 0 &amp; 0 &amp; 1  \\end{bmatrix}.\\end{align}\\]      camera space(orthographic view volume) =&gt; screen space(image pixel)ë¡œì˜ ìµœì¢… ë³€í™˜ ìˆ˜ì‹ì€ ì•„ë˜ì™€ ê°™ìŒ:\\[\\begin{align}  \\begin{bmatrix}  x_{\\text{pixel}} \\\\ y_{\\text{pixel}} \\\\ z_{\\text{canonical}} \\\\ 1 \\end{bmatrix} = (M_{\\text{vp}}M_{\\text{orth}}) \\begin{bmatrix}x \\\\ y \\\\ z \\\\ 1\\end{bmatrix}.\\end{align}\\]  1.3. The Camera Transformation  World(object) space ì—ì„œ Camera Space($uvw$-space)ë¡œì˜ ë³€í™˜ ê³¼ì •ìƒˆë¡­ê²Œ ì •ì˜ë˜ëŠ” ë³€ìˆ˜ 3ê°€ì§€ = {eye position $e$, gaze direction $g$, view-up vector $t$} + ê¸°ì € ë²¡í„° ${uvw}$  ì´ ì •ë³´ë“¤ë¡œ ì™¼ìª½ì²˜ëŸ¼ coordinate system ì„¸íŒ…í•˜ëŠ”ë° ì¶©ë¶„í•œ ì •ë³´ë¥¼ ì œê³µí•¨    arbitrary view(world space coordinate $xyz$)ìœ¼ë¡œë¶€í„° origin $e$ì™€ ê¸°ì €ë²¡í„° $u,v,w$ë¡œ í‘œí˜„ëœ ì¹´ë©”ë¼ ì¢Œí‘œ ì‹œìŠ¤í…œìœ¼ë¡œ ì €ì¥í•˜ëŠ” ê²ƒì´ ëª©í‘œ          origin $e$ë¡œì˜ translation &amp; u,v,zë¡œì˜ scaling matrix ì²˜ëŸ¼ ìƒê°í•˜ë©´ ë¨ (ì™¼ì—ì„œ ì˜¤ë¡œ ê³±í•´ì§€ëŠ” ê·¸ê±°)            ì•„ë˜ì˜ ë³€í™˜ ìˆ˜ì‹ì„ í†µí•´ ìˆ˜í–‰ë¨:\\[\\begin{align} M_{\\text{cam}} =\\begin{bmatrix}\\mathbf{u} &amp; \\mathbf{v} &amp; \\mathbf{w} &amp; \\mathbf{e} \\\\0 &amp; 0 &amp; 0 &amp; 1\\end{bmatrix}^{-1}=\\begin{bmatrix}x_u &amp; y_u &amp; z_u &amp; 0 \\\\x_v &amp; y_v &amp; z_v &amp; 0 \\\\x_w &amp; y_w &amp; z_w &amp; 0 \\\\0 &amp; 0 &amp; 0 &amp; 1\\end{bmatrix}\\begin{bmatrix}1 &amp; 0 &amp; 0 &amp; -x_e \\\\0 &amp; 1 &amp; 0 &amp; -y_e \\\\0 &amp; 0 &amp; 1 &amp; -z_e \\\\0 &amp; 0 &amp; 0 &amp; 1\\end{bmatrix}. \\end{align}\\]    ìµœì¢…ì ì¸ Viewing Transformation ì•Œê³ ë¦¬ì¦˜ :            Matrix Name      Description                  M_vp      Viewport Matrix              M_orth      Orthographic Matrix              M_cam      Camera Matrix              M      $( M = M_{\\text{vp}} M_{\\text{orth}} M_{\\text{cam}} )$      Algorithm  Construct ( $M_{\\text{vp}}$ )  Construct ( $M_{\\text{orth}}$ )  Construct ( $M_{\\text{cam}}$ )  Compute ( $M = M_{\\text{vp}} M_{\\text{orth}} M_{\\text{cam}}$ )  For each line segment ( (a_i, b_i) ):          Compute ( $p = M_{a_i}$ )      Compute ( $q = M_{b_i}$ )      Draw line from ( $(x_p, y_p)$ ) to ( $(x_q, y_q)$ )      2. Projective Transformations  ì•ì„  1.2.ë‹¨ê³„ì˜ orthographic veiw volume(camera space)ì—ì„œ canonical view volumeìœ¼ë¡œ ë³€í™˜ í•˜ëŠ” ë‹¨ê³„ì—ì„œ ì‚¬ìš©í•˜ëŠ” transformation ì¢…ë¥˜ë“¤ì— ëŒ€í•´ì„œ ì•Œì•„ë³´ì.  ì£¼ìš” íŠ¹ì„±(key property) :          screenì— ë³´ì´ëŠ” objectì˜ sizeëŠ” $-z$ì¶• ë°©í–¥ìœ¼ë¡œ ë³´ì—¬ì§€ëŠ” camera spaceì™€ì˜ ê±°ë¦¬(depth) $z$ì˜ ì—­ìˆ˜ì— ë¹„ë¡€í•¨            Affine Transformation(ì–´íŒŒì¸ ë³€í™˜)ìœ¼ë¡œëŠ” ë¶„ëª¨ë¡œ z(input vectorì˜ í•œ ìš”ì†Œ)ë¥¼ ë‚˜ëˆ„ëŠ” ì´ëŸ¬í•œ ì—°ì‚°ì€ êµ¬í˜„í•  ìˆ˜ê°€ ì—†ë‹¤    Homogeneous Coordinate ë©”ì»¤ë‹ˆì¦˜ì„ í™œìš©í•¨          ë§ˆì§€ë§‰ ì›ì†Œë¥¼ 1ë¡œ ë‘ê³  ì°¨ì›ì„ í•˜ë‚˜ í™•ì¥ì‹œí‚¤ëŠ” ì¢Œí‘œê³„ $(x,y,z) -&gt; (x,y,z,1)$      ì—¬ê¸°ì„œ 1ì„ $(x,y,z)$ì¢Œí‘œì˜ ë¶„í¬ë¡œ ìƒê°í•  ìˆ˜ ìˆë‹¤.        Affine ë³€í™˜ì„ í†µí•´ ë³€í™˜ëœ point $xâ€™ = ax + by + cz +d$3. Perspective Projection      matrix transformation : \\(\\begin{bmatrix} y_s \\\\ 1 \\end{bmatrix}  \\sim \\begin{bmatrix} d &amp; 0 &amp; 0 \\\\ 0 &amp; 1 &amp; 0 \\end{bmatrix}  \\begin{bmatrix} y \\\\ z \\\\ 1 \\end{bmatrix}.\\)        Perspective Matrix $P$ : \\(\\begin{align} \\mathbf{P} =\\begin{bmatrix}n &amp; 0 &amp; 0 &amp; 0 \\\\0 &amp; n &amp; 0 &amp; 0 \\\\0 &amp; 0 &amp; n + f &amp; -f n \\\\0 &amp; 0 &amp; 1 &amp; 0\\end{bmatrix}.\\end{align}\\)    perspective matrixë¥¼ orthograpic ì‹œìŠ¤í…œì— ë³‘í•©í•˜ê¸° ìœ„í•´ì„œ, $M_{per} = M_{orth} P.$ë¥¼ ì´ìš©í•˜ì—¬ ì•„ë˜ì™€ ê°™ì€ transforamtion matrix ë¡œ ë¶„í•´í•  ìˆ˜ ìˆë‹¤:  \\[\\begin{align} M = M_{vp} (M_{orth} P) M_{cam} \\end{align}\\]          \\[\\begin{align} M_{\\text{per}} =  M_{orth} P =  \\begin{bmatrix}  \\frac{2n}{r - l} &amp; 0 &amp; \\frac{l + r}{l - r} &amp; 0 \\\\  0 &amp; \\frac{2n}{t - b} &amp; \\frac{b + t}{b - t} &amp; 0 \\\\  0 &amp; 0 &amp; \\frac{f + n}{n - f} &amp; \\frac{2fn}{f - n} \\\\  0 &amp; 0 &amp; 1 &amp; 0  \\end{bmatrix}. \\end{align}\\]            5. Field-of-View(FOV)  í•œêµ­ë§ë¡œ ì‹œì•¼ê°ì´ë¼ëŠ” ì˜ë¯¸  $\\theta$ë¡œ í‘œí˜„ = the angle from the bottom of the screen to the top of the screen as measured from the eye\\[\\begin{align} tan\\frac{2}{\\theta} = \\frac{t}{|n|}  \\end{align}\\]"
  },
  
  {
    "title": "Mip-NeRF 360, CVPR 2022",
    "url": "/posts/MipNerf360/",
    "categories": "Paper Review",
    "tags": "Surface reconstruction, Graphics",
    "date": "2025-02-10 12:30:00 +0900",
    





    
    "snippet": "Mip-NeRF 360: Unbounded Anti-Aliased Neural Radiance Fields  depth distortion lossì˜ ì‹œì´ˆ          í˜„ì¬ GSê¸°ë°˜ Surface Reconstruction ì •ê·œí™” í…€ë“¤ì— ë§ì´ ì‚¬ìš©í•¨      Abstract  â€œunbounded sceneâ€ : í•™ìŠµëœ ë°ì´í„°ì˜ ë°©í–¥(directio...",
    "content": "Mip-NeRF 360: Unbounded Anti-Aliased Neural Radiance Fields  depth distortion lossì˜ ì‹œì´ˆ          í˜„ì¬ GSê¸°ë°˜ Surface Reconstruction ì •ê·œí™” í…€ë“¤ì— ë§ì´ ì‚¬ìš©í•¨      Abstract  â€œunbounded sceneâ€ : í•™ìŠµëœ ë°ì´í„°ì˜ ë°©í–¥(direction)ê³¼ ê±°ë¦¬(distance)ì™€ ë¬´ê´€í•˜ê²Œ ëª¨ë“  rayìƒì— ì¡´ì¬í•˜ëŠ” pointì— ëŒ€í•´ ì˜ í•©ì„±ëœ scene          ì£¼ë¡œ ì „ê²½ ë¬¼ì²´ ë¿ë§Œì•„ë‹ˆë¼ ë°°ê²½ê¹Œì§€ ìˆëŠ” sceneì„ ì˜ë¯¸í•¨        NeRF(Neural Radiance Fields)          volumentric density ë‘ colorë¥¼ MLPë¥¼ í†µí•´ í•©ì„±í•¨      MLP : rayìƒì˜ ì‘ì€ 3D pointë“¤ì„ ì´ìš©        Critical Issues          Parameterization      Efficiency      Ambiguity      Preliminaries : mip-NeRF  ray : $\\mathrm{r}(t) = \\mathrm{o} + t\\mathrm{d}$ ê°€ ìˆì„ ë•Œ,  distance $t$ì— ì˜í•´ì„œ ì •ë ¬ëœ ë²¡í„°ê°€ ì •ì˜ë˜ê³  rayê°€ tì— ëŒ€í•œ êµ¬ê°„ì˜ ì§‘í•©ìœ¼ë¡œ ìª¼ê°œì§„ë‹¤ $T_i = [t_i, t_{i+1}]$  ê° êµ¬ê°„ë§ˆë‹¤ ì›ë¿”ëŒ€(conical frustum)ì˜ í‰ê· ê³¼ ê³µë¶„ì‚°$(\\mu, \\Sigma)=\\mathrm{r}(T_i)$ì„ ê³„ì‚°í•¨          rayì˜ focal lengthì™€ image planeì˜ í”½ì…€ì‚¬ì´ì¦ˆì— ì˜í•´ì„œ ê²°ì •ë¨              featureize ë‹¨ê³„(IPE, Integratged positional Encoding)\\[\\gamma(\\mu, \\Sigma) =\\left\\{\\begin{bmatrix}    \\sin(2\\ell \\mu) \\exp\\left(-2^ {2\\ell-1} \\operatorname{diag}(\\Sigma)\\right) \\\\    \\cos(2\\ell \\mu) \\exp\\left(-2^ {2\\ell-1} \\operatorname{diag}(\\Sigma)\\right)    \\end{bmatrix}    \\right\\}_{\\ell=0}^{L-1}\\]              ìœ„ ê°’ë“¤ì´ MLPì˜ inputìœ¼ë¡œ ë“¤ì–´ê°€ê³ , MLP weightì¸ $\\Theta_{NeRF}$ì™€ ê°™ì´ ë“¤ì–´ê°€ì„œ density $\\tau$ì™€ color $\\mathrm{c}$ë¥¼ ì¶œë ¥í•¨ :          \\[\\forall T_i \\in t, \\quad (\\tau_i, c_i) = \\text{MLP}(\\gamma(r(T_i)); \\Theta_{\\text{NeRF}})\\]              view direction $\\mathrm{d}$ë„ MLPì— ê°™ì´ ë“¤ì–´ê°      Volume renderingì„ í†µí•´ ë Œë”ë§ë˜ëŠ” ìµœì¢… pixel color $\\mathrm{C}(\\mathrm{r}, t)$ :\\[\\begin{align} \\mathrm{C}(\\mathrm{r}, t) = \\sum_limits_i w_i c_i \\\\     w_i = (1-e^{-\\tau_i(t_{i+_1} - t_i)})e^{-\\sum_{i' &lt; i}\\tau_{i'}(t_{i'+1}-t_{i'})} \\end{align}\\]    NeRFëŠ” ë‘ ê°œì˜ ì„œë¡œ ë‹¤ë¥¸ MLP (â€œcoarseâ€ MLPì™€ â€œfineâ€ MLP)ë¥¼ ì‚¬ìš©í•˜ëŠ” ê³„ì¸µì  ìƒ˜í”Œë§ ì ˆì°¨ë¥¼ ì‚¬ìš© :          $t^c \\sim U[t_n, t_f], \\quad t^c = \\operatorname{sort}({t^c}) $      $t^f \\sim hist[t^c, w^c], \\quad t^f = \\operatorname{sort}({t^f}) $            final loss (combination of coarse and fine reconstruction loss) :\\[\\sum_{\\mathbf{r} \\in \\mathcal{R}} \\frac{1}{10}   \\mathcal{L}_{\\text{recon}} \\left( \\mathbf{C}(\\mathbf{r}, t^c), \\mathbf{C}^*(\\mathbf{r}) \\right)   + \\mathcal{L}_{\\text{recon}} \\left( \\mathbf{C}(\\mathbf{r}, t^f), \\mathbf{C}^*(\\mathbf{r}) \\right)\\]  1. Scene and Ray Parameterization1.1. 3D coordinate $x$ì— ëŒ€í•œ Parameterization  ê¸°ì¡´ì˜ ì—°êµ¬ë“¤ì€ unbounded sceneì— ëŒ€í•´ pointë¥¼ íŒŒë¼ë¯¸í„°í™”í–ˆì§€ë§Œ, ë³¸ ë…¼ë¬¸ì—ì„œëŠ” Gaussianì„ ì¬íŒŒë¼ë¯¸í„°í™”í•˜ì˜€ë‹¤  $f(x)$ : smooth coordinate transformation function ë˜ëŠ” state transition modelì´ë¼ê³  ì •ì˜  $f$ ì— ëŒ€í•œ ì„ í˜• ê·¼ì‚¬ = $f(x)â‰ˆf(Î¼)+J_f(Î¼)(xâˆ’Î¼)$          where, $J$: $\\mu$ì—ì„œì˜ fí•¨ìˆ˜ì— ëŒ€í•œ ìŸˆì½”ë¹„ì•ˆ í–‰ë ¬    \\[\\begin{align} f(Î¼,Î£)=(f(Î¼),J_f(Î¼)Î£J_f(Î¼)âŠ¤) \\end{align}\\]    Extended Kalman Filterì´ë‘ ë¹„ìŠ·í•˜ê²Œ ì‘ë™í•¨                  Contract í•¨ìˆ˜ : point xë¥¼ ì…ë ¥ë°›ì•„ íŠ¹ì • ë°˜ì§€ë¦„(1,2)ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ë³€í˜•í•˜ëŠ” ì—°ì‚°\\[\\text{contract}(x) =\\begin{cases} x, &amp; \\text{if } \\|x\\| \\leq 1 \\\\\\left(2 - \\frac{1}{\\|x\\|} \\right) \\left(\\frac{x}{\\|x\\|} \\right), &amp; \\text{if } \\|x\\| &gt; 1\\end{cases}\\]              ì˜ë¯¸          xê°€ 1ë³´ë‹¤ í° ê²½ìš°(ê·¸ë¦¼ì—ì„œ ì£¼í™©ìƒ‰ ë²”ìœ„ì¸ ê²½ìš°)ì—ëŠ” ë²¡í„°ë¥¼ ë°©í–¥ì€ ìœ ì§€í•˜ë©´ì„œ íŠ¹ì • í¬ê¸°ë¡œ ì¶•ì†Œ(ìˆ˜ì¶•, contract)      ë³€í˜•ëœ í¬ê¸°ëŠ” $2âˆ’1âˆ¥xâˆ¥2âˆ’âˆ¥xâˆ¥1â€‹$ ë¡œ ì¡°ì •ë¨ , ë²¡í„°ë¥¼ ë‹¨ìœ„ ë²¡í„°ë¡œ ë³€í™˜í•œ í›„ í¬ê¸°ë¥¼ ë‹¤ì‹œ ìŠ¤ì¼€ì¼ë§í•˜ëŠ” ë°©ì‹      =&gt; ê±°ë¦¬ê°€ ë©€ë¦¬ ë–¨ì–´ì ¸ ìˆì„ìˆ˜ë¡ disparity(ì‹œì  ì°¨) ì¦‰, distanceì˜ ì—­ìˆ˜ë§Œí¼ ë¹„ìœ¨ì ìœ¼ë¡œ ë¶„í¬í•˜ê²Œ í•´ì¤Œ      NDC(normalzed device coordinate)ì™€ ê°™ì€ motivation        ë³¸ ë…¼ë¬¸ì—ì„œëŠ” ì•„ë˜ì˜ ì‹ì— ë”°ë¼ ìœ í´ë¦¬ë“œ ê³µê°„ì—ì„œ mip-NeRFì˜ IPE feature encoding($\\gamma$) inputìœ¼ë¡œ ì¶•ì†Œëœ ê³µê°„ì—ì„œì˜ contractí•¨ìˆ˜ ë°˜í™˜ ê°’($\\gamma(\\text{contract}(x))$)ì„ ê°ë§ˆ í•¨ìˆ˜ì— ì§‘ì–´ë„£ëŠ”ë‹¤2. êµ¬ê°„ì„ ë‚˜ëˆŒ ê´‘ì„  ê±°ë¦¬ $t$ì— ëŒ€í•œ Parameterization :  ì¼ë°˜ì ì¸ NeRFì—ì„œëŠ” uniform distributionì—ì„œ $t_n$(ê·¼ê±°ë¦¬)ê³¼ $t_f$(ì›ê±°ë¦¬)ì‚¬ì´ êµ¬ê°„ì—ì„œ ìƒ˜í”Œë§í•œ ê´‘ì„ ê±°ë¦¬ $t^c$ë¥¼ ì •ë ¬í•˜ì—¬ ì‚¬ìš©          í•˜ì§€ë§Œ, Scene parameterizationì—ì„œ NDCì²˜ëŸ¼ ì—­í• í•˜ëŠ” ì¶•ì†Œëœ ê³µê°„ì—ì„œì˜ state transition ê³¼ì •ìœ¼ë¡œ ì¸í•´ì„œ ì‹¤ì œë¡œëŠ” ê¹Šì´ì˜ ì—­ìˆ˜(disparity)ê°„ê²©ìœ¼ë¡œ ê· ì¼í•˜ê²Œ ìƒ˜í”Œë“¤ì´ ë°°ì¹˜ëœë‹¤.      ì´ ìƒí™©ì€ ì¹´ë©”ë¼ ë°©í–¥ì´ í•˜ë‚˜ë§Œ ì¡´ì¬í•˜ëŠ” unbounded sceneì—ëŠ” ì í•©í•˜ê² ì§€ë§Œ, ë°©í–¥ì´ ë‹¤ë¥¸ ëª¨ë“  ë·°ì— ëŒ€í•œ unbounded sceneì„ ë³µì›í•˜ëŠ” ë°ì—ëŠ” ì í•©í•˜ì§€ ì•Šë‹¤            ìœ í´ë¦¬ë””ì•ˆ ê³µê°„ì— ìˆëŠ” ray distance $t$ë¥¼ â€œnormalizedâ€ ray distance $s$ë¡œ ì—­ë§¤í•‘í•´ì£¼ëŠ” ê²ƒì´ í•„ìš” :\\[s \\triangleq \\frac{g(t) - g(t_n)}{g(t_f) - g(t_n)}, \\quad t \\triangleq g^{-1} \\left( s \\cdot g(t_f) + (1 - s) \\cdot g(t_n) \\right), \\quad (11)\\]          ì—¬ê¸°ì„œ gëŠ” ê°€ì—­(ì •ê·œí™”ëœ ê°’ì„ ì¶œë ¥í•´ì£¼ëŠ”)í•¨ìˆ˜      2. Coarse-to-Fine Online Distillation  Mip-NeRF :          MLPì—ì„œ â€œcoarseâ€ ray interval $t^c$ì„ ì‚¬ìš©í•˜ì—¬ í•œ ë²ˆ í‰ê°€í•˜ê³ , ë‹¤ì‹œ â€œfineâ€ ray interval $t^f$ë¥¼ ì‚¬ìš©í•˜ì—¬ í‰ê°€ë˜ë©°, ë‘ ìˆ˜ì¤€ ëª¨ë‘ì—ì„œ image reconsruction lossë¥¼ ì‚¬ìš©        Mip-NeRF 360 :          ë‘ ê°€ì§€ì˜ MLPí•™ìŠµ(NeRF MLP $\\Theta_{NeRF}$ &amp; Proposal MLP $\\Theta_{prop}$)                  NeRF MLP $\\Theta_{NeRF}$ : ê¸°ì¡´ Mip-NeRFì—ì„œ ì‚¬ìš©í•˜ë˜ MLP          Proposal MLP $\\Theta_{prop}$ : volumetric densityë§Œ ì—ì¸¡í•¨, colorëŠ” ì˜ˆì¸¡í•˜ì§€ ì•ŠìŒ                          outputì˜ volumetric densityê°€ ë‹¤ì‹œ weight vector $\\hat{w}$ë¡œ ë°˜í™˜ë¨              proposal ê°€ì¤‘ì¹˜ $\\hat{w}$ëŠ” ìì²´ ê°€ì¤‘ì¹˜ ë²¡í„° $w$ë¥¼ ì˜ˆì¸¡í•˜ëŠ” NeRF MLPì— ì œê³µë˜ëŠ” $s$-ê°„ê²©ì„ ìƒ˜í”Œë§í•˜ëŠ” ë° ì‚¬ìš©              ì…ë ¥ ì´ë¯¸ì§€ë¥¼ ì¬í˜„í•˜ë„ë¡ í•™ìŠµë˜ì§€ ì•Šê³  ëŒ€ì‹  NeRF MLPì— ì˜í•´ ìƒì„±ëœ ê°€ì¤‘ì¹˜ $w$ë¥¼ ì œí•œí•˜ë„ë¡ í•™ìŠµ              ë‘ MLP ëª¨ë‘ ëœë¤í•˜ê²Œ ì´ˆê¸°í™”ë˜ê³  ê³µë™ìœ¼ë¡œ í•™ìŠµë˜ë¯€ë¡œ ì´ supervisionì€ NeRF MLP ì§€ì‹ì„ proposal MLPì— ëŒ€í•œ ì¼ì¢…ì˜ â€œonline distillationâ€ë¡œ ìƒê°í•¨                                          proposal MLP $(\\hat{\\mathrm{t}}, \\hat{\\mathrm{w}})$ì™€ NeRF MLP $(\\mathrm{t},\\mathrm{w})$ì˜ íˆìŠ¤í† ê·¸ë¨ì´ ì¼ê´€ë˜ë„ë¡ ì¥ë ¤í•˜ëŠ” loss functionì´ í•„ìš”                  ì´ ë•Œ ë‘ íˆìŠ¤í† ê·¸ë¨ xì¶• binê¸¸ì´ê°€ ë™ì¼í•  í•„ìš”ê°€ ì—†ìŒ, ì•„ë‹ˆ ì˜¤íˆë ¤ ë‹¬ë¼ì ¸ì•¼ proposal MLPê°€ ì˜ í•™ìŠµë˜ì—ˆë‹¤ëŠ” ê·¼ê±°ì„          ë”°ë¼ì„œ binì´ ë‹¤ë¥¼ ë•Œì˜ íˆìŠ¤í† ê·¸ë¨ ìœ ì‚¬ì„±ì„ í‰ê°€í•˜ëŠ” í†µê³„ì  ë°©ë²•ë¡  ì—°êµ¬ë“¤ì´ ìƒëŒ€ì ìœ¼ë¡œ ë¶€ì¡±í•˜ê¸° ë•Œë¬¸ì— ê½¤ ì–´ë ¤ìš´ ë¬¸ì œì„                          $\\text{bound}(\\hat{\\mathrm{t}}, \\hat{\\mathrm{w}}, T) = \\sum\\limits_{j : T \\cap \\hat{T}_j neq \\emptyset}\\hat{w_j} .$              ë§Œì•½ ë‘ íˆìŠ¤í† ê·¸ë¨ì´ ì„œë¡œ ì¼ê´€(ì¼ì¹˜)í•˜ë©´, $(\\mathrm{t},\\mathrm{w})$ì˜ ëª¨ë“  ê°„ê²© $(T_i, w_i)$ì— ëŒ€í•´ $w_i \\leq \\text{bound}((\\hat{\\mathrm{t}}, \\hat{\\mathrm{w}}), T_i)$ê°€ ëª¨ë“  êµ¬ê°„ì— ëŒ€í•´ ì„±ë¦½í•´ì•¼ í•¨              ì´ ì„±ì§ˆ ì´ìš©í•´ì„œ $L_{prop}$ ì„¤ê³„ :            \\[\\begin{align} \\mathcal{L}_{\\text{prop}} (\\mathbf{t}, \\mathbf{w}, \\hat{\\mathbf{t}}, \\hat{\\mathbf{w}}) =\\sum_i \\frac{1}{w_i} \\max \\left( 0, w_i - \\text{bound} (\\hat{\\mathbf{t}}, \\hat{\\mathbf{w}}, T_i) \\right)^2,\\end{align}\\]                                  3. Regularization for Interval-Based Models (Depth distortion loss)  â€œfloaterâ€ê°€ ë°œìƒí•˜ê±°ë‚˜ â€œback-ground collapseâ€ê°€ ë°œìƒí•˜ëŠ” ê²°í•¨ ìƒí™©ì—ì„œ ì˜ í•´ê²°í•  ìˆ˜ ìˆìŒ      ì •ê·œí™”ëœ ray distance $s$ì™€ blending weight $w$ê°„ì˜ step functionìœ¼ë¡œ êµ¬ì„±ë¨\\[\\begin{align}  \\mathcal{L}_{\\text{dist}} (\\mathbf{s}, \\mathbf{w}) =\\int_{-\\infty}^{\\infty} \\int_{-\\infty}^{\\infty} w_{\\mathbf{s}}(u) w_{\\mathbf{s}}(v) |u - v| \\, d u \\, d v, \\end{align}\\]          where, w_s(u)ëŠ” $u$ì—ì„œ $(s,w)$ì— ì˜í•´ ì •ì˜ëœ step functionì— ëŒ€í•œ ë³´ê°„ì´ë‹¤.      $ w_s(u)=\\sum_i w_i ğŸ™[s_i,s_{i+1})(u) $            ìœ„ ì ë¶„ ì‹ì€ ì •ì˜ëŠ” ì§ê´€ì ì´ì§€ë§Œ ê³„ì‚°í•˜ëŠ” ê²ƒì´ ì–´ë µê¸° ë•Œë¬¸ì—, ì•„ë˜ ì‹ìœ¼ë¡œ rewrittení•  ìˆ˜ ìˆìŒ\\[\\begin{align} \\mathcal{L}_{\\text{dist}} (\\mathbf{s}, \\mathbf{w}) =  \\sum_{i,j} w_i w_j \\left| \\frac{s_i + s_{i+1}}{2} - \\frac{s_j + s_{j+1}}{2} \\right|  + \\frac{1}{3} \\sum_i w_i^2 (s_{i+1} - s_i)  \\end{align}\\]    ì²« ë²ˆì§¸ í•­ì€ ëª¨ë“  intervalì— ëŒ€í•œ midpointì‚¬ì´ì˜ weighted distances ìµœì†Œí™” term, ë‘ ë²ˆì§¸ í•­ì€ ê°ê°ì˜ intervalì— ëŒ€í•œ weighted sizeë¥¼ ìµœì†Œí™”í•˜ëŠ” í…€ì´ë‹¤.ëŠë‚€ì   ì´ì „ì— ë‚˜ì˜¨ ëª¨ë¸ë¡œ Mip-NeRF(ICLR 2021)ê°€ ìˆëŠ”ë° ray tracing based volume renderingì´ ì•„ë‹ˆë¼, â€œConeâ€ tracingí•œë‹¤ëŠ” ì ì´ ê°€ì¥ í° íŠ¹ì§•ì¸ ê²ƒë§Œ ì•Œê³  ì½ì€ ìƒíƒœë¼ ëª¨ë“  ìˆ˜ì‹ì´ ë§¤ë„ëŸ½ê²Œ ì´í•´ë˜ì§„ ì•Šì•˜ë‹¤  NeRFìì²´ë¥¼ ì œëŒ€ë¡œ ê³µë¶€í•´ë³¸ì ì´ ì—†ì—ˆì–´ì„œ ì˜ ì´í•´ê°€ ì•ˆë˜ëŠ” ê²Œ ë§ê¸´ í•˜ëŠ”ë° ì–¸ì  ê°€ ê³µë¶€ ê¸‰í•œê±´ ì•„ë‹˜"
  },
  
  {
    "title": "Gaussian Opacity Fields, SIGGRAPH Asia 2024",
    "url": "/posts/GOF/",
    "categories": "Paper Review",
    "tags": "Surface reconstruction, Graphics",
    "date": "2025-02-08 11:30:00 +0900",
    





    
    "snippet": "Gaussian Opacity Fields: Efficient Adaptive Surface Reconstruction in Unbounded ScenesAbstract  ë³¸ ë…¼ë¬¸ì˜ GOFëŠ” ray-tracing ê¸°ë°˜ 3D Gaussianì˜ volume renderingì„ í†µí•´ ì§ì ‘ì ìœ¼ë¡œ geometryë¥¼ ì¶”ì¶œí•˜ì—¬ level-setì„ í™•ì¸í•˜ëŠ” ê³¼ì •ì„ ...",
    "content": "Gaussian Opacity Fields: Efficient Adaptive Surface Reconstruction in Unbounded ScenesAbstract  ë³¸ ë…¼ë¬¸ì˜ GOFëŠ” ray-tracing ê¸°ë°˜ 3D Gaussianì˜ volume renderingì„ í†µí•´ ì§ì ‘ì ìœ¼ë¡œ geometryë¥¼ ì¶”ì¶œí•˜ì—¬ level-setì„ í™•ì¸í•˜ëŠ” ê³¼ì •ì„ ìˆ˜í–‰          SuGaRì²˜ëŸ¼ í¬ì•„ì†¡ ì¬ê±´(Poisson reconstruction)ì„ ì‚¬ìš©í•˜ì§€ ì•Šìœ¼ë©°, 2DGSì™€ GS2Meshì²˜ëŸ¼ TSDF fusionì„ ì‚¬ìš©í•˜ì§€ ì•ŠìŒ      surface normalì„ ray-Gaussian intersection plane(rayì™€ êµì°¨í•˜ëŠ” ê°€ìš°ì‹œì•ˆì˜ í‰ë©´)ì„ ì´ìš©í•˜ì—¬ ê·¼ì‚¬í•¨      geometry extraction methodë¡œëŠ” â€œMarching Tetrahedraâ€œ(ë§ˆì¹­ íë¸Œì•„ë‹ˆê³  ë§ˆì¹­-ì‚¬ë©´ì²´)ë°©ë²• ì‚¬ìš©í•¨      Introduction  NeRF ê¸°ë°˜          SDF(Signed Distance Function)ì™€ occupancy ë„¤íŠ¸ì›Œí¬ë¥¼ ì‚¬ìš©í•˜ì—¬ surface reconstructionì„ ìˆ˜í–‰      foreground object ë³µì›ì—ë§Œ ì œí•œì ì„      e.g., Neuralangelo      NeRFâ€™s opacity Fieldë¡œë¶€í„° real-time rendering ë° surface ì¶”ì¶œí•˜ëŠ” ì—°êµ¬ë„ ì§„í–‰ë¨ (e.g., Binary Opacity Grids-BOG)        Marching Cube Algorithm          mesh extraction Algorithm      surface reconìì²´ë³´ë‹¤ NVS(novel view synthesis)ì— ì´ˆì ì´ ë§ì¶°ì ¸ì„œ ê³ ì•ˆëœ ë°©ë²•ì´ë¼, ì •ê·œí™” í…€ì´ ë¶€ì¡±í•˜ê³  ë‹¤ì†Œ noisyí•¨        3DGS ê¸°ë°˜          SuGaR : surface-align Gaussianë“¤ì„ ì–»ê¸° ìœ„í•´ ì •ê·œí™” í…€ ì¶”ê°€ &amp; depth mapìœ¼ë¡œë¶€í„° Poisson reconstructionê¸°ë°˜ ë©”ì‰¬ì¶”ì¶œ      2DGS : image planeì— projectedëœ 2D Gaussianì˜ propertyì´ìš© + TSDF fusionì´ìš©      - ì´ ë°©ë²•ë“¤ì€ surface reconstruction ì„±ëŠ¥ í–¥ìƒì´ ë˜ì—ˆì§€ë§Œ, fine-grained geometryë¥¼ ì¡ëŠ” ê²ƒê³¼ background regionì„ ë³µì›í•˜ëŠ” ê²ƒì—ëŠ” ì•„ì§ ë¶€ì¡±í•˜ë‹¤.        Poisson-Reconstruction ê³¼ TSDF Fusionì˜ ê²°í•¨          í¬ì•„ì†¡ ì¬ê±´ì€ Gaussian primitiveì— ëŒ€í•œ opacity(íˆ¬ëª…ë„), scale, rendered depthê°™ì€ ì •ë³´ë“¤ì„ ê³ ë ¤í•˜ì§€ ì•ŠìŒ      TSDF fusionì€ ì–‡ì€ êµ¬ì¡°ë¬¼ì´ë‚˜ Unbounded sceneì— ëŒ€í•œ ë³µì› ì„±ëŠ¥ì´ ì •í™•í•˜ì§€ ì•ŠìŒ      Contributions  Volume Rendering ì¸¡ë©´ :          projection-based ë°©ë²•ì´ë‘ ë‹¤ë¥´ê²Œ, explicití•œ ray-Gaussian intersectionì„ ì´ìš©í•´ì„œ volume renderingí•  ë•Œì˜ Gaussianì˜ â€œê¸°ì—¬ë„â€ë¥¼ ê²°ì •í•¨      ì´ëŸ¬í•œ ray-tracing ìœ¼ë¡œë¶€í„° ê¸°ë°˜ëœ formulaëŠ” rayìƒì— ì¡´ì¬í•˜ëŠ” ëª¨ë“  Pointì— ì¡´ì¬í•˜ëŠ” Gaussianì˜ opacityë¥¼ ê²°ì •ì§“ê²Œ í•  ìˆ˜ ìˆìŒ //  (ì—¬ê¸°ê¹Œì§„ RaDe-GSì—ì„œë„ ray-tracing intersectionì„ ì´ìš©í•´ì„œ rasterized methodë¡œ ê°€ìš°ì‹œì•ˆì˜ primitiveë“¤ì„ í’€ì–´ëƒˆë‹¤ëŠ” ì ì´ ìœ ì‚¬í•˜ë‹¤.)      â€œview independenceâ€ = ëª¨ë“  ë·°ì— ëŒ€í•´ opacityê°€ ìµœì†Œì¸ ê°’ì„ ì·¨í•˜ë©´ viewì— ëŒ€í•´ ë…ë¦½ì ì´ë‹¤(??) : opacity fieldê°€ Poisitionì— ëŒ€í•œ í•¨ìˆ˜ë¥¼ ì „ì ìœ¼ë¡œ ì±…ì„ì§        Surface normal ì¸¡ë©´ :          rayì™€ Gausssianì‚¬ì´ì˜ intersection plane(êµì°¨ í‰ë©´)ì— ëŒ€í•œ normal        Surface extraction technique(alogirthm) ì¸¡ë©´ :          poisson recon, marching cubeì™€ëŠ” ë‹¤ë¥¸ ë©”ì†Œë“œ      tetrahedra-grids(ë‹¤ë©´ì²´ ê·¸ë¦¬ë“œ)ì— ê¸°ë°˜í•œ â€˜Marching tetrahedraâ€™ ì‚¬ìš©í•¨                  3D Gaussian primitiveì¤‘ì—ì„œ 3D bounding boxì˜ ì½”ë„ˆê°’ê³¼ ì¤‘ì•™ê°’ì„ ì´ìš©í•˜ì—¬ ë‹¤ë©´ì²´ ë©”ì‰¬ì˜ ê¼­ì§“ì  ì§‘í•©ìœ¼ë¡œ êµ¬ì„±í•˜ëŠ” ë°©ë²•ì„                    Methods1. Modeling  Given multiple posed + calibrated images      3D sceneì€ 3D Gaussianì˜ ì§‘í•© $\\mathcal{G}_k$ì€ ì¤‘ì‹¬ì  $\\mathrm{p}_k$, scaling matrix $\\mathrm{S}_k$, ê·¸ë¦¬ê³  rotation matrix $\\mathrm{R}_k$ìœ¼ë¡œ íŒŒë¼ë¯¸í„°í™”ë˜ê³ , ì´ëŠ” ì¿¼í„°ë‹ˆì–¸(quaternion, ë³µì†Œìˆ˜ì˜ í™•ì¥í˜•íƒœ)ë¡œ ì•„ë˜ì²˜ëŸ¼ ë‚˜íƒ€ë‚´ì§ :\\[\\begin{align} \\mathcal{G}_k(\\mathrm{x}) = e^{-\\frac{1}{2}(\\mathrm{x}-\\mathrm{p}_k)\\Sigma_k^{-1}(\\mathrm{x}-\\mathrm{p}_k)} \\end{align}\\]  Ray Gaussian Intersection  rayì™€ Gaussianì´ ë§Œë‚˜ëŠ” intersectionì˜ ì •ë„ë¥¼ ì´ìš©í•œë‹¤.  RaDe-GSì— ìˆë˜ ë‚´ìš©ì´ë‘ ê²¹ì¹¨, ê·¸ë˜ì„œ ì–´ë–¤ ë¶€ë¶„ì´ ì–´ë””ì„œë¶€í„° ë…¸ë²¨í‹°ì¸ì§€ ë¶„ê°„ì´ ì•ˆëœë‹¤(ray tracing chapter advanced verê³µë¶€ ë” í•´ì•¼ê² ë‹¤)  â€œray intersectionâ€ : 1-D Gaussian Functionì´ ìµœëŒ€í™”ë˜ëŠ” ì           point $\\mathrm{x} = \\mathrm{o} + t\\mathrm{r}$ , rì€ ray direction, tëŠ” rayì˜ depth            local coordinate systemìœ¼ë¡œ point $\\mathrm{x}$ ì„ ë³€í™˜ &amp; scaleë¡œ normalizeí•œë‹¤\\[\\begin{align} \\mathrm{o}_g &amp;= \\mathrm{S}_k^{-1}\\mathrm{R}_k(\\mathrm{o}-\\mathrm{p}_k) \\\\               \\mathrm{r}_g &amp;= \\mathrm{S}_k^{-1}\\mathrm{R}_k\\mathrm{r} \\\\               \\mathrm{x}_g &amp;= \\mathrm{o}_g + t\\mathrm{r}_g \\end{align}\\]        ray ì„  ìƒì— ì¡´ì¬í•˜ëŠ” depth tì—ì„œì˜ 1-D Gaussian value :\\[\\begin{align} \\mathcal{G}_k(\\mathrm{t}) = e^{-\\frac{1}{2}\\mathrm{x}_g^T\\mathrm{x}_g} = e^{-\\frac{1}{2}(\\mathrm{r}_g^T\\mathrm{r}_gt^2 + 2\\mathrm{o}_g^T\\mathrm{r}_gt + \\mathrm{o}_g^T\\mathrm{o}_g)} \\end{align}\\]        ìœ„ì˜ ê°€ìš°ì‹œì•ˆ valueê°€ tì— ëŒ€í•œ quadratic term(ì´ì°¨í˜•ì‹)ì„ í¬í•¨í•˜ê³  ìˆìœ¼ë¯€ë¡œ ë¯¸ë¶„ ì´ìš©í•´ì„œ ìµœëŒ€í™”ë˜ëŠ” ì§€ì ì˜ $t^*$ì„ ìœ ë„ ê°€ëŠ¥(RaDe-GS reviewì—ì„œ í–ˆìŒ) :\\[\\begin{align} t^* = -\\frac{B}{A} \\end{align}\\]    where, $A =\\mathrm{r}_g^T\\mathrm{r}_g ,$  $B = \\mathrm{o}_g^T\\mathrm{r}_g$ ì´ë ‡ê²Œ êµ¬í•œ ray-Gaussian intersectionì€ world spaceì—ì„œ ë°”ë¡œ(directly) êµ¬í•´ì§ˆ ìˆ˜ ìˆë‹¤ëŠ” ì ì—ì„œ surface normalêµ¬í•  ë•Œë„ ìœ ìš©í•œ íŠ¹ì„±ì„        â€œGaussian $\\mathcal{G}_k$ì— ëŒ€í•œ ê¸°ì—¬ë„(Contribution) $\\mathcal{E}$ ë¼ê³  ì •ì˜í•¨ :\\[\\begin{align} \\mathcal{E}(\\mathcal{G}_k, \\mathrm{o}, \\mathrm{r}) = \\mathcal{G}_k^{1D}(t^*) \\end{align}\\]      Volume Rendering      camera rayìƒì˜ pixel colorëŠ” Gaussian primitiveì˜ depthë¡œ ì •ë ¬ëœ ìˆœì„œì— ë”°ë¼ì„œ alpha blendingì„ í†µí•´ ë Œë”ë§ë¨\\[\\begin{align} \\mathrm{c}(\\mathrm{o}, \\mathrm{r}) = \\sum\\limits_{k=1}^{K}\\mathrm{c}_k\\alpha_k\\mathcal{E}(\\mathcal{G}_k, \\mathrm{o}, \\mathrm{r})\\prod\\limits_{i=1}^{k-1}(1 - \\alpha_j \\mathcal{E}(\\mathcal{G}_j, \\mathrm{o}, \\mathrm{r})) \\end{align}\\]  where, $c_k$ : view-dependent color modeled with spherical harmonics and $\\alpha_k$ : additional parameter that influences the opacity of Gaussian $k$.      (tile-based rendering process) ì¦‰ standard 3DGSì™€ ê°™ì´ depth ê¸°ë°˜ alpha blendingë°©ì‹ìœ¼ë¡œ pixel color renderingí•˜ëŠ” ë°©ì‹ ì‚¬ìš©í•¨      2. Gaussian Opacity Fields      projected 2D GaussianëŒ€ì‹  ray-Gaussian Intersectionì„ ì´ìš©í•˜ê¸° ë•Œë¬¸ì—, rayì— ì¡´ì¬í•˜ëŠ” ì–´ë– í•œ ì ì´ë¼ë„ opacity value($\\mathrm{O}_k(\\mathcal{G}_k, \\mathrm{o}, \\mathrm{r}, t)$)ë¥¼ êµ¬í•  ìˆ˜ ìˆë‹¤ëŠ” ì¥ì \\[\\begin{align} \\mathrm{O}_k(\\mathcal{G}_k, \\mathrm{o}, \\mathrm{r}, t) = \\begin{cases}\\mathcal{G}_k^{1D}(t) &amp; \\text{if } t \\leq t^* \\\\\\mathcal{G}_k^{1D}(t^*),  &amp; \\text{if } t  &gt; t^*\\end{cases} \\end{align}\\]        ì´ë ‡ê²Œ êµ¬í•´ì§„ rayìƒì˜ opacity valueë¥¼ ì´ìš©í•˜ì—¬ volume rendering processëŠ” ì•„ë˜ ìˆ˜ì‹ì²˜ëŸ¼ ì´ë£¨ì–´ì§ :\\[\\begin{align} \\mathrm{O}(\\mathrm{o}, \\mathrm{r}, t) = \\sum\\limits_{k=1}^{K}\\alpha_k \\mathrm{O}_k(\\mathcal{G}_k, \\mathrm{o}, \\mathrm{r}, t) \\prod\\limits_{i=1}^{k-1}(1 - \\alpha_j \\mathrm{O}_k(\\mathcal{G}_k, \\mathrm{o}, \\mathrm{r}, t)) \\end{align}\\]        ì´ ë•Œ 3D pointëŠ” ëª¨ë“  ë·°ì—ì„œ ë³´ì—¬ì§€ëŠ”ë°, 3D point $\\mathrm{x}$ì˜ opacityëŠ” ì´ ëª¨ë“  í•™ìŠµ ë·°ì— ëŒ€í•œ opacity value ì¤‘ ìµœì†Ÿê°’ìœ¼ë¡œ ì •ì˜í•œë‹¤.\\[\\begin{align} \\mathrm{O(\\mathrm{x})} = \\min\\limits_{(o, r)}\\mathrm{O}(\\mathrm{o}, \\mathrm{r}, t) \\end{align}\\]        ìœ„ì˜ $\\mathrm{O(\\mathrm{x})}$ë¥¼ \"Gaussian Opacity Fields(GOF)\"ë¼ê³  ì–¸ê¸‰í•œë‹¤.          ì´ GOFë¥¼ ì´ìš©í•˜ë©´ poisson reconstructionì´ë‚˜ TSDF Fusionì—†ì´ë„ surfaceë¥¼ ë°”ë¡œ ì¶”ì¶œí•  ìˆ˜ ìˆë‹¤.      by identifying their level sets      ë³¸ ë…¼ë¬¸ì—ì„œ ë§Œë“  Tetrahedral ê¸°ë°˜ ë©”ì‰¬ ì¶”ì¶œ ë°©ë²•ê³¼ ì—°ê²°ë˜ì–´ ì‚¬ìš©í•¨, 4.ì„¹ì…˜ì— ë” ìì„¸íˆ ìˆ˜ë¡      3. Optimization  ê¸°ë³¸ì ìœ¼ë¡œ 2DGSì—ì„œ ì–¸ê¸‰ëœ lossë“¤(depth distortion, normal consistency loss)ë¥¼ ì´ìš©í•˜ì—¬ ì •ê·œí™”í•¨3.1. Depth Distortion loss  Mip-NeRF360 ë…¼ë¬¸ì—ì„œ ì²˜ìŒìœ¼ë¡œ ì œì•ˆë¨      ray-Gaussian intersectionë“¤ì´ ë” ë°€ì§‘ë˜ê³  ì§‘ì¤‘ë˜ê²Œ í•´ì£¼ëŠ” ê²ƒ ì´‰ì§„í•¨\\[\\begin{align} L_d = \\sum\\limits_{i,j}w_iw_j|t_i-t_j| \\end{align}\\]                  where $w_i$ : ië²ˆì§¸ ê°€ìš°ì‹œì•ˆì˜ blending weight \\[w_i = \\alpha_k\\mathcal{E}(\\mathcal{G}_k, \\mathrm{o}, \\mathrm{r})\\prod_{j=1}^{k-1}(1-\\alpha_j\\mathcal{E}(\\mathcal{G}_k, \\mathrm{o}, \\mathrm{r}))\\]              í•˜ì§€ë§Œ, depth distortionë§Œìœ¼ë¡œëŠ” Gaussianë§ˆë‹¤ì˜ ê±°ë¦¬ì™€ weightë¥¼ ëª¨ë‘ ê°ì†Œì‹œí‚¤ëŠ” ì •ê·œí™” í…€ì´ê¸° ë•Œë¬¸ì—, ì´ê²ƒì€ alpha valuesê°€ ì¦ê°€í•˜ëŠ” ê²°ê³¼ê°€ ì´ˆë˜ë  ìˆ˜ ìˆë‹¤.          alpha blendingì—ì„œ ì„ì—¬ì§€ëŠ” ì´ˆê¸° ê°€ìš°ì‹œì•ˆì˜ alpha valueê°’ì´ ì§€ë‚˜ì¹˜ê²Œ í¬ë‹¤ë©´, ê³¼ì¥ëœ Gaussianì´ ì´ˆë˜ë˜ê³  ì´ê²ƒì€ \"floater\"ë¥¼ ìœ ë°œí•˜ëŠ” ì›ì¸ì´ ë¨        ë”°ë¼ì„œ, ê°€ìš°ì‹œì•ˆë¼ë¦¬ì˜ ê±°ë¦¬ì— ëŒ€í•´ì„œë§Œ ìµœì†Œí™”í•˜ê³ , blending weight $w_i$ëŠ” ìµœì†Œí™” í…€ì—ì„œ ë—´ì–´ëƒ„3.2. Normal Consistency loss\\[\\begin{align} L_n = \\sum\\limits_{i}w_i(1-n_i^TN) \\end{align}\\]  2DGSì˜ normal consistency regularizationì„ ë°”ë¡œ 3D normalë¡œ ì ìš©í•˜ëŠ” ê²ƒì´ ì±Œë¦°ì§€  2D Gaussianì˜ gradientëŠ” í•­ìƒ íˆ¬ì˜ëœ image planeì—ì„œì˜ ê°€ìš°ì‹œì•ˆ ì¤‘ì‹¬ì (center, mu)ì—ì„œ ë°”ê¹¥ìª½ìœ¼ë¡œ ìœ„ì¹˜í•˜ëŠ” íŠ¹ì„±ì´ ìˆìŒ          íˆ¬ì˜ëœ 2D ê°€ìš°ì‹œì•ˆ ì¤‘ì‹¬ì—ì„œ í”½ì…€ ì¢Œí‘œê¹Œì§€ì˜ ë°©í–¥ì´ ë‹¤ë¥´ë©´, ë‘ ê°œì˜ ë‹¤ë¥¸ í”½ì…€ì—ì„œ ë Œë”ë§ëœ ë…¸ë©€ì€ ì„œë¡œ ë‹¤ë¥´ê²Œ ë‚˜íƒ€ë‚œë‹¤ =&gt; ì •í™•ì„±ì´ ë–¨ì–´ì§€ëŠ” ëª¨í˜¸í•¨ì´ ë°œìƒí•¨            ì´ ë¬¸ì œ ì™„í™”ë¥¼ ìœ„í•´ì„œ 3D Gaussianì˜ normalì„ ray direction rì´ ì£¼ì–´ì¡Œì„ ë•Œ, intersection planeì˜ normalë¡œ ì •ì˜í•¨.      Final Loss\\[\\begin{align} L = L_c + \\alpha L_d + \\beta L_n \\end{align}\\]  where,  $L_c$ : RGB reconstruction loss with combining $L_1$ with the D-SSIm term4. Surface Extraction (Marching-Tetrahedral)  tetrahedral(ë‹¤ë©´ì²´) ê¸°ë°˜ìœ¼ë¡œ ê·¸ë¦¬ë“œë¥¼ ìƒì„±í•˜ì—¬ ë©”ì‰¬ ì¶”ì¶œí•˜ëŠ” ì•Œê³ ë¦¬ì¦˜ì„ ì´ìš©  í•™ìŠµ ì´í›„, surface ë˜ëŠ” triangle mesh extraction ë‹¨ê³„  ì „í†µì ì¸ ë©”ì‰¬ ì¶”ì¶œ ë°©ë²•ë“¤ì€ DTU datasetì²˜ëŸ¼ ì‘ì€ ë¬¼ì²´ë‹¨ìœ„ì˜ ë² ê²½ì—†ëŠ” foreground object(regions of interest)ì˜ì—­ì€ ë¹„êµì  ì˜ ë˜ì§€ë§Œ, large-scaleì˜ unbounded datasetì—ëŠ” ì„±ëŠ¥ ì¢‹ê²Œ ë‚˜ì˜¤ëŠ”ê²Œ ì–´ë ¤ìš´ ë¬¸ì œì˜€ìŒ          dense evaluationìœ¼ë¡œ í•˜ëŠ” ê¸°ì¡´ ë°©ë²• -&gt; ê·¸ë¦¬ë“œì˜ í•´ìƒë„ì— ë”°ë¼ computation complexityê°€ ì¦ê°€í•œë‹¤ëŠ” ì ì—ì„œ, large scale meshì— ì í•©í•˜ì§€ ì•Šê³  ì‹œê°„ì´ ë§¤ìš° ë§ì´ ê±¸ë¦¬ëŠ” ë¬¸ì œ        ë³¸ ë…¼ë¬¸ì—ì„œ novel method ì†Œê°œ : â€œTetrahedral gridâ€ë¥¼ ì´ìš©í•œ â€œMarching Tetrahedraâ€œ4.1. Tetrahedral Grids Generation  3D Gaussianì˜ primitiveì—ì„œ positionê³¼ scale valueëŠ” surfaceì˜ ì¡´ì¬ì— ìœ ì˜ë¯¸í•œ ì •ë³´ë¥¼ ì£¼ëŠ” ì—­í•   ê°ê°ì˜ ê°€ìš°ì‹œì•ˆì„ ê°ì‹¸ëŠ” 3D Bounding boxë¥¼ ì •ì˜ :          3d boxì˜ ì¤‘ì‹¬ì ì—ì„œ ê°€ì¥ ë†’ì€ opacityë¥¼ ê°€ì§€ê³ , ê°€ì¥ìë¦¬ ê¼­ì§“ì (corner)ì—ì„œ ê°€ì¥ ì‘ì€ opacityë¥¼ ê°€ì§„ë‹¤.      ì´ opacityìì²´ë¥¼ ê³ ë ¤í•˜ëŠ” ê²ƒì€ ì•„ë‹˜, ë‚®ì€ opacity valueë¥¼ ê°€ì§€ëŠ” ê°€ìš°ì‹œì•ˆì„ filter out(pruning)í•˜ê¸´ í•¨        bboxì˜ centerì™€ cornerë“¤ë¡œ [ì‚¬ë©´ì²´ ê·¸ë¦¬ë“œ]ë¥¼ ìƒì„±í•¨          CGAL ë¼ì´ë¸ŒëŸ¬ë¦¬ ì´ìš©(Tetra-NeRFì—ì„œ ì˜ê°ë°›ì•„ ì‚¬ìš©)í•´ì„œ [Delaunay triangulation] ìˆ˜í–‰      ë“¤ë¡œë„¤ ì‚¼ê°ë²•ì´ë€? : 2D í‰ë©´ì˜ ì  ì§‘í•©ì„ ì‚¼ê°í˜•ë“¤ë¡œ ì—°ê²°í•˜ëŠ” ë°©ë²• ì¤‘ í•˜ë‚˜ë¡œ, ì‚¼ê°í˜•ì˜ ë‚´ì ‘ì›ì˜ ì› ì•ˆì— ë‹¤ë¥¸ ì ì´ í¬í•¨ë˜ì§€ ì•Šë„ë¡ ì‚¼ê°í˜•ì„ êµ¬ì„±í•˜ëŠ” ê¸°ë²•      refer : ë“¤ë¡œë„¤-ì‚¼ê°ë¶„í•         ìƒì„±ëœ ì‚¬ë©´ì²´ ê·¸ë¦¬ë“œì—ì„œ filtering stepì„ í†µí•´ ê²¹ì³ì§€ì§€ ì•Šì€ ê°€ìš°ì‹œì•ˆê³¼ ì—°ê²°ëœ edgeë¥¼ í¬í•¨í•˜ëŠ” ì‚¬ë©´ì²´ cellë“¤ì„ ì œê±°í•¨          ê²¸ì³ì§€ì§€ ì•Šì€ ê°€ìš°ì‹œì•ˆìœ¼ë¡œ íŒë³„í•˜ëŠ” ê³¼ì • : ì‚¬ë©´ì²´ì˜ edge ê¸¸ì´ê°€ ê·¸ê²ƒì— ëŒ€í•œ maximum scale(í‰ê· ì—ì„œ 3Ïƒ(í‘œì¤€í¸ì°¨)ì˜ ìµœëŒ€ ë²”ìœ„ê¹Œì§€ í™•ì¥ëœ ì°¨ì›)ì˜ í•©ì„ ì´ˆê³¼í•  ë•Œ      4.2. Efficient Opacity Evaluation  ì•ì„œ êµ¬í•´ì§„ ì‚¬ë©´ì²´ ê·¸ë¦¬ë“œì˜ vertices ì¦‰, ê¼­ì§“ì ì—ì„œì˜ opacityë¥¼ ì¸¡ì •í•˜ê¸° ìœ„í•´, 3DGSì˜ rasterized methodì²˜ëŸ¼ tile-based evaluation algorithm ì„¤ê³„í•¨          ê¼­ì§“ì ë“¤ì„ image spaceë¡œ projectioní•œ í›„, íƒ€ì¼ë¡œ ìª¼ê°œì ¸ìˆì„ ë•Œ ê·¸ ëŒ€ì‘ë˜ëŠ” íƒ€ì¼ IDë¥¼ í™•ì¸í•œë‹¤.      ê°ê°ì˜ íƒ€ì¼ì— ëŒ€í•´ì„œ projectionìœ¼ë¡œ ë“¤ì–´ê°€ì ¸ìˆëŠ” point ë¦¬ìŠ¤íŠ¸ë¥¼ ì–»ì„ ìˆ˜ ìˆë‹¤. ê·¸ í›„ì— ì ë“¤ì„ ë‹¤ì‹œ pixel spaceë¡œ projectioní•´ì„œ ëŒ€ì‘ë˜ì–´ ë–¨ì–´ì§€ëŠ” pixelì„ êµ¬í•  ìˆ˜ ìˆë‹¤.      ë”°ë¼ì„œ í•´ë‹¹ pixelì— ê¸°ì—¬í•˜ëŠ” ê°€ìš°ì‹œì•ˆë“¤ì„ ì¶”ì í•  ìˆ˜ ìˆê³  ì´ ê³¼ì •ì€ ëª¨ë“  í•™ìŠµ ì´ë¯¸ì§€ë“¤ì— ëŒ€í•´ì„œ ìˆ˜í–‰ëœë‹¤.      ê·¸ í›„, pre-filteredëœ(pruning) Opcaityë¥¼ ê°€ì§€ëŠ” ê°€ìš°ì‹œì•ˆë“¤ì¤‘ì—ì„œ minimumê°’ì„ Tetrahedral grid ê¼­ì§“ì ì˜ opacityë¡œ ì‚¼ëŠ”ë‹¤.      4.3. Binary Search of level Set  traingle mesh ì¶”ì¶œ ë‹¨ê³„ via. Marching Tetrahedral method  â€œmarching tetrahedralâ€ :           ì„ í˜• ë³´ê°„(linear interpolation)ì´ level setêµ¬ë¶„í•˜ëŠ” ê²ƒì— ì˜ì¡´í•˜ê¸° ë•Œë¬¸ì—, Opacity Fieldë¼ëŠ” ê°€ìš°ì‹œì•ˆì˜ ë¹„ì„ í˜•ì  íŠ¹ì„±ì—ëŠ” misalignë˜ì–´ì„œ ì„±ëŠ¥ì´ ë¶ˆì™„ì „í•¨      ì„ í˜• ì¶”ì •(linear assumption)ì„ ëŠ˜ë ¤ê°€ë©´ì„œ non-linearí•œ opacity fieldë¡œ level setì„ ì •í™•í•˜ê²Œ í™•ì¸      Binary Search(ì´ì§„ íƒìƒ‰)ì•Œê³ ë¦¬ì¦˜ìœ¼ë¡œ êµ¬í˜„í•¨                  8 iteration binary searchí•œ ê²ƒì´ dense evaluation 256ë²ˆ í•œ ê²ƒì´ë‘ ê°™ì€ ì‹œë®¬ë ˆì´ì…˜ íš¨ê³¼ë‚˜ì˜¤ëŠ” ê²ƒ í™•ì¸í•¨                            Experiments  custom CUDA kernel  DTU, TnTÂ ê°™ì€ foreground simple datasetë¿ë§Œ ì•„ë‹ˆë¼ Mip-Nerf360 datasetì²˜ëŸ¼ unboundedëœ sceneì—ì„œ backgroundì˜ì—­ê¹Œì§€ ë³µì› ì˜ ë¨  ëŠë‚€ì  &amp; Future work  ray-Gaussian Intersection(GOF)ê³¼ ray-tracing based rasterized method(RaDe-GS)ì— ë‚˜ì˜¤ëŠ” ê³µí†µ ë°©ë²•ë¡ ì´ ì–´ë””ì„œë¶€í„° ì‹œì‘ëœ ì´ë¡ ì¸ì§€ ë ˆí¼ëŸ°ìŠ¤ ì°¾ê¸°  (mip-nerf 360) ë…¼ë¬¸ì—ì„œ depth distortion loss ë¶€ë¶„ ì¤‘ì‹¬ìœ¼ë¡œ ì½ê¸° (ì™„)  ë“¤ë¡œë„¤ ì‚¼ê°ë¶„í•  Â«Â ëŒ€ì¶© í›‘ê¸°ë§Œ í•´ì„  ì´í•´ì•ˆë¨  í¬ì•„ì†¡ ì¬ê±´, ë§ˆì¹­íë¸Œ// ë§ˆì¹­-ì‚¬ë©´ì²´ ê°™ì€ ë©”ì‰¬ì¶”ì¶œ ì•Œê³ ë¦¬ì¦˜ë§Œ ì •ë¦¬ë¼ìˆëŠ” ë‚´ìš© ì–´ë””ì—†ëŠ”ì§€ í™•ì¸"
  },
  
  {
    "title": "RaDe-GS, arXiv preprint",
    "url": "/posts/RaDe-GS/",
    "categories": "Paper Review",
    "tags": "Surface reconstruction, stereo vision, Graphics",
    "date": "2025-02-07 19:34:00 +0900",
    





    
    "snippet": "RaDe-GS: Rasterizing Depth in Gaussian Splatting  ì¸ìš©ë„ ë§ì´ ëê³  ë‚˜ì˜¨ì§€ ê½¤ ëëŠ”ë° ì•„ì§ ì•„ì¹´ì´ë¸Œì´ê¸¸ë˜ ì•„ë§ˆ cvpr2025 ì´ë²ˆì— ë‚´ì§€ ì•Šì•˜ì„ê¹Œ ì‹¶ì€ë°â€¦  GOF(Gaussian Opacity Fields, SIGGRAPH Asia 2024) ë‹¤ìŒì— ì½ê¸°Abstract  3DGSì˜ ì´ì‚°ì ì´ê³  ë¹„êµ¬ì¡°ì ì¸ íŠ¹ì„±ë•Œ...",
    "content": "RaDe-GS: Rasterizing Depth in Gaussian Splatting  ì¸ìš©ë„ ë§ì´ ëê³  ë‚˜ì˜¨ì§€ ê½¤ ëëŠ”ë° ì•„ì§ ì•„ì¹´ì´ë¸Œì´ê¸¸ë˜ ì•„ë§ˆ cvpr2025 ì´ë²ˆì— ë‚´ì§€ ì•Šì•˜ì„ê¹Œ ì‹¶ì€ë°â€¦  GOF(Gaussian Opacity Fields, SIGGRAPH Asia 2024) ë‹¤ìŒì— ì½ê¸°Abstract  3DGSì˜ ì´ì‚°ì ì´ê³  ë¹„êµ¬ì¡°ì ì¸ íŠ¹ì„±ë•Œë¬¸ì— shape accuracê°€ ë–¨ì–´ì§€ëŠ” ë¬¸ì œ ìˆìŒ  ìµœê·¼ ê´€ë ¨ ì—°êµ¬ ì¤‘, 2D-GSì—ì„œëŠ” shape reconstruction ì„±ëŠ¥ì„ ì˜¬ë¦¬ê¸° ìœ„í•´, Gaussian primitivesë“¤ì„ ì´ìš©í–ˆì§€ë§Œ ì´ê²ƒì€ ë Œë”ë§ í€„ë¦¬í‹°ë‘ ê³„ì‚°ì ì¸ íš¨ìœ¨ì„±ì€ ê°ì†Œì‹œí‚¤ëŠ” íš¨ê³¼ê°€ ìˆìŒ  ê·¸ë˜ì„œ ë³¸ ë…¼ë¬¸ì—ì„œëŠ” rasterized ì ‘ê·¼ë²•ì„ í†µí•´, 3DGSì˜ depth mapê³¼ surface normal mapì„ ë Œë”ë§í•˜ëŠ” Shape reconstruction ì •í™•ì„± ë³´ì¥  DTU datasetì—ì„œ NeuraLangeloì™€ ë¹„êµí–ˆì„ ë•Œ CD(Chamfer Distance) errorê°€ ì¢‹ê²Œ ë‚˜ì˜´Introduction  multi-view ì´ë¯¸ì§€ë“¤ë¡œë¶€í„° 3D Reconstructioní•˜ëŠ” íƒœìŠ¤í¬ì—ì„œëŠ” multi-view stereo ì•Œê³ ë¦¬ì¦˜ì„ í†µí•´ depth mapì„ ì–»ëŠ” ê²ƒì„ í¬í•¨í•œë‹¤.  ì´ë ‡ê²Œ ì–»ì–´ì§„ depth mapìœ¼ë¡œ ì™„ì „í•œ triangle meshë¥¼ ë§Œë“œëŠ” ëª¨ë¸ë¡œ í†µí•©ë˜ëŠ” ê²ƒì´ ê°€ëŠ¥í•˜ë‹¤      ì „í†µì ì¸ image-based ëª¨ë¸ë§ ì ‘ê·¼ë²•ì€ ê½¤ ì •í™•í•œ ê²°ê³¼ë¡œ depth map rendering + mesh reconì´ ê°€ëŠ¥í•˜ë‚˜, ê³ ì§ˆì ìœ¼ë¡œ ë¹›ë‚˜ëŠ” í‘œë©´(shiny surface)ì´ë‚˜ reflectiveí•œ ìœ ë¦¬ê°™ì€ transparent surfaceì—ì„œ íŠ¹íˆë‚˜ robustnessê°€ ë–¨ì–´ì§€ëŠ” í•œê³„ì ì´ ì¡´ì¬í•œë‹¤.    explicití•œ 3DGSì—ì„œ surface ì˜ ë½‘ì•„ë‚´ëŠ” ê²ƒì€ ì–´ë ¤ìš´ ë¬¸ì œì„          2DGS[Huang et al.2024] : PSNR ìˆ˜ì¹˜ ì¤„ì–´ë“¦      GOF[Yu et al.2024] : ray-tracing ê¸°ë°˜ ë°©ë²•ì„ í†µí•´ ê´‘ì„ (light ray)ì— ë”°ë¥¸ Gaussian opacityë¥¼ ê³„ì‚°í•˜ëŠ” ë°©ë²•ìœ¼ë¡œ high-quality surfaceë¥¼ ë½‘ì•„ëƒ„      Contributions  ë³¸ ë…¼ë¬¸ì—ì„œëŠ” raasterized ê¸°ë°˜ ë°©ë²•ìœ¼ë¡œ general Gaussian Splattingì—ì„œ ì •í™•í•œ depth mapì„ ì–»ëŠ” ê²ƒì„ ë°œì „ì‹œì¼°ë‹¤.  standard GSë§Œí¼ì˜ computation efficiencyë¥¼ ê°€ì§„ë‹¤.  DTU datasetì—ì„œ shape reconstruction accuracyë¥¼ Chamfer Distance 0.69mm ë‹¬ì„±, 5ë¶„ì˜ í•™ìŠµì‹œê°„          ì´ ìˆ˜ì¹˜ëŠ” implicití•œ representation ê¸°ë°˜ ëª¨ë¸ì¸ NeuraLangelo(0.69mm)ì™€ ë¹„ìŠ·      GS-based ë°©ë²•ë¡ ë“¤(sotaëŠ” GOF)ì—ì„œëŠ” ë‹¹ì—°íˆ ì„±ëŠ¥ ë” ì¢‹ì•˜ìŒ      Methods  sceneì— splattingëœ Gaussianë“¤ê³¼ ê´‘ì„ ì— ì˜í•œ intersection pointë¥¼ í†µí•œ ì†”ë£¨ì…˜ì„ ì°¾ìŒ  ğŸ’¡Key ideağŸ’¡   &gt; camera centerë¡œë¶€í„° ê°ê°ì˜ Light rayì— ì˜í•´ Gaussian valueê°€ ìµœëŒ€í™”ë˜ëŠ” ì§€ì ì´ intersection pointì´ë‹¤   &gt; intersection pointë“¤ì—ì„œ Affine-projectionì„ ì‹œí‚¤ë©´ co-planar (ë™ì¼ í‰ë©´ìƒì— ì¡´ì¬)í•˜ë‹¤   &gt; ê·¸ë¦¬ê³  ì´ intersection pointë“¤ì„ Image planeì— projection ëœ depthë¡œ ì •ì˜í•˜ì—¬ curved surfaceë¥¼ êµ¬í•  ìˆ˜ ìˆë‹¤   &gt; ë”°ë¼ì„œ, planar equationìœ¼ë¡œ projected depthë¥¼ êµ¬í•˜ëŠ”ë° ì´ê²ƒì€ rasterizationì— ì˜í•´ íš¨ìœ¨ì ìœ¼ë¡œ ê³„ì‚°ë  ìˆ˜ ìˆë‹¤.     &gt; final depth mapì€ íˆ¬ëª…ë„(translucency)ë¥¼ ê³ ë ¤í•˜ì—¬ íˆ¬ì˜ëœ Gaussianë“¤ ì¤‘ì—ì„œ ì¤‘ê°„ê°’ ê¹Šì´(median depth)ë¡œ ê³„ì‚°1. Rasterizing Depth for Gaussian Splats      Gaussian Splattingì—ì„œëŠ” ì•„ë˜ ì‚¬ì§„ì²˜ëŸ¼ Perspective camera projectionì„ Affine transformationì„ í†µí•´ ê·¼ì‚¬ì‹œì¼œì„œ ë” íš¨ìœ¨ì ì¸ renderingê°€ëŠ¥í•˜ë‹¤ëŠ” ê²ƒ ì‚¬ì „ì— ì•Œì•„ë‘ê³  ì‹œì‘        standard 3DGSì—ì„œëŠ” ì•ŒíŒŒ ë¸”ë Œë”©ì„ ìœ„í•´ì„œ image planeì— projectedëœ 2D Gaussianì˜ ì¤‘ì‹¬ì (center)ì„ depthë¡œ ì„¤ì •í•œë‹¤.          shape detail í¬ì°© ë¶ˆê°€ëŠ¥        ê·¸ëŸ¬ë¯€ë¡œ, ë³¸ ë…¼ë¬¸ì—ì„œëŠ” spatially varying depthë¥¼ rasterized methodê¸°ë°˜ ë°©ë²•ìœ¼ë¡œ ê³„ì‚°í•œë‹¤.1.1. Depth Under Perspective Projection  planar equationì„ ì–»ëŠ” ë³¸ê²©ì ì¸ ê³¼ì • ì´ì „ì—, perspective projectionìœ¼ë¡œ camera coordinateì— ëŒ€í•œ ê¸°ë³¸ conceptsë¶€í„° ë¨¼ì € ì´í•´í•´ë³´ì.          Figure 4.              ìœ„ ê·¸ë¦¼ì—ì„œ ì™¼ìª½ì˜ (a)ì—ì„œ ë³´ì—¬ì§„ ê²ƒ ì²˜ëŸ¼, camera center $\\mathrm{o}$ì™€ unit direction $\\mathrm{v}$ê°€ ì£¼ì–´ì¡Œì„ ë•Œ, ray ìƒì— $o$ë¡œë¶€í„° ê±°ë¦¬ $t$ë§Œí¼ ë–¨ì–´ì ¸ ìˆëŠ” point $\\mathrm{x}$ëŠ”, \\(\\begin{align} \\mathrm{x}= \\mathrm{o} + t\\mathrm{v} \\end{align}\\)ìœ¼ë¡œ êµ¬í•  ìˆ˜ ìˆë‹¤.        ì´ rayì— ì¡´ì¬í•˜ëŠ” Gaussian value $\\mathrm{G}^1(t)$ëŠ”,\\(\\begin{align} \\mathrm{G}^1(t)= e^{-(\\mathrm{o} + t\\mathrm{v}-\\mathrm{x}_c)^T\\Sigma^{-1}(\\mathrm{o} + t\\mathrm{v}-\\mathrm{x}_c)} \\end{align}\\)ìœ¼ë¡œ êµ¬í•  ìˆ˜ ìˆë‹¤.    ì´ ë•Œ, Gaussian valueëŠ” 1-D functionì´ê³ , ì´ ê°’ì´ ìµœëŒ€í™”ë˜ëŠ” ì§€ì ì´ 3D Gaussianê³¼ rayê°€ ë§Œë‚˜ëŠ” â€œintersection pointâ€ ë¼ê³  ì •ì˜í•œë‹¤.      ê·¸ í›„ distance $t^*$ : intersection pointì™€ camera centerê°„ì˜ ê±°ë¦¬ëŠ” ìœ„ì˜ Gaussian valueê°€ ìµœëŒ€í™”ë˜ëŠ” të¥¼ ì°¾ìœ¼ë©´ ë˜ê³  êµ¬í•œ ì‹ì€ ì•„ë˜ì²˜ëŸ¼ ë¨\\[\\begin{align} t^* = \\frac{\\mathrm{v}^T\\Sigma^{-1}(\\mathrm{x}_c - \\mathrm{o})}{\\mathrm{v}^T\\Sigma^{-1}\\mathrm{v}} \\end{align}\\]    (ìœ ë„ ê³¼ì •) :        ì´ë ‡ê²Œ ìœ ë„ëœ distance $t^*$ì´ ì˜ë¯¸í•˜ëŠ” ë°”ëŠ”, 3D Gaussianë“¤ê³¼ ê´‘ì„ ë“¤ ì§‘í•©ê°„ì˜ intersectionë“¤ì´ â€œcurved surfaceâ€(ì—°ë‘ìƒ‰ ê³¡ì„ ) ë¥¼ ë‚˜íƒ€ë‚¸ë‹¤ê³  í•´ì„í•  ìˆ˜ ìˆìŒ          different pixels have different depth values of $t^*$ and different viewing direction $\\mathrm{v}$.      1.2. Depth Under Local Affine Projection  ì´ì œ ê°€ìš°ì‹œì•ˆë§ê³ , í”½ì…€ì˜ depthë¥¼ â€œlocal affine projectionâ€ìœ¼ë¡œ êµ¬í•´ë³´ì.      ìœ„ì˜ Figure4.(b)ìƒí™© =&gt; â€œray spaceâ€ ì¢Œí‘œê³„    [1.2.1. Transformation from Camera to Ray space]          (a) ì˜ íŒŒë€ ì  $\\mathrm{x} = (x, y, z)^T$ ê°€ (b)ì˜ íŒŒë€ ì  $\\mathrm{u} = (u,v,t)$ ë¡œ ë³€í™˜      $(u,v,t)$ì—ì„œ $(u,v)$ëŠ” image plane coordinate(ì´ë¯¸ì§€ í‰ë©´ì—ì„œì˜ ì¢Œí‘œê³„)ì´ê³ , $(t)$ëŠ” pointì™€ $uv-plane$ì‚¬ì´ì˜ ê±°ë¦¬ë¥¼ ë‚˜íƒ€ë‚¸ë‹¤      ì¦‰, $t=\\sqrt{x^2+y^2+z^2}$              ray spaceì—ì„œ light direction $\\mathrm{v}$ ëŠ” ë‹¨ìœ„ê³ ìœ ë²¡í„° $(0,0,1)^T$ì„                    ê°€ìš°ì‹œì•ˆë“¤ë„ ray spaceë¡œ ë³€í™˜ë˜ì–´ì•¼ í•˜ëŠ”ë°, ë³€í™˜ëœ Gaussian Functionì€ ì•„ë˜ì™€ ê°™ë‹¤\\[\\begin{align} \\mathrm{G}'(\\mathrm{u}) = e^{-(\\mathrm{u}-\\mathrm{u_c})^T\\Sigma^{'-1}(\\mathrm{u}-\\mathrm{u_c})} \\end{align}\\]        Gaussian center $\\mathrm{u_c}=(u_c, v_c, t_c)^T$ë¡œ, (b)ê·¸ë¦¼ì—ì„œ ë¹¨ê°„ ì                   [1.2.2. Intersection in Ray Space]    ê¸°ë³¸ ê³¼ì •ì€ perpective projectionë•Œì™€ ê°™ìŒ     1) ray space ìƒì— ì¡´ì¬í•˜ëŠ” point $\\mathrm{u}$Â  :\\[\\begin{align} \\mathrm{u} = \\mathrm{u_o} + t\\mathrm{v'} \\end{align}\\]    where , $\\mathrm{u_o} = (u,v,0)^T \\quad and \\quad \\mathrm{vâ€™} = (0,0,1)^T $    2) 1D Gaussian function $\\mathrm{G^{â€˜1}}(t)$ :\\[\\begin{align} \\mathrm{G^{'1}}(t)=  e^{-(\\mathrm{u_o} + t\\mathrm{v'}-\\mathrm{u_c})^T\\Sigma^{'-1}(\\mathrm{u_o} + t\\mathrm{v'}-\\mathrm{u_c})} \\end{align}\\]    3) maximum pointê°€ ìœ„ì¹˜í•œ distance $t^*$ :\\[\\begin{align} t^* = \\frac{\\mathrm{v'}^T\\Sigma^{'-1}(\\mathrm{u}_c - \\mathrm{u_o})}{\\mathrm{v'}^T\\Sigma^{'-1}\\mathrm{v'}} \\end{align}\\]    ê°„ë‹¨í•˜ê²Œ í‘œí˜„í•˜ê¸° ìœ„í•´ì„œ $(\\mathrm{u}_c - \\mathrm{u_o})$ ë²¡í„° ë¹¼ê³  ë‚˜ë¨¸ì§€ í•­ë“¤ì„ $\\hat{q}$ë¡œ ì •ì˜í•˜ì—¬ ê°„ë‹¨í•˜ê²Œ ì•„ë˜ì²˜ëŸ¼ í‘œí˜„ :\\[\\begin{align} t^* = \\hat{q}(\\mathrm{u}_c - \\mathrm{u_o}) \\end{align}\\]        [1.2.3. Depth of Intersection]    1) $t$ëŠ” 3D point $x$ì™€ camera center $o$ì‚¬ì´ì˜ ê±°ë¦¬ì´ë¯€ë¡œ xì— ëŒ€í•œ ê¹Šì´ëŠ”, ê°„ë‹¨í•˜ê²Œ ì‚¼ê°ë¹„ ì„±ì§ˆì„ ì´ìš©í•´ì„œ (a)ê·¸ë¦¼ì˜ $z^*$ì„ ì•„ë˜ì²˜ëŸ¼ êµ¬í•  ìˆ˜ ìˆë‹¤:\\[\\begin{align} d = cos\\theta t^* \\end{align}\\]    2) (b), affine projectionì¸ ìƒí™©ì— ëŒ€ì…í•´ì„œ depthêµ¬í•˜ë©´,\\[\\begin{align} d = cos\\theta_c t^* = \\frac{x_c}{t_c}t^* = \\frac{x_c}{t_c}\\hat{q}(\\mathrm{u}_c - \\mathrm{u_o}) = \\hat{p}(\\mathrm{u}_c - \\mathrm{u_o})    \\end{align}\\]    ì—¬ê¸°ì„œ $\\hat{p} = \\frac{z_c}{t_c}\\hat{q}$ë¡œ ì •ì˜    3) ì´ì–´ì„œ ìœ„ì˜ ì‹ì„ ì•„ë˜ì²˜ëŸ¼ ë‚˜íƒ€ë‚¼ ìˆ˜ ìˆëŠ”ë°,\\[\\begin{align} d = \\hat{p}(\\mathrm{u}_c - \\mathrm{u_o}) =  \\hat{p}\\begin{pmatrix} u_c - u \\\\ v_c-v \\\\ t_c \\end{pmatrix} = \\hat{p}\\begin{pmatrix} 0 \\\\ 0 \\\\ t_c \\end{pmatrix} + \\hat{p}\\begin{pmatrix} \\Delta{u} \\\\ \\Delta{v} \\\\ 0 \\end{pmatrix}.  \\end{align}\\]    4) ìœ„ì˜ ìµœì¢… ë¶„í•´ëœ ì‹ ì¤‘, ì²« ë²ˆì§¸ í•­ $\\begin{pmatrix} 0 \\ 0 \\ t_c \\end{pmatrix}$ì— ëŒ€í•œ ì„±ì§ˆ :\\[\\begin{align}       \\hat{p} \\begin{pmatrix} 0 \\\\ 0 \\\\ t_c \\end{pmatrix}       &amp;= \\frac{z_c}{t_c} \\hat{q} \\begin{pmatrix} 0 \\\\ 0 \\\\ t_c \\end{pmatrix} \\\\      &amp;= \\frac{z_c}{t_c} \\frac{\\mathrm{v^{'T}}\\Sigma^{'-1}}{\\mathrm{v^{'T}}\\Sigma^{'-1}\\mathrm{v'}} \\begin{pmatrix} 0 \\\\ 0 \\\\ t_c \\end{pmatrix} \\\\      &amp;= \\frac{z_c}{t_c} \\frac{\\mathrm{v^{'T}}\\Sigma^{'-1}}{\\mathrm{v^{'T}}\\Sigma^{'-1}\\mathrm{v'}} (t_c\\mathrm{v'}) \\\\      &amp;= \\frac{z_c}{t_c} \\frac{\\mathrm{v^{'T}}\\Sigma^{'-1}\\mathrm{v'}}{\\mathrm{v^{'T}}\\Sigma^{'-1}\\mathrm{v'}} (t_c) \\\\      &amp;= z_c .  \\end{align}\\]       5) ë‘ ë²ˆì§¸ í•­ì˜ $\\hat{p}$ ëŠ” $p$ ë¡œ ê·¼ì‚¬ë¨          ë”°ë¼ì„œ, ìµœì¢…ì ìœ¼ë¡œ depthë¥¼ êµ¬í•˜ëŠ” rasterized methodìˆ˜ì‹ìœ¼ë¡œ ìœ ë„ëœë‹¤.       Recall. $d = z_c + p(\\begin{pmatrix} \\Delta{u} \\ \\Delta{v} \\end{pmatrix})^T$      2. Rasterizing Normal for Gaussian Splats  ëŠë‚€ì   ì´ ë¶„ì•¼ì—ì„œëŠ” ì‚´ì§ ë­ ë°”ê¿¨ë”ë‹ˆ ì†Œíƒ€ë‹¤ ì´ëŸ°ê±´ ì ˆëŒ€ ì•ˆë¨¹íˆê² ë‹¤  ì™„ì „íˆê¹Œì§„ ì•„ë‹ˆì—¬ë„ ì ë‹¹íˆ ì°½ì˜ì ìœ¼ë¡œ ë©”ì†Œë“œë¥¼ ì§œì•¼ë˜ê² êµ¬ë‚˜ë¼ëŠ” ìƒê°ì´ ë“¤ì—ˆë‹¤. ì´ëŸ° ë©´ì´ ì¬ë°Œì§€ë§Œì„œë„ ë‹¤ì†Œ ë§‰ë§‰í•˜ê¸´ í•˜ë‹¤  Affine aprroximation projectionê¸°ë°˜ìœ¼ë¡œ spatial varying depth êµ¬í•˜ëŠ” ë°©ë²•ì´ ì°½ì˜ì ì´ë‹¤  2DGSì—ì„œ ì“´ loss ê°€ì ¸ë‹¤ ì“´ ê±´ ì•„ì‰¬ìš´ë° ì´ê±°ê¹Œì§€ ìƒˆë¡œ ì§°ìœ¼ë©´ ê± ì”¨ê·¸ë¼í”„ ì˜¤ë„ ì°ì—ˆì„ ê²ƒ ê°™ë‹¤  ì´ê±´ ì–´ì…‰ ì™œ ì•ˆë˜ì§€          GOF(SIGGRAPH Asia 2024)ê°€ ì‘ë…„ 9ì›”ì— ë‚˜ì™€ì„œ sotaì¸ ê²ƒ ê°™ë‹¤. ì´ì–´ì„œ ì´ê±° ì½ê¸°      "
  },
  
  {
    "title": "Graphics-Ch6. Transformation Matrices",
    "url": "/posts/ch6-Transformation_Matrices/",
    "categories": "Graphics, Study",
    "tags": "Graphics",
    "date": "2025-02-07 13:04:00 +0900",
    





    
    "snippet": "Introduction  Chapter 5ëŠ” ì„ í˜•ëŒ€ìˆ˜í•™(Linear Algebra)ì´ë¼ ì•„ëŠ” ë‚´ìš©ì´ ë§ì•„ì„œ ì •ë¦¬ ìƒëµ  Transformation matrixëŠ” ì™œ í•„ìš”í•œê°€ : Rotation, Translation, Scaling, Projectionê°™ì€ ê¸°í•˜í•™ì  ë³€í™˜ì—ì„œ í–‰ë ¬ ê³±ì„ í†µí•´ ë³€í™˜ë˜ëŠ”ë° ì´ë•Œ ë³€í™˜ í–‰ë ¬ì´ í•„ìš”í•¨1. 2D Linear Tr...",
    "content": "Introduction  Chapter 5ëŠ” ì„ í˜•ëŒ€ìˆ˜í•™(Linear Algebra)ì´ë¼ ì•„ëŠ” ë‚´ìš©ì´ ë§ì•„ì„œ ì •ë¦¬ ìƒëµ  Transformation matrixëŠ” ì™œ í•„ìš”í•œê°€ : Rotation, Translation, Scaling, Projectionê°™ì€ ê¸°í•˜í•™ì  ë³€í™˜ì—ì„œ í–‰ë ¬ ê³±ì„ í†µí•´ ë³€í™˜ë˜ëŠ”ë° ì´ë•Œ ë³€í™˜ í–‰ë ¬ì´ í•„ìš”í•¨1. 2D Linear Transformations      2D vectorë¥¼ 2x2 í–‰ë ¬ë¡œ ë³€í™˜í•˜ëŠ” ê³¼ì •ì€ ì•„ë˜ì²˜ëŸ¼ ì „ê°œë¨ : \\[\\begin{bmatrix} a_{11} &amp; a_{12} \\\\ a_{21} &amp; a_{22} \\end{bmatrix}  \\begin{bmatrix} x \\\\ y \\end{bmatrix} = \\begin{bmatrix} a_{11}x &amp; a_{12}y \\\\ a_{21}x &amp; a_{22}y \\end{bmatrix}\\]        ì—¬ê¸°ì„œ, ë²¡í„° $(x y)^T$ì— ê³±í•´ì§€ëŠ” í–‰ë ¬ $A$ë¥¼ ë³€í™˜í–‰ë ¬ì´ë¼ê³  í•œë‹¤  1.1. 2D Scaling\\[\\begin{align} scale(s_x, s_y) = \\begin{bmatrix} s_x &amp; 0 \\\\ 0 &amp; s_y \\end{bmatrix} \\end{align}\\]=&gt; Cartesian componentsì™€ ê²°í•©ë˜ë©´ ì•„ë˜ì™€ ê°™ì´ ì „ê°œë¨ \\[\\begin{bmatrix} s_x &amp; 0 \\\\ 0 &amp; s_y \\end{bmatrix}  \\begin{bmatrix} x \\\\ y\\end{bmatrix} = \\begin{bmatrix} s_xx \\\\ s_yy \\end{bmatrix}\\]1.2. Shearing  ë¬¼ì²´ì— í‰í–‰í•œ ë°©í–¥ìœ¼ë¡œ í˜ì´ ê°€í•´ì ¸ ë³€í˜•ë˜ëŠ” í˜„ìƒ      ì–¼ë§Œí¼($=s$ë§Œí¼) xë˜ëŠ” yë°©í–¥ìœ¼ë¡œ ë¬¼ì²´ë¥¼ ë°€ ê±´ì§€\\[shear-x(s) = \\begin{bmatrix} 1 &amp; s \\\\ 0 &amp; 1 \\end{bmatrix} , shear-y(s) = \\begin{bmatrix} 1 &amp; 0 \\\\ s &amp; 1 \\end{bmatrix}\\]        ë§Œì•½, ì‹œê³„ ë°©í–¥ìœ¼ë¡œ ê°ë„ $\\phi$ë§Œí¼ íšŒì „ì‹œí‚¤ëŠ” shear transformation matrix :\\(\\begin{bmatrix} 1 &amp; tan\\phi \\\\ 0 &amp; 1 \\end{bmatrix}\\)    ë§Œì•½, ë°˜ì‹œê³„ ë°©í–¥ìœ¼ë¡œ ê°ë„ $\\phi$ë§Œí¼ íšŒì „ì‹œí‚¤ëŠ” shear transformation matrix :\\(\\begin{bmatrix} 1 &amp; 0 \\\\ tan\\phi &amp; 1 \\end{bmatrix}\\)1.3. Rotationvector $\\mathrm{a}$ê°€ xì¶•ìœ¼ë¡œë¶€í„° ê°ë„ $\\alpha$ë§Œí¼ ë–¨ì–´ì§„ ê¸¸ì´ê°€ rì¸ ë²¡í„°ë¼ëŠ” ìƒí™© ê°€ì • ë°˜ì‹œê³„ë°©í–¥(counterclockwise)ìœ¼ë¡œ ë²¡í„° aë¥¼ íšŒì „ì‹œí‚¨ ë²¡í„°ë¥¼ $\\mathrm{b}$ë¼ê³  ë‘ì.   $$ \\begin{align} \\mathrm{a} = (x_a, y_a) , \\mathrm{b} = (x_b, y_b) \\end{align} $$  $$ \\begin{align} x_a = rcos\\alpha \\\\ y_a = rsin\\alpha \\end{align} $$    $$ \\begin{align} x_b = rcos(\\alpha+\\phi)=rcos\\alpha cos\\phi - rsin\\alpha sin\\phi \\\\ y_b = rsin(\\alpha+\\phi) = rsin\\alpha cos\\phi + rcos\\alpha sin\\phi \\end{align} $$  ìœ„ ì‹ì—ì„œ, $x_a =rcos\\alpha$ ê·¸ë¦¬ê³  $y_a = rsin\\alpha$ ë¥¼ ëŒ€ì…í•˜ë©´ ì•„ë˜ì²˜ëŸ¼ ì •ë¦¬ëœë‹¤. \\[\\begin{align} x_b = x_a cos\\phi - y_a sin\\phi \\\\ y_b = x_bcos\\phi + x_a sin\\phi \\end{align}\\]ë”°ë¼ì„œ, vector $\\mathrm{a}$ì—ì„œ vector $\\mathrm{b}$ë¡œ ê°€ëŠ” Rotation matrix termì€ ì•„ë˜ì™€ ê°™ë‹¤ :\\[\\begin{align} rotate(\\phi) = \\begin{bmatrix} cos\\phi &amp; -sin\\phi \\\\ sin\\phi &amp; cos\\phi \\end{bmatrix} \\end{align}\\]  ê° í–‰ì— ëŒ€í•œ ì›ì†Œ norm $(sin^2\\phi + cos^2\\phi = 1)$ ì´ê¸° ë•Œë¬¸ì—, í–‰ë“¤ì€ ì„œë¡œ ì§êµí•œë‹¤(orthogonal)  ë”°ë¼ì„œ, Rotation matrixë¥¼ ì§êµí–‰ë ¬(orthogonal matrix)ë¡œ ë³¼ ìˆ˜ ìˆë‹¤.1.4. Reflection  ëŒ€ì¹­ì´ë™(ì¶•ì„ ê¸°ì¤€ìœ¼ë¡œ ë’¤ì§‘ëŠ” ë³€í™˜) \\[\\begin{align} reflect-y = \\begin{bmatrix}  -1 &amp; 0 \\\\ 0 &amp; 1 \\end{bmatrix}  ,\\quad reflect-x = \\begin{bmatrix}  - &amp; 0 \\\\ 0 &amp; -1 \\end{bmatrix}  \\end{align}\\]1.5. Composition and Decomposition of Transformations      ì²˜ìŒ ìƒíƒœ : 2D vector $\\mathrm{v_1}$        scale transformation $S$ ì ìš© ì´í›„, Rotation transformation $R$ì„ ì ìš©í•œë‹¤ë©´ : \\[\\begin{align} \\mathrm{v_2} = S\\mathrm{v_1}, \\quad then, \\mathrm{v_3} = R\\mathrm{v_2} \\end{align}\\]\\[\\begin{align}  \\mathrm{v_3} = R(S\\mathrm{v_1}) . \\\\ \\mathrm{v_3}=(RS)\\mathrm{v_1} \\end{align}\\]  ì²˜ëŸ¼ ë‚˜íƒ€ë‚¼ ìˆ˜ ìˆë‹¤.ë”°ë¼ì„œ, $M = RS$í–‰ë ¬ì„ ë³€í™˜ í–‰ë ¬ë¡œ ì·¨ê¸‰í•œë‹¤.  ì¤‘ìš”í•œ ê²ƒì€, ì´ëŸ¬í•œ ë³€í™˜ë“¤ì€ ì˜¤ë¥¸ìª½ ë³€í™˜ë¶€í„° ì ìš©ëœë‹¤ëŠ” ê²ƒì„ í˜¼ë™í•˜ë©´ ì•ˆë¨, ì¦‰, RSì—ì„œ scalingë¨¼ì € ì ìš©í•˜ëŠ” ì˜ë¯¸  ì´ ìˆœì„œê°€ ë°”ë€Œë©´ ê²°ê³¼ë„ ë‹¬ë¼ì§1.6. Decomposition of Transformations  Compoisitionë§ê³  ê³±í•´ì§„ ìƒíƒœì˜ ë³€í™˜ í–‰ë ¬ì„ â€œë¶„í•´â€í•˜ëŠ” ë°©ë²•  í¬ê²Œ ê³ ìœ ê°’ ë¶„í•´(Eigenvalue Deomposition) ê¸°ë°˜ê³¼ íŠ¹ì´ê°’ ë¶„í•´(Singular Value Decomposition)ê¸°ë°˜ ë°©ë²•ì´ ìˆë‹¤.1. Symmetric Eigenvalue Deomposition      í–‰ë ¬ì´ symmetric(ëŒ€ì¹­)í–‰ë ¬ì¼ ë•Œ, \\(\\mathrm{A} = \\mathrm{R}\\mathrm{S}\\mathrm{R}^T\\) ìœ¼ë¡œ ë¶„í•´ë¨      1) $\\mathrm{R}^T$ ë³€í™˜ : í–‰ë ¬ Aì˜ eigen vector(ê³ ìœ ë²¡í„°)ì¸ $\\mathrm{v_1}$ê³¼ $\\mathrm{v_2}$ë¥¼ x ë˜ëŠ” yì¶• ê¸°ë°˜ìœ¼ë¡œ íšŒì „ì‹œí‚´ 2) $\\mathrm{S}$ ë³€í™˜ : xì™€ yë¥¼ $(\\lambda_1, \\lambda_2)$ë§Œí¼ scaling ì‹œí‚´ 3) $\\mathrm{R}$ ë³€í™˜ :  $\\mathrm{v_1}$ê³¼ $\\mathrm{v_2}$ë¥¼ x ë˜ëŠ” yì¶• ê¸°ë°˜ìœ¼ë¡œ ë‹¤ì‹œ ì—­íšŒì „ì‹œí‚´   2. Singular Value Deomposition  ì „ì²´ì ìœ¼ë¡œ ê³¼ì •ì€ ê°™ìŒ, ëŒ€ì‹  ì „ì²´ ë³€í™˜í–‰ë ¬ Aê°€ ëŒ€ì¹­í–‰ë ¬ì´ ì•„ë‹˜  ê³ ìœ ê°’ ëŒ€ì‹  íŠ¹ì´ê°’ì‚¬ìš©2. 3D Linear Transformations  2D ë³€í™˜ì˜ í™•ì¥ëœ ver.3. Translation and Affine Transformations[1] ë³€í™˜ í–‰ë ¬ Mì´ ê³±í•´ì¡Œì„ ë•Œ, \\[\\begin{align} x' = m_{11}x + m_{12}y \\\\ y' = m_{21}x + m_{22}y \\end{align}\\][2] Translation ì´ ìˆì„ ë•Œ, \\[\\begin{align} x' = x + x_t \\\\ y' = y + y_t \\end{align}\\]ìœ„ì˜ ë‘ ê°€ì§€ ë³€í™˜ ì—°ì‚°ì„ í•©ì¹œ Transformation matrix Mì„ singleí•˜ê²Œ ì–´ë–»ê²Œ ë‚˜íƒ€ë‚¼ ê²ƒì¸ê°€, trick : Homogeneous coordinateì„ ì´ìš©í•¨ :  $(x \\quad y) -&gt; [x \\quad y \\quad 1]^T $\\[M = \\begin{bmatrix}  m_{11} &amp; m_{12} &amp; x_t \\\\ m_{21} &amp; m_{22} &amp; y_t \\\\ 0 &amp; 0 &amp; 1 \\end{bmatrix}\\]ì´ë ‡ê²Œ ê³±í•´ì§€ëŠ” í˜•íƒœì˜ ë³€í™˜ì„ â€œAffine Transformationâ€ ì´ë¼ê³  í•œë‹¤.â€¦ ì´ì–´ì„œ"
  },
  
  {
    "title": "Graphics-Ch4. Ray Tracing",
    "url": "/posts/ch4-Ray-Tracing/",
    "categories": "Graphics, Study",
    "tags": "Graphics",
    "date": "2025-02-04 17:34:00 +0900",
    





    
    "snippet": "Rendering  Object based Rendering          ê°ê°ì˜ objectë‹¨ìœ„ë¡œ ê³ ë ¤ë¨      ë¬¼ì²´ê°€ ì¡´ì¬í•˜ëŠ” ëª¨ë“  í”½ì…€ë“¤ì´ ì°¾ì•„ì§€ê³  ì—…ë°ì´íŠ¸ ë¨        Image based Rendering          ê°ê°ì˜ pixelë‹¨ìœ„ë¡œ ê³ ë ¤ë¨      ë¬¼ì²´ì— ì˜í–¥ì„ ì£¼ëŠ” ê° pixelë“¤ì´ ì°¾ì•„ì§€ê³  ì—…ë°ì´íŠ¸ ë¨ë‘˜ì˜ ì°¨ì´ì ì— ëŒ€í•´...",
    "content": "Rendering  Object based Rendering          ê°ê°ì˜ objectë‹¨ìœ„ë¡œ ê³ ë ¤ë¨      ë¬¼ì²´ê°€ ì¡´ì¬í•˜ëŠ” ëª¨ë“  í”½ì…€ë“¤ì´ ì°¾ì•„ì§€ê³  ì—…ë°ì´íŠ¸ ë¨        Image based Rendering          ê°ê°ì˜ pixelë‹¨ìœ„ë¡œ ê³ ë ¤ë¨      ë¬¼ì²´ì— ì˜í–¥ì„ ì£¼ëŠ” ê° pixelë“¤ì´ ì°¾ì•„ì§€ê³  ì—…ë°ì´íŠ¸ ë¨ë‘˜ì˜ ì°¨ì´ì ì— ëŒ€í•´ì„œëŠ” ch8ì—ì„œ ë” ìì„¸í•˜ê²Œ ë‹¤ë£¬ë‹¤      Ray Tracingì´ë€  3D Sceneì„ ë Œë”ë§í•˜ëŠ”ë°ì— ì‚¬ìš©ë˜ëŠ” image-order ì•Œê³ ë¦¬ì¦˜  object-order renderingì—ì„œ ì‚¬ìš©ë˜ì–´ì§€ëŠ” ìˆ˜í•™ì  ë°©ë²•1. Basic Ray-Tracing Algorithm  imageìƒì˜ Pixelì—ì„œ ray tracingì„ í–ˆì„ ë•Œ ë³´ì—¬ì§€ëŠ” ë¬¼ì²´ë¥¼ ì°¾ëŠ” ê²ƒì´ ëª©í‘œ  ê°ê°ì˜ í”½ì…€ì€ ë‹¤ë¥¸ ë°©í–¥ì„ â€œë°”ë¼ë³¸ë‹¤â€          ì´ ë³´ì—¬ì§€ëŠ” ë¬¼ì²´ë“¤ì€ ëª¨ë‘ viewing ray ìƒì— ì¡´ì¬í•œë‹¤        ì¹´ë©”ë¼ì— ê°€ì¥ ê°€ê¹ê²Œ ì¡´ì¬í•˜ëŠ” viewing rayì— ëŒ€í•´ êµì°¨í•˜ê³  ìˆëŠ” íŠ¹ì • Objectë¥¼ ì°¾ëŠ” ê²ƒì´ ëª©í‘œ      ê·¸ ë¬¼ì²´ê°€ ì°¾ì•„ì§€ë©´, shading ê³„ì‚°ì„ í†µí•´ intersection point, surface normal, ê·¸ë¦¬ê³  ë‹¤ë¥¸ ì •ë³´ë“¤ì„ êµ¬í•´ì„œ pixel colorë¥¼ ê²°ì •í•  ìˆ˜ ìˆìŒ    Basic Ray Tracerì˜ ì„¸ ê°€ì§€ íë¦„ :          Ray Generation : Camera geometryì— ê¸°ë°˜í•˜ì—¬, originê³¼ ê° í”½ì…€ë§ˆë‹¤ vieweing rayì˜ directionì„ êµ¬í•˜ëŠ” ê²ƒ      Ray Intersection : viewing rayì™€ êµì°¨í•˜ëŠ” ê°€ì¥ ê°€ê¹Œìš´ ë¬¼ì²´(Object)ë¥¼ ì°¾ëŠ” ê²ƒ      Shading : ray-intersection ê³¼ì •ì„ í†µí•´ êµ¬í•´ì§„ ê²°ê³¼ë¥¼ ê¸°ë°˜ìœ¼ë¡œ Pixel colorë¥¼ ê³„ì‚°í•˜ëŠ” ê²ƒ        ê¸°ë³¸ ë‚´ìš©ì„ ë‹¤ë£¬ë‹¤, ë” ë°œì „ëœ ë‚´ìš©ì€ chapter 10, 12, 13 ë“±ë“±ì— ë‚˜ì˜´2. Perspective projection  how to mapping 3D objects into 2D image plane?                            Linear perspecrive          straight line =&gt; straight line                                      Parallel projection          projection directionì— ë”°ë¼ì„œ ì›€ì§ì—¬ì§                          parallel projectionì„ í†µí•´ ë³´ì´ëŠ” ë·°ëŠ” orthographic viewë¼ê³ ë„ ë¶€ë¥¸ë‹¤          ì¥ì  : ë³€í™˜ë˜ì–´ë„ sizeë‘ shapeì€ ë³€í™”ì‹œí‚¤ì§€ ì•Šê³  ì¼ì •í•˜ê²Œ ìœ ì§€í•œë‹¤          ë‹¨ì  : ë¬¼ì²´ê°€ view pointê¸°ì¤€ìœ¼ë¡œ ë©€ì–´ì§ˆìˆ˜ë¡ ì‘ê²Œ ë³´ì¸ë‹¤ =&gt; vanishing point(ì†Œì‹¤ì )ê³¼ ì—°ê´€ ìˆìŒ                          this is because eyes and cameras donâ€™t collect light from a single viewing direction(ë·° í•˜ë‚˜ ë³´ì´ëŠ” ê²ƒìœ¼ë¡œ ëˆˆê³¼ ì¹´ë©”ë¼ì—ì„œ ëª¨ë“  ë¹›ì„ ìˆ˜ì§‘í•  ìˆ˜ ì—†ê¸° ë•Œë¬¸ì„)                                           3. Computing Viewing Rays (Ray Generation)\\(p(t) = e + t(s-e)\\)  $e$ : eye(origin point, view point)  $s$ : end point of the ray      $t$ : ì‹œê°„ ì¶•    vector $(s-e)$ ë¥¼ view directionë¡œ í•´ì„í•  ìˆ˜ ìˆë‹¤  ë§Œì¼ $t$ê°€ 0ë³´ë‹¤ ì‘ë‹¤ë©´, view behindì— ìˆë‹¤ê³  í•´ì„í•  ìˆ˜ ìˆë‹¤  â€œRay Generationâ€ ë‹¨ê³„ì˜ originê³¼ view directionì„ êµ¬í•˜ëŠ” ê³¼ì •ì—ì„œ camera frameìœ¼ë¡œ ì•Œë ¤ì§„ orthonormal ì¢Œí‘œê³„ì—ì„œ ì‹œì‘í•´ì•¼ í•œë‹¤.          orthonormal coordinate frame : ì„¸ ê°€ì§€ ê¸°ì € ë²¡í„° $u, v, w$ìœ¼ë¡œ êµ¬ì„±ë˜ì–´ ìˆìŒ      3.1. Orthographic (Parallel) Views  ì´ë¯¸ì§€ë¥¼ í‘œí˜„í•˜ëŠ” 4ê°€ì§€ ì°¨ì› = ${l, r, b, t}$[Orthographic viewing rays ë§Œë“œëŠ” ë°©ë²•]  ray Starting point(Origin)ë¡œ pixelì˜ image-plane positionì„ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•  ìˆ˜ ìˆë‹¤ = $e + u\\mathrm{u} + v\\mathrm{v}$  rayâ€™s Directionìœ¼ë¡œëŠ” view directionì„ ê°€ì ¸ë‹¤ê°€ ì‚¬ìš©í•  ìˆ˜ ìˆë‹¤ = $-w$3.2. Perspective Views  ê° í”½ì…€ë§ˆë‹¤ì˜ rayë“¤ì€ ê°™ì€ origin$(e)$ë¥¼ ê³µìœ í•¨          Image Planeì´ ë”ì´ìƒ $e$ ì ì— ìœ„ì¹˜í•˜ëŠ” ê²ƒì´ ì•„ë‹ˆë¼, ê±°ë¦¬ $d$ë§Œí¼ ë–¨ì–´ì ¸ì„œ ì¡´ì¬í•¨      $d$ : image plane distance ë˜ëŠ” focal length ë¼ê³  ë¶ˆë¦°ë‹¤        view directionì€ ëª¨ë‘ ë‹¤ë¦„          ì–´ë–»ê²Œ êµ¬í•´ì§€ëŠ”ê°€? -&gt; image planedml pixelìœ„ì¹˜ì™€ viewpointì— ì˜í•´ì„œ ì •ì˜ëœë‹¤ = $-dw + u\\mathrm{u} + v\\mathrm{v}$      4. Ray-Object Intersection  ì•ì„  Ray Generationë‹¨ê³„ë¥¼ í†µí•´ ray $\\mathrm{e} + t\\mathrm{d}$ë¥¼ ë§Œë“¤ì—ˆë‹¤ë©´, $t &gt; 0$ ì¸ êµ¬ê°„ì—ì„œ rayì™€ ì²˜ìŒìœ¼ë¡œ êµì°¨ë˜ëŠ”(ë§Œë‚˜ëŠ”) ë¬¼ì²´ë¥¼ ì°¾ëŠ” ê²ƒì´ í•„ìš”í•˜ë‹¤.  General problem = find the first intersection between the ray &amp; a surface that occurs at a $t$ in the interval $[t_0, t_1]$          sphereê³¼ traingles ë¬¼ì²´(surface)ë¥¼ ë¨¼ì € ë‹¤ë£¨ê³ , ë‹¤ë¥¸ ë‹¤ë©´ì²´ë“¤ì€ ë‹¤ìŒ ì„¹ì…˜ì— ë‹¤ë£¨ê² ìŒ      4.1. Ray-Sphere Intersectionë‹¤ìŒì˜ rayì™€ surfaceê°€ ë§Œë‚˜ëŠ” êµì°¨ì ì„ êµ¬í•œë‹¤ê³  ìƒê°í•´ë´…ì‹œë‹¤,  ray $p(t) = \\mathrm{e} + t\\mathrm{d}$  implicit surface $f(p) = 0$\\[\\begin{align} f(p(t)) = 0 \\\\  f(\\mathrm{e} + t\\mathrm{d}) = 0 \\end{align}\\]      ê·¸ë¦¬ê³  sphereëŠ” ì¤‘ì‹¬ì  $c = (x_c, y_c, z_c)$ì™€ ë°˜ì§€ë¦„ $R$ì„ ì´ìš©í•´ì„œ ì•„ë˜ì²˜ëŸ¼ implicit equationì„ ë‚˜íƒ€ë‚¼ ìˆ˜ ìˆìŒ\\(\\begin{align} (x - x_c)^2 + (y - y_c)^2 + (z - z_c)^2 - R^2 = 0 \\\\  (p-c) \\cdot (p-c) - R^2 = 0    \\end{align}\\)              ì´ vector form êµ¬ì˜ ë°©ì •ì‹ì—ì„œ pì—ë‹¤ê°€ ray $p(t)$ë¥¼ ì§‘ì–´ë„£ì–´ë„ ì‹ì´ ì„±ë¦½í•´ì•¼ í•¨, intersection pointì´ê¸° ë•Œë¬¸      $(\\mathrm{e} + t\\mathrm{d} - c) \\cdot (\\mathrm{e} + t\\mathrm{d} - c) - R^2 = 0$                  ì‹ì„ í’€ë©´ ì•„ë˜ì™€ ê°™ì´ $t$ì— ëŒ€í•œ 2ì°¨ë°©ì •ì‹ termìœ¼ë¡œ í’€ì–´ì§      $(d \\cdot d)t^2 + 2d \\cdot (e-c)t + (e-c) \\cdot (e-c) - R^2 = 0$            ê·¼ì˜ ê³µì‹ì„ ì´ìš©í•˜ì—¬ $t$ë¥¼ êµ¬í•œë‹¤\\(t = \\frac{-d \\cdot (e-c) \\pm \\sqrt{(d \\cdot (e-c))^2 - (d \\cdot d)( (e-c) \\cdot (e-c) - R^2)}}{(d \\cdot d)}\\)        ê·¼ì˜ ê³µì‹ í’€ê¸° ìœ„í•´ì„œëŠ”  íŒë³„ì‹ ($B^2 - 4AC$) ì´ê±°ë¥¼ í†µí•´ ê·¼ì´ ëª‡ ê°œ ë‚˜ì˜¤ëŠ”ì§€ ë¨¼ì € íŒë‹¨í•œë‹¤, ì´ ê°’ì´ ìŒìˆ˜ë©´ í—ˆìˆ˜ë¼ì„œ êµì°¨ì  ì—†ë‹¤ê³  íŒë‹¨í•˜ë©´ ë¨              section 2.5.4ì—ì„œ ë‹¤ë£¨ì—ˆë˜ ê²ƒì²˜ëŸ¼, point $p$ì— ìˆëŠ” normal vectorëŠ” gradientë¥¼ í†µí•´ ì•„ë˜ì²˜ëŸ¼ ê³„ì‚°í•  ìˆ˜ ìˆìŒ      \\mathrm{n} = 2(p-c)        unit normal = (p-c) / R4.2. Ray-Traingle Intersection  barycentric ì¢Œí‘œê³„ ì‚¬ìš©í•¨ =&gt; ì‚¼ê°í˜•ì„ í¬í•¨í•˜ëŠ” parametric planeì„ í‘œí˜„í•  ë•Œ ì‚¼ê°í˜•ì˜ ê¼­ì§“ì ë§Œ ì´ìš©í•˜ë©´ ë‹¤ë¥¸ storageê°€ í•„ìš”ì—†ëŠ” íš¨ìœ¨ì ì¸ ì¢Œí‘œê³„í‘œí˜„ì´ê¸° ë•Œë¬¸  parameteric surfaceì™€ rayê°„ì˜ intersection pointêµ¬í•˜ëŠ” ë°©ë²• :          Cartesian coordinate (ë°ì¹´ë¥´íŠ¸ ì¢Œí‘œê³„)ë¥¼ ì´ìš©í•œ ë‹¤ìŒ ì—°ë¦½ë°©ì •ì‹ìœ¼ë¡œ í‘¼ë‹¤=&gt; ì‹ì´ ì„¸ ê°œì´ê³ , êµ¬í•´ì•¼ ë˜ëŠ” ë¯¸ì§€ìˆ˜ë„ $(t, u, v)$ë¡œ ì„¸ ê°œì´ê¸° ë•Œë¬¸ì— ê³„ì‚° ê°€ëŠ¥      ì™¼ìª½ ê·¸ë¦¼ê³¼ ê°™ì´, $a,b,c$ ì˜ verticesë¡œ ì´ë£¨ì–´ì§„ ì‚¼ê°í˜•ì´ ì¡´ì¬í•˜ê³  ray $p(t) = \\mathrm{e} + t\\mathrm{d}$ê°€ ì¡´ì¬í•˜ëŠ” ìƒí™©ì„ ê°€ì •í•  ë•Œ, intersection pointì¸ $p$ëŠ” ê·¸ë¦¼ê³¼ ê°™ì´ ray ì—°ì¥ì„  ìœ„ì— ì¡´ì¬í•œë‹¤. $$ \\mathrm{e} + t\\mathrm{d} = \\mathrm{a} + \\beta(\\mathrm{b} - \\mathrm{a}) + \\gamma(\\mathrm{c}-\\mathrm{a}) $$ ì´ ì‹ì—ì„œ $t, \\beta, \\gamma$ë¥¼ êµ¬í•´ì•¼ í•¨ìœ„ì˜ ì‹ì„ vector formìœ¼ë¡œ ì•„ë˜ì²˜ëŸ¼ ì‹ì„ í™•ì¥í•  ìˆ˜ ìˆìŒ :\\[\\begin{align}x_e  + tx_d = x_a + \\beta(x_b - x_a) + \\gamma(x_c - x_a), \\\\y_e  + ty_d = y_a + \\beta(y_b - y_a) + \\gamma(y_c - y_a), \\\\z_e  + tz_d = z_a + \\beta(z_b - z_a) + \\gamma(z_c - z_a). \\\\\\end{align}\\]      vector formì„ í–‰ë ¬ë¡œ ë°”ê¶ˆì„œ standard linear system(ì„ í˜• ê²°í•© í˜•íƒœ)ë¡œ ì•„ë˜ì²˜ëŸ¼ ë°”ê¿” í‘œí˜„ ê°€ëŠ¥:        ê·¸ í›„, í¬ë˜ë¨¸ ê·œì¹™(Cramerâ€™s rule)ì„ ì´ìš©í•´ì„œ $t, \\beta, \\gamma$ ê°’ì„ ë„ì¶œí•  ìˆ˜ ìˆë‹¤ (ìì„¸í•œ í’€ì´ ìƒëµ ì±… ì°¸ê³ )  5. Shading  í”½ì…€ì— ëŒ€í•œ intersection point, ì¦‰ visible surfaceê°€ êµ¬í•´ì¡Œë‹¤ë©´, ê´‘ì›ì„ ê³ ë ¤í•´ì„œ pixel color(intensity) ê²°ì •í•˜ëŠ” ë‹¨ê³„  Light Reflection(ë°˜ì‚¬) ê´€ë ¨ ëª¨ë¸ë§ì„ ì‚¬ìš©í•œë‹¤          ì¤‘ìš”í•œ ë³€ìˆ˜ë“¤                  light direction $\\mathrm{l}$          view direction $\\mathrm{v}$          surface normal $\\mathrm{n}$                    5.1. Lambertian Shading  ê°€ì¥ ê°„ë‹¨í•œ shading modeling ì„ ìœ„í•œ ê°€ì •**Lambertian Shading**  : ì™¼ìª½ ê·¸ë¦¼ì—ì„œ í‘œë©´ì— ë–¨ì–´ì§€ëŠ” ê´‘ì›ìœ¼ë¡œë¶€í„° ë‚˜ì˜¤ëŠ” ë¹›ì˜ ì–‘ì€  ë¹›ì— ëŒ€í•œ ì…ì‚¬ê° $\\theta$ì— ì˜í•´ì„œë§Œ ê²°ì •ëœë‹¤. (View-Independent) ì´ë¥¼ ì´ìš©í•´ì„œ lambertian Shading modelì‹ì„ ì•„ë˜ì²˜ëŸ¼ ì„¤ê³„  $$ L = k_d I max(0, \\mathrm{n} \\cdot \\mathrm{l}) $$  $k_d$ : diffuse coefficient (ë‚œë°˜ì‚¬ ê³„ìˆ˜) ë˜ëŠ” surface color = í‘œë©´ì´ ì…ì‚¬ëœ ë¹›ì„ ì–¼ë§ˆë‚˜ ê· ì¼í•˜ê²Œ(ë‚œë°˜ì‚¬ë¡œ) ë°˜ì‚¬í•˜ëŠ”ì§€ë¥¼ ë‚˜íƒ€ë‚´ëŠ” ê³„ìˆ˜  $I$ : intensity of the light source  ì—¬ê¸°ì„œ nê³¼ lì€ í¬ê¸°ê°€ 1ì¸ ë‹¨ìœ„ë²¡í„°ì´ê¸° ë•Œë¬¸ì—, $\\mathrm{n} \\cdot \\mathrm{l}$ì„ $cos\\theta$ ë¡œ ê³„ì‚° ê°€ëŠ¥í•˜ë‹¤.          ì¦‰, ë‚´ì ì€ cosine ìœ ì‚¬ë„ë¥¼ ì˜ë¯¸í•˜ë¯€ë¡œ ë¹›ì´ ë“¤ì–´ì˜¤ëŠ” ë°©í–¥ì— ëŒ€í•´ì„œ ì–¼ë§ˆë‚˜ ë°˜ì‚¬ë˜ëŠ”ì§€ ê·¸ ê°•ë„(intensity)ê°€ ê²°ì •ëœë‹¤ëŠ” ì˜ë¯¸      =&gt; ìœ„ì˜ ëª¨ë¸ë§ ìˆ˜ì‹ì€ RGB ì±„ë„ 3ê°œì— ëŒ€í•´ì„œ ê°ê° ì ìš©ë˜ì–´ pixel valueê°€ êµ¬í•´ì§„ë‹¤  $\\mathrm{v}, \\mathrm{l}, \\mathrm{n}$ì´ ëª¨ë‘ ë‹¨ìœ„ë²¡í„°(í¬ê¸°ê°€ 1)ì¸ ê²ƒì„ ìŠì§€ ë§ê¸°!5.2. Blinn-Phong Shading  ëª¨ë“  ê´‘ì›ì´ ë‚œë°˜ì‚¬(diffuse)ë¡œë§Œ êµ¬ì„±ë˜ì§€ëŠ” ì•ŠëŠ”ë‹¤,  specular component (ì •ë°˜ì‚¬ë˜ëŠ” ì„±ì§ˆ) ë¹›ì„ ëª¨ë¸ë§í•˜ê¸° ìœ„í•œ ëª¨ë¸  Idea : $\\mathrm{v}$ë‘ $\\mathrm{l}$ ì´ surface normal $\\mathrm{n}$ì„ ê°€ë¡œì§€ë¥´ëŠ” ìƒí™©ì—ì„œ ë°˜ì‚¬ê°€ ê°€ì¥ ì˜ëœë‹¤ëŠ” ê²ƒ          mirror reflectionì´ ë°œìƒí• ë•Œ ë°˜ì‚¬ìœ¨ì´ ê°€ì¥ í¬ë‹¤.      ì˜¤ë¥¸ìª½ ê·¸ë¦¼ì²˜ëŸ¼, $\\mathrm{v}$ì™€ $\\mathrm{l}$ ê°ë„ ì¤‘ê°„ì— ìœ„ì¹˜í•œ half vector $\\mathrm{h}$ê°€ ìˆë‹¤ê³  ê°€ì •í•´ë³´ì, ì´ hê°€ surface noraml nê³¼ ê°€ê¹Œìš¸ìˆ˜ë¡, specular componentê°€ ì¦ê°€í•œë‹¤. (ë°ê¸°ê°€ ì¦ê°€) $\\mathrm{h}$ì™€ $\\mathrm{n}$ì‚¬ì´ì˜ ìœ ì‚¬ë„ëŠ” **dot product(ë‚´ì )**ìœ¼ë¡œ ìƒê°í•  ìˆ˜ ìˆë‹¤. *Phong exponent*ë¼ê³  ë¶ˆë¦¬ëŠ” power $p$ê°€ surfaceì— ëŒ€í•œ ê´‘íƒì˜ ì •ë„ë¥¼ ì¡°ì ˆí•˜ëŠ” ì—­í• ì„\\[\\begin{align}h = \\frac{\\mathrm{v} + \\mathrm{l}}{||\\mathrm{v} + \\mathrm{l}||}, \\\\L = k_d  I  max(0, \\mathrm{n} \\cdot \\mathrm{l}) + k_s I max(0, \\mathrm{n} \\cdot \\mathrm{h})^p \\\\\\end{align}\\]where, $k_s$ is the specular coefficient, or the specular color of the surface5.3. Ambient Shading      ì¡°ëª…ì´ ë„ë‹¬í•˜ì§€ ì•ŠëŠ” í‘œë©´ì—ì„œëŠ” ì™„ì „í•˜ê²Œ blackìœ¼ë¡œ ë³´ì´ê¸° ë•Œë¬¸ì—, ì´ëŸ° í˜„ìƒì„ ì¤„ì´ê¸° ìœ„í•´ì„œ constant componentë¥¼ shading modelì— ì¶”ê°€ì‹œí‚´        Full version of a simple and useful shading model(Ambident shading components &amp; Blinn-Phong model) :\\[\\begin{align}l = k_aI_a + k_dImax(0, \\mathrm{n} \\cdot \\mathrm{l}) + k_s I Max(0, \\mathrm{n} \\cdot \\mathrm{h})^n\\\\  \\end{align}\\]  "
  },
  
  {
    "title": "2D Gaussian Splatting, SIGGRAPH 2024",
    "url": "/posts/2DGS/",
    "categories": "Paper Review",
    "tags": "Geometry Reconstruction, Mesh extraction, Novel View Synthesis, Graphics",
    "date": "2025-02-03 16:34:00 +0900",
    





    
    "snippet": "Intro  3DGS : Rederingê²°ê³¼ Inconsistencyí•œ depthë°œìƒ, ì™œëƒí•˜ë©´ pixel rayì‚¬ì´ì˜ intersectionì„ í†µí•´ gaussian valueë¥¼ êµ¬í•˜ê¸° ë•Œë¬¸  2DGS : explicit ray-splat intersection ì´ìš©  surface normal ì •í™•í•˜ê²Œ ì¶”ì¶œí•˜ë©´ meshë„ ì˜ êµ¬í•´ì§          ...",
    "content": "Intro  3DGS : Rederingê²°ê³¼ Inconsistencyí•œ depthë°œìƒ, ì™œëƒí•˜ë©´ pixel rayì‚¬ì´ì˜ intersectionì„ í†µí•´ gaussian valueë¥¼ êµ¬í•˜ê¸° ë•Œë¬¸  2DGS : explicit ray-splat intersection ì´ìš©  surface normal ì •í™•í•˜ê²Œ ì¶”ì¶œí•˜ë©´ meshë„ ì˜ êµ¬í•´ì§                  depth distortion        : 2D primitivesì— ì§‘ì¤‘í•´ì„œ ë” ì¢ì€ ë²”ìœ„ì˜ rayì— ê°€ìš°ì‹œì•ˆë“¤ì´ ë¶„í¬í•˜ê²Œ í•´ì¤Œ                    normal consistency        : rendered normal mapê³¼ rendered depthì˜ gradient ì‚¬ì´ì˜ discrepancies ë¥¼ ìµœì†Œí™”í•¨              ë‘ ê°œ regularaization termì„ ì´ìš©í•´ì„œ smoother surface êµ¬í•¨  Contributions  efficient differentiable 2D Gaussian Renderer  surface reconì„ ìœ„í•œ 2ê°€ì§€ ì •ê·œí™” í…€ ì†Œê°œ (depth distortion, normal consistency)  sota Reconstruction &amp; NVS result1. Modeling  normal = the steepest change of density          better alignment with thin surfaces        input = only a sparse calibration point cloud &amp; photometric supervision2D Gaussian Explicit Properties  central point $p_k$  two principal tangential vector $t_u, t_v$      scaling vector $S = (s_u, s_v)$    primitive normal : $t_w = t_u \\times t_v$      3x3 Rotation matrix $R = [t_u, t_v, t_w]$    2D Gaussianë“¤ì€ local tangent planeì— ì •ì˜ë¨      $P(u,v) = p_k + s_ut_uu + s_vt_vv =H(u,v,1,1)^T$ â‡’  world spaceì—ì„œ ì •ì˜ëœ local tangent planeì—ì„œì˜ 2D Gaussian  point    where $H$   is the homogeneous transformation matrix, representing the geometry of the 2D Gaussian        $G($u$) = exp(-\\frac{u^2+v^2}{2})$    $point - \\mathrm{u} = (u, v)$  2. Splatting  image spaceë¡œ 2D Gaussianë“¤ì„ projectí•˜ëŠ” ê³¼ì •  affine approximation of Perspective Transformation ì´ìš©          Perspective transformationì€ í‰í–‰ì„±ì´ ì§€ì¼œì§€ì§€ ì•ŠìŒ, parallelí•œ lineë“¤ì´ ì†Œì‹¤ì (vanishing point)ì—ì„œ ë§Œë‚¨              í•œê³„ì (ì„ í–‰ ì¡°ê±´í•„ìš”) :                              center of the Gaussianì´ ì •í™•í•´ì•¼í•˜ê³ ,                                centerë¡œë¶€í„°ì˜ ê±°ë¦¬ê°€ ë©€ì–´ì§ˆìˆ˜ë¡ approximation errorê°€ ì¦ê°€í•´ì•¼í•¨                                homogeneous coordinateì„ ì´ìš©í•´ì„œ ì™„í™”ëœ í•´ê²°ë°©ë²• ì œì•ˆë¨      2D Splatì„ 2D image planeì— projectioní•œëŠ ê±´ ì¼ë°˜ì ì¸ 2D-to-2D mapping in homogeneous coordinateì´ë¼ê³  í•  ìˆ˜ ìˆë‹¤    $W$ :  transformation matrix from World space to Screen space      Screen spaceì—ì„œì˜ projected points $\\mathrm{x}$    $\\mathrm{x} = (xz, yz, z, 1)^T = WP(u,v) = WH(u,v,1,1)^T$ ë¡œ êµ¬í•´ì§    2D Gaussianë“¤ì„ rasterizeí•˜ë ¤ë©´, inverse transfomation ì¸ $M= (WH)^{-1}$ì„ ì´ìš©í•˜ëŠ” ë°©ë²•ì´ ìˆìœ¼ë‚˜, ì´ ë°©ë²•ì€  numerical instabilityí•¨ íŠ¹íˆ splatì´ line segment(viewê°€ ì˜†ë©´ì—ì„œ ë³´ì´ëŠ” ìƒí™©ì¸ ê²½ìš°, )ì—ì„œ íŠ¹íˆ ê²°í•¨ì´ ë§ìŒ      ì´ ë¬¸ì œ í•´ê²°ìœ„í•´ previous surface splatting rendering methodë“¤ì€ ë¯¸ë¦¬ ì •ì˜ëœ predefined thresholdì„ ì´ìš©í•´ì„œ  ill-conditioned transformationì„ ì´ìš©í•´ì™”ìŒ (related work)      â‡’ ëª¨ë‘ unstableí•¨, ë”°ë¼ì„œ ë³¸ ë…¼ë¬¸ì—ì„œëŠ” â€œRay-Splat Intersectionâ€ ê¸°ë°˜ ë°©ë²•ì„ ì œì•ˆ2-1. Ray-Splat Intersection      í‰í–‰í•˜ì§€ ì•Šì€ 3ê°€ì§€ í‰ë©´ (three non-parallel planes) ì—ì„œì˜ êµì ì„ ì°¾ìŒìœ¼ë¡œì¨ ray-splat intersectionì„ ìœ„ì¹˜ì‹œí‚´  (??)        image space coordinate $\\mathrm{x} = (x, y)$ê°€ ì£¼ì–´ì¡Œì„ ë•Œ,    ë‘ê°œì˜ ìˆ˜ì§ plane (x-planeê³¼ y-plane)ì˜ êµì°¨ rayë¥¼ íŒŒë¼ë¯¸í„°í™”í•œë‹¤            x - plane : normal vectorì¸ (-1, 0, 0)ê³¼ offset xë¡œ ì •ì˜ë¨    â‡’ 4D homogeneous Plane (homogeneous coordinateì„ ì´ìš©í•œ 4D ì¢Œí‘œê³„ í‘œí˜„í•œ ê°œë…)    $h_x = (-1, 0, 0, x)^T$        y - plane : normal vectorì¸ (0, -1, 0)ê³¼ offset yë¡œ ì •ì˜ë¨    â‡’ $h_y = (0, -1,  0, y)^T$        ray $\\mathrm{x} = (x,y),$  ( Image Coordinate ) ëŠ” x-planeê³¼ y-planeì‚¬ì´ì˜ êµì°¨ë˜ëŠ” lineì— ëŒ€í•œ ì¢Œí‘œë¡œ ê²°ì •    ê°ê°ì˜ planeì„ 2D Gaussianì˜ local coordinate( $uv-$coordinate system)ìœ¼ë¡œ ë³€í™˜í•´ì•¼ í•¨  pointë¡œë¶€í„° planeìœ¼ë¡œì˜ transformation matrix $M$ ì˜ ì—­í–‰ë ¬ì„ ê³±í•´ì£¼ëŠ” Inverse Transpose $M^{-1}$ì„ ìˆ˜í–‰í•´ì•¼ intersection of the x&amp;y-planeì— ëŒ€í•œ ì¢Œí‘œë¥¼ ì•„ë˜ì²˜ëŸ¼ êµ¬í•  ìˆ˜ ìˆìŒ,                  ì´ ë•Œ $M = (WH)^{-1}$, $M^{-T} =  (WH)^T$\\[\\begin{align} h_u = (WH)^Th_x   \\\\ h_v = (WH)^Th_y \\end{align}\\]        where, W : world spaceì—ì„œ screen spaceë¡œ ê°€ëŠ” ë³€í™˜ í–‰ë ¬, H : homogeneous ì¢Œí‘œê³„ë¡œ ë³€í™˜í•˜ëŠ” í–‰ë ¬              ë‘ í‰ë©´ì´ ë§Œë‚˜ëŠ” intersection point $\\mathrm{u}(\\mathrm{x})$  êµ¬í•˜ê¸°                  2D Gaussianì˜ point  : $(u, v, 1, 1)$        $h_u^i , h_v^i$ ëŠ” 4D homogeneous plane íŒŒë¼ë¯¸í„°ë“¤ ì¤‘ì—ì„œ ië²ˆì¨° íŒŒë¼ë¯¸í„°ë¥¼ ì˜ë¯¸í•¨          \\[\\begin{align}h_u \\cdot (u,v,1,1)^T = h_v \\cdot (u,v,1,1)^T = 0  \\\\ u(\\mathrm{x}) = \\frac{h_u^2h_v^4-h_u^4h_v^2}{h_u^1h_v^2-h_u^2h_v^1} \\\\ v(\\mathrm{x}) = \\frac{h_u^4h_v^1-h_u^1h_v^4}{h_u^1h_v^2-h_u^2h_v^1} \\end{align}\\]        Screen spaceì—ì„œì˜ projected points    $\\mathrm{x} = (xz, yz, z, 1)^T = WP(u,v) = WH(u,v,1,1)^T$    ì´ê±° ì‹ì„ Recallí•´ì„œ $x, y, u, v$ ë‹¤ ì•„ë‹ˆê¹Œ depth $z$ë¥¼ êµ¬í•  ìˆ˜ ìˆë‹¤.  3. Improvements3-1. Degenerate Case  object-space low-pass filter ì œì•ˆ\\[\\begin{align}    \\widehat{G}(\\mathrm{x}) = \\max \\left\\{ G(\\mathrm{u}(\\mathrm{x})), G\\left(\\frac{\\mathrm{x}-c}{\\sigma}\\right) \\right\\}\\end{align}\\]â‡’ ì§ê´€ì ì¸ ìˆ˜ì‹ ì˜ë¯¸ = fixed screen-space(ì˜¤ë¥¸ìª½ í•­)ì—ì„œì˜ Gaussianì´ë‘ ìœ„ì—ì„œ êµ¬í•œ intersection point u(x)ì—ì„œì˜ ê°€ìš°ì‹œì•ˆì¤‘ì— ë” í° ê°’ì„ ì„ íƒí•˜ì—¬ degenerateí•˜ëŠ” ê°€ìš°ì‹œì•ˆë“¤ ì—†ì•°where $c$  : projection of center $p_k$ë³¸ ì‹¤í—˜ì—ì„œëŠ” $\\sigma = \\sqrt{2}/2$ë¡œ ì„¤ì •í•¨      Volumetric alpha blending (Rasterization)\\[c(\\mathrm{x}) = \\sum_{i = 1}c_i\\alpha_i\\widehat{G}_i(\\mathrm{u}(\\mathrm{x}))\\prod_{j =1}^{i-1}(1-\\alpha_i \\widehat{G}_i(\\mathrm{u}(\\mathrm{x})))\\]  4. Training  3DGSì˜ photometric lossì—ë‹¤ê°€ 2ê°€ì§€ ì •ê·œí™” í…€ì„ ì¶”ê°€ì‹œì¼œì„œ ë” smoothí•œ surface alignì„ ì´‰ì§„í•˜ì—¬ geometry reconstructionì˜ ì„±ëŠ¥ í–¥ìƒ4.1. Depth Distortion      Depth distortion loss : ray-splat intersectionê²°ê³¼ìƒ êµ¬í•œ depth ê°„ì˜ ê±°ë¦¬ ì°¨ë¥¼ ìµœì†Œí™”í•¨ìœ¼ë¡œì¨ rayì— ì¡´ì¬í•˜ëŠ” weightì„ ë” concentrateí•´ì¤Œ,  Mip-Nerf360ì—ì„œ ì˜ê° ë°›ìŒ\\[\\begin{align} L_d = \\sum_{i,j}w_iw_j|z_i-z_j| \\end{align}\\]    where, $w_i :$ië²ˆì§¸ intersectioní•˜ëŠ” ì§€ì ì—ì„œì˜ blending weight    $z_i :$ ië²ˆì§¸ êµì°¨ì ì—ì„œì˜ depth  4.2. Normal Consistency  êµì°¨í•˜ëŠ” median point(ì¤‘ê°„ ì§€ì ) $p_s$ì—ì„œ actual surface ê³ ë ¤      ì¶•ì ëœ opacityê°€ 0.5ê°€ ë˜ë©´, splatëœ ê°€ìš°ì‹œì•ˆë“¤ì˜ normalê³¼ depth mapì—ì„œì˜ gradientë¥¼ ê³ ë ¤í•´ì„œ aligní•´ì£¼ëŠ” ê³¼ì •\\[\\begin{align}L_n = \\sum_iw_i(1-n_i^T\\mathrm{N}) \\end{align}\\]    where $i :$ rayìƒì— ì¡´ì¬í•˜ëŠ” intersected ëœ splatë“¤    $w :$ blending weight of the intersection point    $n_i :$ normal of the splat that is oriented towards the camera    $\\mathrm{N} :$ normal estimate by the gradient of the depth map  Final Loss: $L = L_c + \\alpha L_d + \\beta L_n$$L_c :$ RGB reconstruction loss combining L1 with the D-SSIM termğ›¼ = 1000 for bounded scenes, ğ›¼ = 100 for unbounded scenes, and ğ›½ = 0.05 for all scenes.5. Experiments  single RTX 3090  Datasets          DTU                  15ê°œ ì”¬ìœ¼ë¡œ êµ¬ì„±ë¨ (49ì¥ ë˜ëŠ” 69ì¥ ì´ë¯¸ì§€, resolution = 1600 x 1200)          Colmapìœ¼ë¡œ sparse point cloudì–»ì–´ì§„ ìƒíƒœ, í•´ìƒë„ë¥¼ 800 x 600 ìœ¼ë¡œ downsampleí•œ ì´í›„ì— ì‚¬ìš©í•¨ íš¨ìœ¨ì„±ì„ ìœ„í•´ì„œ                    TnT      MipNerf360        Evaluation Metrics          PSNR      SSIM      LIPPS      Limitations  assume surfaces with full opacity and extract meshes from multi-view depth maps          semi-transparentí•œ í‘œë©´ì—ì„œëŠ” ì˜ ë³µì›ì´ ì•ˆë¨, ìœ ë¦¬ê°™ì€ ë¶€ë¶„        fine geometric structureì— ëŒ€í•´ì„œëŠ” ëœ ì •í™•í•¨  regularization termì‚¬ìš©í•  ë•Œ ì´ë¯¸ì§€ í€„ë¦¬í‹°ì™€ geometryê°„ì˜ trade-offê°€ ë°œìƒí•¨ â‡’ íŠ¹ì • ì˜ì—­ì—ì„œ over-smoothê²°ê³¼ ì´ˆë˜í•  ìˆ˜ ìˆìŒ"
  },
  
  {
    "title": "Graphics-Ch3. Raster Images",
    "url": "/posts/ch3-Raster/",
    "categories": "Graphics, Study",
    "tags": "Graphics",
    "date": "2025-01-29 18:00:00 +0900",
    





    
    "snippet": "Chapter 3. Raster Imagesì„œë¡   Raster image : 2D í–‰ë ¬ í˜•íƒœë¡œ í”½ì…€ì— ëŒ€í•œ RGB colorê°’ì„ í‘œí˜„í•œ ì´ë¯¸ì§€          RGB ìƒ‰ìƒì€ 3ì°¨ì› ë²¡í„° í˜•íƒœ        ë””ì§€í„¸ ì¹´ë©”ë¼ëŠ” image sensorë¥¼ í¬í•¨í•˜ê³  ìˆëŠ”ë°, ì´ê²ƒì€ ë¹›ì´ ë“¤ì–´ì˜¤ëŠ” ì •ë„(intensity)ì™€ colorë¥¼ êµ¬ì„±í•˜ê³  ìˆìŒ  í•˜ì§€ë§Œ ìš°ë¦¬ê°€...",
    "content": "Chapter 3. Raster Imagesì„œë¡   Raster image : 2D í–‰ë ¬ í˜•íƒœë¡œ í”½ì…€ì— ëŒ€í•œ RGB colorê°’ì„ í‘œí˜„í•œ ì´ë¯¸ì§€          RGB ìƒ‰ìƒì€ 3ì°¨ì› ë²¡í„° í˜•íƒœ        ë””ì§€í„¸ ì¹´ë©”ë¼ëŠ” image sensorë¥¼ í¬í•¨í•˜ê³  ìˆëŠ”ë°, ì´ê²ƒì€ ë¹›ì´ ë“¤ì–´ì˜¤ëŠ” ì •ë„(intensity)ì™€ colorë¥¼ êµ¬ì„±í•˜ê³  ìˆìŒ  í•˜ì§€ë§Œ ìš°ë¦¬ê°€ ì´ëŸ¬í•œ 2D arrayìì²´ë¡œ ì´ë¯¸ì§€ë¥¼ ë³´ì§€ëŠ” ì•ŠìŒ,          ì´ë¯¸ì§€ í”½ì…€ê³¼ ë””ìŠ¤í”Œë ˆì´ í”½ì…€ê°„ì˜ ë§¤ì¹­(direct link)ì´ í•„ìš”í•˜ê³  ì´ë¥¼ Rasterizerê°€ ì²˜ë¦¬í•¨        Vector Image : í”½ì…€ì— ëŒ€í•œ í–‰ë ¬í˜•íƒœë¡œ ë‚˜íƒ€ë‚´ëŠ” ê²ƒì´ ì•„ë‹ˆë¼, shapeì´ë‘ line, curvesë¡œ ê²½ê³„ì§€ì–´ì§„ color ì˜ì—­ì— ëŒ€í•œ ì´ë¯¸ì§€ í‘œí˜„          resolution independentí•˜ë‹¤ëŠ” ì ê³¼, ê³ í•´ìƒë„ë¡œ displayedëœë‹¤ëŠ” ì ì´ ì¥ì ì´ì§€ë§Œ displayë˜ê¸° ì´ì „ì— rasterizedë˜ì–´ì•¼ í•œë‹¤ëŠ” ì ì´ ë‹¨ì ì´ë‹¤.        ì´ë²ˆ ì±•í„°ì—ì„œëŠ” Raster Imageë¥¼ ë‹¤ë£¨ë©°, ë¹›ì˜ ì„¸ê¸°(light iintensity)ì™€ ì—°ê´€ëœ pixel valueë¥¼ ì–´ë–»ê²Œ ê²°ì •í•˜ëŠ”ì§€ì— ëŒ€í•œ ìì„¸í•œ ë‚´ìš©ì€ ë‚˜ì¤‘ ì±•í„°ì—ì„œ ë‹¤ë£° ì˜ˆì •ì´ë‹ˆ ì¼ë‹¨ ê¸°ì–µí•´ë‘ê¸°.1. Raster Devices  ì¥ì¹˜ë¥¼ Rasterí•œë‹¤ëŠ” ê²ƒì€ ë¬´ìŠ¨ ì˜ë¯¸ì¼ê¹Œ  input outputì„ ê°„ë‹¨í•œ ì¡°ì§ë„ë¡œ ë‚˜íƒ€ë‚¸ ì‚¬ì§„ì€ ì•„ë˜ì™€ ê°™ë‹¤.1.1. Displays  pixel valueì— ëŒ€í•œ ê³ ì •ëœ 2D array ê¸°ë°˜ìœ¼ë¡œ ë””ìŠ¤í”Œë ˆì´ë˜ì–´ì§€ëŠ”ë°, ë°©ì‹ì´ ë‘ ê°€ì§€ë¡œ ë¶„ë¥˜ ê°€ëŠ¥í•¨ 1) Emissive(ë°©ì¶œí•˜ëŠ”) Display : í”½ì…€ë“¤ì´ directí•˜ê²Œ ì¡°ì ˆê°€ëŠ¥í•œ lightë¥¼ ë°©ì¶œí•˜ëŠ” ë°©ì‹   í”½ì…€ ìì²´ê°€ ê´‘ì›ì´ ë¨  LED(Light-Emitting Diode)ê°€ ëŒ€í‘œì ì¸ ì˜ˆì‹œ2) Transmissive(íˆ¬ê³¼í•˜ëŠ”) Display : ë¹›ì„ ë°©ì¶œí•˜ì§„ ì•Šê³ , ëŒ€ì‹ ì— íˆ¬ê³¼í•  ìˆ˜ ìˆëŠ” ë§Œí¼ì˜ ë¹›ì„ í”½ì…€ì´ ê°–ê³  ìˆëŠ” ë°©ì‹  transmissive displayëŠ” í”½ì…€ í–‰ë ¬ ë’¤ì— backlightê°€ í•„ìš”í•¨, ì–´ëŠì •ë„ illuminate(ë°ê²Œ í•˜ë‹¤)ë  ë§Œí¼ì˜ ê´‘ì›ì´ í•„ìš”í•˜ê¸° ë•Œë¬¸  LCD(Light-Crystal Display)ê°€ ëŒ€í‘œì ì¸ ì˜ˆì‹œ    on-state(ìœ„, ì „ì•• ë“¤ì–´ì˜¨ ìƒíƒœ)ê°€ ë˜ë©´ liquid crystal cellì´ íšŒì „í•˜ë©´ì„œ polarized lightì´ front plarizerë¥¼ íˆ¬ê³¼í•  ìˆ˜ ìˆê²Œ í•´ì£¼ëŠ” ì›ë¦¬2. Images, Pixels, and Geometry  Raster ImageëŠ” ì´ë¯¸ì§€ í”½ì…€ë³„ë¡œ RGB ìƒ‰ìƒì— ëŒ€í•œ ê°’ì„ 2ì°¨ì› í–‰ë ¬ í˜•íƒœë¡œ ë‚˜íƒ€ë‚´ëŠ” ê²ƒì„ ì•Œê³  ìˆë‹¤.  ì´ë¯¸ì§€ë¥¼ ì¸¡ì •í•˜ê±°ë‚˜ reproduceí•  ë•Œ, light energyì— ëŒ€í•´ ë‹¤ìŒì˜ 2ì°¨ì› ë¶„í¬ë¥¼ ì•Œì•„ì•¼ í•œë‹¤ ;                  light emitted from the monitor as a function of a position on the face of the display  = ë””ìŠ¤í”Œë ˆì´ í‘œë©´ì—ì„œ ë°©ì¶œë˜ëŠ” ë¹›                    light falling on a cameraâ€™s image sensor as a function of a position across the sensorâ€™s plane  = ì¹´ë©”ë¼ì˜ ì´ë¯¸ì§€ ì„¼ì„œë¡œ ë“¤ì–´ê°€ëŠ” ë¹›                    Reflectance(ë°˜ì‚¬ìœ¨) ë˜ëŠ” í¡ìˆ˜ë˜ëŠ” ë¹› ëŒ€ë¹„ ë°˜ì‚¬ë˜ëŠ” ë¹›ì˜ ë¹„ìœ¨(fraction)  = function of position on a piece of paper            We can abstract an â€œimageâ€ as a function $I(x,y)$: \\(I(x,y) : R -&gt; V\\)          grayscale ì´ë¯¸ì§€ì¸ ê²½ìš°ì—ëŠ” $V$ê°€ ì–‘ìˆ˜êµ¬ì—­ì´ê³ , idealí•œ color imageì¸ ê²½ìš°ì— $V$ëŠ” 3ì°¨ì› ì‹¤ìˆ˜ ê³µê°„ì˜ì—­ì´ë‹¤.        continuous(ì—°ì†ì ì¸)ê°’ìœ¼ë¡œ ì–´ë–»ê²Œ Raster imageê°€ í‘œí˜„ë˜ëŠ” ê²ƒì¸ê°€.          Point samplingê³¼ ê´€ë ¨ìˆë‹¤, ìì„¸í•œ ê²ƒì€ chapter 9ì˜ ì‹ í˜¸ì²˜ë¦¬ë‹¨ì›ì—ì„œ ë‹¤ë£¬ë‹¤ê³  í•œë‹¤      ì´ë¯¸ì§€ì˜ ìƒ‰ìƒì— ëŒ€í•œ Local averageë¥¼ pixel valueì •í•¨      pixel valueì¸ xë¥¼ êµ¬í•œë‹¤ëŠ” ë§ì€ ì¦‰, â€œthe value of the image in the vincinity(ì£¼ë³€) of the grid point is xâ€ë¥¼ êµ¬í•œë‹¤ëŠ” ê²ƒê³¼ ê°™ì€ ë§ì´ë‹¤. (ë‹¹ì—°í•œê±°ì•„ë‹˜?)        ì´ë¯¸ì§€ widthê°€ $n_x$, ë†’ì´ê°€ $n_y$ì¼ ë–„, image rectangular domainì€ ë‹¤ìŒê³¼ ê°™ì´ í‰í–‰ì´ë™ì„ 0.5ì”© í–ˆë‹¤ë©´ top-right pixelë„ ë˜‘ê°™ì´ í‰í–‰ì´ë™ì‹œí‚¨ ë§Œí¼ìœ¼ë¡œ ì„¤ì •í•  ìˆ˜ ìˆë‹¤;\\(R = [-0.5, n_x - 0.5] \\times [-0.5, n_y - 0.5]\\)2.1. Pixel Values  Pixel formats :          ë¹„íŠ¸ ìˆ˜ê°€ ì¤„ì–´ë“¤ë©´, artifactë‚˜ flaws(ê²°í•¨)ë¶€ë¶„ì´ ì´ë¯¸ì§€ìƒì— ìƒê¸¸ ìˆ˜ë„ ìˆë‹¤      2.2. Monitor Intensities and Gamma  ëª¨ë‹ˆí„°ëŠ” pixel â€œvalueâ€ë¥¼ digital inputìœ¼ë¡œ ë°›ì•„ì„œ, â€œintensityâ€ level(ë¹›ì˜ ê°•ë„)ë¡œ ë³€í™˜í•¨  ì¸ê°„ì˜ ê°•ë„ì— ëŒ€í•œ ì¸ì§€ëŠ” ë¹„ì„ í˜•ì ì´ë¼ì„œ ì´ ë‹¨ì›ì—ì„œ ë…¼í•  ë¶€ë¶„ì€ ì•„ë‹˜(chapter 20ì— ë‚˜ì˜´)  ëª¨ë‹ˆí„°ë„ inputì— ëŒ€í•´ì„œ non-linearí•˜ê²Œ ì²˜ë¦¬í•˜ëŠ”ë°, ì˜ˆë¥¼ ë“¤ì–´ ëª¨ë‹ˆí„°ì—ê²Œ 0, 0.5, 1.0ì˜ ì„¸ í”½ì…€ valueë¥¼ ì£¼ì—ˆì„ ë•Œ, ë””ìŠ¤í”Œë ˆì´ë˜ëŠ” intensityëŠ” 0, 0.025, 1.0ìœ¼ë¡œ ì²˜ë¦¬ë¨      ì´ëŸ¬í•œ ê·¼ì‚¬ ë¹„ì„ í˜•ì„±ì€ $ \\gamma $ì— ì˜í•´ ê²°ì •ë¨\\(displayed-intensity = (maximum-intensity) a^\\gamma\\)    ì´ ë•Œ, aëŠ” ì•„ë˜ ê·¸ë¦¼ì˜ ì²´ì»¤ë³´ë“œ ì´ë¯¸ì§€ë¥¼ í†µí•œ standard techniqueì„ í†µí•´ ì°¾ì„ ìˆ˜ ìˆëŠ” ê°’ì„ (calibrationê³¼ ì—°ê´€ëœ ê±´ê°€?)  â€œGamma Correctâ€          gammaê°’ì„ ì•Œê³  ìˆìœ¼ë©´, inputì„ ê°ë§ˆ ë³€í˜•í•´ì„œ $a = 0.5$ ì¦‰, í‘ë°±ì˜ ì¤‘ê°„ ê°•ë„ì— ëŒ€í•´ ë””ìŠ¤í”Œë ˆì´ë˜ê²Œ í•  ìˆ˜ ìˆìŒ, ì•„ë˜ì˜ ë³€í˜•ê³¼ì •ì„ ê±°ì¹œë‹¤      $aâ€™ = a^{\\frac{1}{\\gamma}} $      \\[: displayed-intensity = (a')^{\\gamma} = (a^{\\frac{1}{\\gamma}})^{\\gamma}(maximum-intensity) = a(maximum-intensity)\\]            ëŠë‚€ì   pixel ì •ì˜ë‚˜ ì´ë¯¸ì§€ì— ëŒ€í•œ matching functionê°™ì€ ê¸°ì´ˆì ì¸ ê°œë…ì„ í›‘ê³  ê°€ëŠ” ì‹œì‘ ë‹¨ì›ì´ë‹¤,, ë³„ ë‚´ìš©ì´ ì—†ìŒ  ì„¤ë‚ ì¸ë° ì—¬ìœ ë¡­ê²Œ ì¹´ê³µë„ í•˜ê³  ê¸°ë¶„ì´ ì¢‹ë‹¤.ã…‹ã…‹"
  },
  
  {
    "title": "Graphics STUDY",
    "url": "/posts/Graphics_study/",
    "categories": "Graphics, Study",
    "tags": "Graphics",
    "date": "2025-01-25 11:00:00 +0900",
    





    
    "snippet": "Fundamentals of Computer Graphics by Steve Marschner and Peter Shirley  êµìˆ˜ë‹˜ ì¶”ì²œ ì±…, (â€œê·¸ë˜í”½ìŠ¤ì—ì„œ ê°€ì¥ ìœ ëª…í•œ, ì •ì„ ê°™ì€ ì±…ì´ì—ìš”. ê·¸ë˜í”½ìŠ¤ì˜ ê±°ì˜ ëª¨ë“  ë¶„ì•¼ ë‹¤ë£¸â€)  ì•„ì§ ì°¨ë¡€ë§Œ ë³´ê¸´ í–ˆëŠ”ë° ê¹Šê²Œ ì•Œê³ ì‹¶ì—ˆë˜ ë‚´ìš© ì´ì§‘í•©ì¸ ê²ƒ ê°™ì•„ì„œ ì•„ì£¼ ë§ˆìŒì— ë“ ë‹¤Contents1. Introduc...",
    "content": "Fundamentals of Computer Graphics by Steve Marschner and Peter Shirley  êµìˆ˜ë‹˜ ì¶”ì²œ ì±…, (â€œê·¸ë˜í”½ìŠ¤ì—ì„œ ê°€ì¥ ìœ ëª…í•œ, ì •ì„ ê°™ì€ ì±…ì´ì—ìš”. ê·¸ë˜í”½ìŠ¤ì˜ ê±°ì˜ ëª¨ë“  ë¶„ì•¼ ë‹¤ë£¸â€)  ì•„ì§ ì°¨ë¡€ë§Œ ë³´ê¸´ í–ˆëŠ”ë° ê¹Šê²Œ ì•Œê³ ì‹¶ì—ˆë˜ ë‚´ìš© ì´ì§‘í•©ì¸ ê²ƒ ê°™ì•„ì„œ ì•„ì£¼ ë§ˆìŒì— ë“ ë‹¤Contents1. Introduction  1.1 Graphics Areas  1.2 Major Applications  1.3 Graphics APIs  1.5 Numerical Issues  1.6 Efficiency  1.7 Designing and Coding Graphics Programs 2. Miscellaneous Math  2.1 Sets and Mappings  2.2 Solving Quadratic Equations  2.3 Trigonometry  2.4 Vectors  2.5 Curves and Surfaces  2.6 Linear Interpolation  2.7 Triangles 3. Raster Images  3.1 Raster Devices  3.2 Images, Pixels, and Geometry  3.3 RGB Color  3.4 Alpha Compositing 4. Ray Tracing  4.1 The Basic Ray-Tracing Algorithm  4.2 Perspective  4.3 Computing Viewing Rays  4.4 Ray-Object Intersection  4.5 Shading  4.6 A Ray-Tracing Program  4.7 Shadows  4.8 Ideal Specular Reflection  4.9 Historical Notes5. Linear Algebra  5.1 Determinants  5.2 Matrices  5.3 Computing with Matrices and Determinants  5.4 Eigenvalues and Matrix Diagonalization 6 Transformation Matrices  6.1 2D Linear Transformations  6.2 3D Linear Transformations  6.3 Translation and Affine Transformations  6.4 Inverses of Transformation Matrices  6.5 Coordinate Transformations7 Viewing  7.1 Viewing Transformations  7.2 Projective Transformations  7.3 Perspective Projection  7.4 Some Properties of the Perspective Transform  7.5 Field-of-View8. The Graphics Pipeline  8.1 Rasterization  8.2 Operations Before and After Rasterization  8.3 Simple Antialiasing  8.4 Culling Primitives for Efficiency9. Signal Processing  9.1 Digital Audio: Sampling in 1D  9.2 Convolution  9.3 Convolution Filters  9.4 Signal Processing for Images  9.5 Sampling Theory10. Surface Shading  10.1 Diffuse Shading  10.2 Phong Shading  10.3 Artistic Shading11. Texture Mapping  11.1 Looking Up Texture Values  11.2 Texture Coordinate Functions  11.3 Antialiasing Texture Lookups  11.4 Applications of Texture Mapping  11.5 Procedural 3D Textures12 Data Structures for Graphics  12.1 Triangle Meshes  12.2 Scene Graphs  12.3 Spatial Data Structures  12.4 BSP Trees for Visibility  12.5 Tiling Multidimensional Arrays20ë‹¨ì›ê¹Œì§€ ìˆëŠ”ë° ì¼ë‹¨ ë¦¬ë²„í„¸ ëë‚˜ê³ ë‚˜ì„œ 2ì›” ë§ê¹Œì§€ ì—¬ê¸°ê¹Œì§€ 1íšŒë… ëª©í‘œ í•™ë¶€ ë•Œ ë°°ìš´ íŒ¨í„´ì¸ì‹ì´ë‘ ì»´ë¹„ë•Œ ë°°ìš´ ë‚´ìš©ì´ í¬í•¨ëœê²Œ ë§ì•„ì„œ ë³µìŠµí• ê²¸ ëª¨ë¥´ëŠ” ë‚´ìš© ìœ„ì£¼ ê³µë¶€í•´ì•¼ê² ë‹¤."
  },
  
  {
    "title": "MarchingCubes, SIGGRAPH 1987",
    "url": "/posts/MarchingCubes/",
    "categories": "Paper Review",
    "tags": "Mesh extraction, Graphics",
    "date": "2025-01-21 11:00:00 +0900",
    





    
    "snippet": "Abstract  output = ì—°ì†ì ì¸ densityê°’ì„ ê°–ëŠ” surfaceì˜ triangle model  ì•Œê³ ë¦¬ì¦˜ í° íë¦„ : 3D medical dataë¥¼ scan-line orderì— ì²˜ë¦¬í•œ í›„, ì„ í˜• ë³´ê°„(linear interpolation)ì„ ì´ìš©í•´ì„œ ì‚¼ê°í˜•ì˜ vertices(ê¼­ì§“ì )ì„ êµ¬í•˜ëŠ” ê²ƒIntroduction  mesh extr...",
    "content": "Abstract  output = ì—°ì†ì ì¸ densityê°’ì„ ê°–ëŠ” surfaceì˜ triangle model  ì•Œê³ ë¦¬ì¦˜ í° íë¦„ : 3D medical dataë¥¼ scan-line orderì— ì²˜ë¦¬í•œ í›„, ì„ í˜• ë³´ê°„(linear interpolation)ì„ ì´ìš©í•´ì„œ ì‚¼ê°í˜•ì˜ vertices(ê¼­ì§“ì )ì„ êµ¬í•˜ëŠ” ê²ƒIntroduction  mesh extractioní•˜ëŠ” ê²ƒì€ medical imageì—ì„œ êµ‰ì¥íˆ ìœ ìš©í•˜ê²Œ ë§ì´ ì“°ì„  ìƒˆë¡œìš´ 3D surface construction ì•Œê³ ë¦¬ì¦˜ì¸ â€œMarching Cubeâ€ëŠ” ì—°ì†ì ì¸ density surfaceë¥¼ ê°€ì§€ëŠ” ë¬¼ì²´ì— ëŒ€í•œ verticesë¥¼ ì¶”ì¶œí•¨ìœ¼ë¡œì¨ ê³ í•´ìƒë„ì˜ ë©”ì‰¬ ë§Œë“¦  3D Medical ì•Œê³ ë¦¬ì¦˜ íë¦„ :                            Data Acquistion          MR, CT, SPECTê°™ì€ ê¸°ê¸°ë¡œ í™˜ì ë°ì´í„° ì–»ìŒ                                      Image Processing          3D dataì˜ ì „ì²´ì ì¸ êµ¬ì¡°ë¥¼ íŒŒì•…í•  ìˆ˜ ìˆëŠ” ê¸°ë²• ì‚¬ìš©                                      Surface Construction          ë³¸ ë…¼ë¬¸ì˜ ì£¼ì œ, ì ì ˆí•œ ì•Œê³ ë¦¬ì¦˜ ì‚¬ìš©                    Display      Related Work      ê¸°ì¡´ì˜ ì—°êµ¬ (1) Connected Contour ì•Œê³ ë¦¬ì¦˜ : surfaceì˜ ìœ¤ê³½(contour)ì—ì„œ ì‹œì‘í•˜ì—¬ ê·¸ê²ƒë“¤ì´ ì„œë¡œ ì—°ì†ì ì¸ ì‚¼ê°í˜•ì´ ë˜ê²Œ ì—°ê²°í•˜ëŠ” ì ‘ê·¼ë²•   -&gt; sliceì— í•˜ë‚˜ ì´ìƒì˜ contourê°€ ì¡´ì¬í•´ì•¼í•˜ëŠ”ë° ì´ë•Œ ambiguity(ëª¨í˜¸ì„±)ì´ ë°œìƒí•˜ì—¬ ì •í™•ë„ ë–¨ì–´ì§   -&gt; ì›ë°ì´í„°ì˜ inter-sliceì˜ ì—°ê²°ì„±ì„ ë¬´ì‹œí•¨    (2) Cuberille ì ‘ê·¼ë²• : cuberilles(ì‘ì€ íë¸Œì¸ voxelí˜•íƒœë¡œ í‘œí˜„í•˜ëŠ” êµ¬ì¡°)ë¡œë¶€í„° surface êµ¬ì¶•í•˜ëŠ” ì ‘ê·¼ë²•   -&gt; ì´ êµ¬ì¡°ì—ì„œ gradientë¥¼ ê³„ì‚°í–ˆì„ ë•Œ ê·¸ ê°’ì´ shading(ê·¸ë¦¼ì)ì˜ì—­ì˜ ì§€ì ì„ ì°¾ëŠ”ë°ì— ì´ìš©ë˜ëŠ”ë°, ì´ê²Œ ì •í™•í•˜ê¸°ê°€ ì‰½ì§€ ì•ŠìŒ   -&gt; thresholdingí•´ì„œ 3D spaceë¥¼ ë¸”ë¡ ë‹¨ìœ„ voxelì²˜ëŸ¼ í‘œí˜„í•˜ê³  surfaceì„ í‘œí˜„    (3) Ray casting   -&gt; 3ì°¨ì› sensationì„ ìƒì‚°í•˜ê¸° ìœ„í•´ motionì— ì˜ì¡´í•¨(?)   Marching Cubbe Algorithm (Method)  í¬ê²Œ 2ê°€ì§€ì˜ ì£¼ìš”í•œ ë‹¨ê³„ë¡œ êµ¬ì„±ë¨  divide-and-conquer ì ‘ê·¼ë²•  3D spaceìƒì˜ íë¸Œ í•˜ë‚˜ì—ì„œ ë‹¤ìŒ íë¸Œë¡œ ë„˜ì–´ê°ˆ ë•Œ, surfaceê°€ ì–´ë–»ê²Œ êµì°¨í•˜ëŠ”ì§€ë¥¼ ì°¾ëŠ” ê²ƒì´ ëª©í‘œ      ì´ì›ƒí•œ 8ê°œ í”½ì…€(ë‘ Slice ë©´ì˜ 4ê°œ ê¼­ì§“ì )ë¡œë¶€í„° logicalí•œ cubeê°€ Figure-2ì²˜ëŸ¼ ìœ„ì¹˜í•˜ê²Œ ì„¸íŒ…,        íë¸Œì˜ ê¼­ì§“ì (vertex) ë°ì´í„° ê°’ì´ ìš°ë¦¬ê°€ êµ¬ì„±í•˜ëŠ” surfaceì˜ vertex valueê°’ì„ ì´ˆê³¼í•˜ë©´ 1ì„ ë¶€ì—¬  ë§ˆì°¬ê°€ì§€ë¡œ íë¸Œ vertex valueê°€ surface vertex valueê°’ë³´ë‹¤ ì•„ë˜ì´ë©´ 0ì„ ë¶€ì—¬=&gt; surfaceì˜ ì™¸ë¶€ì— ì¡´ì¬í•˜ëŠ” ì  ëŒ€ëµ ì´ëŸ¬í•œ ê³¼ì •ìœ¼ë¡œ êµì°¨ì ë“¤ì„ í†µí•´ surfaceë¥¼ ë³µì›í•˜ê²Œ ëœë‹¤. íë¸Œë§ˆë‹¤ 8ê°œì˜ vertices &amp; 2ê°œì˜ state(inside, outside)ê°€ ì¡´ì¬í•˜ê¸° ë•Œë¬¸ì—, í‘œë©´ì´ ê¼­ì§“ì  1ê°œ ë‹¹ $2^8$ê°€ì§€ ê²½ìš°ì˜ ìˆ˜ë¡œ êµì°¨ë  ìˆ˜ ìˆë‹¤.  í•´ë‹¹ 256ê°€ì§€ ê²½ìš°ì˜ ìˆ˜ì— ëŒ€í•œ tableì„ ë§Œë“¤ ìˆ˜ ìˆìœ¼ë‚˜ ë§¤ìš° ë”°ë¶„í•˜ê³  ì—ëŸ¬ê°€ ë°œìƒí•˜ê¸° ì‰½ê¸° ë•Œë¬¸ì— , 256ê°€ì§€ ê²½ìš°ì˜ ìˆ˜ë¥¼ 14ê°€ì§€ íŒ¨í„´ìœ¼ë¡œ ì¤„ì¼ ìˆ˜ ìˆëŠ” ë‹¤ìŒì˜ ë‘ ê°€ì§€ ëŒ€ì¹­ ì†ì„±ì„ ì´ìš©í•¨          íë¸Œê°€ reverseë¡œ ë’¤ì§‘í˜€ë„, surface valueë“¤ì€ ê·¸ëŒ€ë¡œ ë™ì¼í•˜ê²Œ ë°”ë€Œì§€ ì•ŠìŒ              Rotational ëŒ€ì¹­                        â€˜â€™â€˜(ex) 0ë²ˆ íŒ¨í„´ : ëª¨ë“  verticesê°€ 0ìœ¼ë¡œ ì„ íƒëœ ì¼€ì´ìŠ¤(í˜¹ì€ ëª¨ë‘ 1) =&gt; ì‚¼ê°í˜•ì„ ìƒì‚°í•˜ì§€ ì•Šê²Œ ë¨          1ë²ˆ íŒ¨í„´ : surfaceê°€ 1ê°œì˜ vertexë¥¼ ë‚˜ë¨¸ì§€ 7ê°œì˜ verticesì— ëŒ€í•´ ë¶„ë¦¬ì‹œí‚¨ ìƒíƒœ =&gt; ì‘ì€ ì‚¼ê°í˜• 1ê°œ           â€¦.  ì´ ë•Œ, ìœ— ê·¸ë¦¼ì²˜ëŸ¼ 8ê°œ vertices(v1~v8)ì™€ ê° vertex ì‚¬ì´ì˜ bit index 12ê°œ(e1~e12)ë¥¼ numberingí•˜ì—¬ edge intersectionì„ ê³ ë ¤í•œë‹¤.  ê·¸ í›„ surfaceì™€ ë§ë‹¿ëŠ” edgeê°€ ì–´ë–¤ ê²ƒì¸ì§€ ì•Œì•˜ìœ¼ë©´, ì´ edgeë“¤ ì‚¬ì´ì—ì„œ linear interpolation(ì„ í˜• ë³´ê°„)ì„ ìˆ˜í–‰í•œë‹¤.  ë§ˆì§€ë§‰ ë‹¨ê³„ë¡œ ê° triangle vertexì— ëŒ€í•œ unit normal(ë‹¨ìœ„ ë²•ì„ ë²¡í„°)ë¥¼ ê³„ì‚°í•œë‹¤.          ì´ë ‡ê²Œ êµ¬í•œ normalë¡œ Gouraud-shaded imageë¥¼ ë Œë”ë§í•  ë•Œ ì‚¬ìš©ë¨, ì¦‰ ëª…ì•” ë„£ê¸° ë‹¨ê³„ì„                  ê³ ëŸ¬ë“œ ì‰ì´ë”©(Gouraud Shading)                    Details :                  surface ì˜ normalì€, surfaceì˜ ì ‘ì„  ë°©í–¥ì— ëŒ€í•œ gradient vectorì´ë‹¤.                      direction of gradient vectorë¥¼ $\\vec{g}$ë¡œ í‘œê¸°\\[\\vec{g}(x,y,z) = \\Delta{\\vec{f}(x, y,z)}\\]                                    $\\Delta{\\vec{f}(x,y,z)}$ ë¥¼ êµ¬í•˜ê¸° ìœ„í•´ 3ë°©í–¥ì—ì„œì˜ gradient vectorë¥¼ ì•„ë˜ì²˜ëŸ¼ ê³„ì‚°í•œ í›„ì— ì„ í˜•ë³´ê°„ì„ í•˜ì—¬ surface ë³µì›    \\(G_x(i,j,k) = \\frac{D(i+1, j, k) - D(i-1, j, k)}{\\Delta{x}}\\)     \\(G_x(i,j,k) = \\frac{D(i, j+1, k) - D(i, j-1, k)}{\\Delta{x}}\\)    \\(G_x(i,j,k) = \\frac{D(i, j, k+1) - D(i, j, k-1)}{\\Delta{x}}\\)        In summary, marching cubes creates a surface from a three-dimensional set of data as follows: (ë…¼ë¬¸ í‘œí˜„)          Read four slices into memory.      Scan two slices and create a cube from four neighbors on one slice and four neighbors on the next slice.      Calculate an index for the cube by comparing the eight density values at the cube vertices with the surface con- stant.      Using the index, look up the list of edges from a precal- culated table.      Using the densities at each edge vertex, find the surface- edge intersection via linear interpolation.      Calculate a unit normal at each cube vertex using central differences. Interpolate the normal to each triangle ver- tex.      Output the triangle vertices and vertex normals      Enhancements to the Basic Algorithm  "
  },
  
  {
    "title": "SuGaR, CVPR 2024",
    "url": "/posts/SuGaR/",
    "categories": "Paper Review",
    "tags": "Mesh reconstruction, 3D Gaussian Splatting",
    "date": "2025-01-20 11:00:00 +0900",
    





    
    "snippet": "Abstract  precise and extremely fast mesh extraction from 3DGS representation  state-of-the-art method on SDFs, while providing a better rendering qualityContributions  Regularization term         ...",
    "content": "Abstract  precise and extremely fast mesh extraction from 3DGS representation  state-of-the-art method on SDFs, while providing a better rendering qualityContributions  Regularization term          Gaussian Splatting ìµœì í™” ì¤‘ì˜ loss termì— ì¶”ê°€ì‹œì¼œì„œ 3D Gaussianë“¤ì´ í‘œë©´ì— ì˜ ì •ë ¬ë˜ê²Œ í•˜ëŠ” ì—­í•       3D Gaussianì˜ surface geometry(density &amp; SDF)ë¥¼ ì´ìš©í•¨        Refinement strategy          meshì— ìˆëŠ” gaussianë“¤ ì‚¼ê°í˜•ìœ¼ë¡œ ë¬¶ì–´ì£¼ë©´ì„œ refinementí•¨      Introduction  mesh extraction taskëŠ” 3DGS representationì˜ explicití•œ íŠ¹ì„± ë•Œë¬¸ì— ë” ì–´ë ¤ì›€  3DGSê°€ ì˜ ìµœì í™”ë˜ì—ˆìœ¼ë©´, ê°€ìš°ì‹œì•ˆë“¤ì´ í‰í‰í•˜ê³  í‘œë©´ì— ì˜ ë¶„í¬ë˜ì–´ìˆë‹¤ëŠ” ê°€ì •ì„ ì–»ì„ ìˆ˜ ìˆìŒ          ì´ë•Œ gaussian densityì™€ ê´€ë ¨ëœ geometryë¥¼ ì´ìš©í•´ì„œ Loss termì— ì¶”ê°€í•˜ë©´ì„œ gaussianìœ¼ë¡œë¶€í„° meshì¶”ì¶œì´ ë” ì‰¬ì›Œì§€ê²Œ ë§Œë“¦      volumne density ì‚¬ìš©?        Marching Cube ì•Œê³ ë¦¬ì¦˜ ëŒ€ì‹  Poisson Reconstruction ì•Œê³ ë¦¬ì¦˜ ì‚¬ìš©í•´ì„œ point cloudë¡œë¶€í„° mesh extractionì„ í–ˆë‹¤Method1. Aligning the Gaussians with the Surface (=Regularization)  ëª©í‘œ : 3DGSê°€ ì˜ ìµœì í™”ë˜ì–´ìˆë‹¤ëŠ” ê°€ì • í•˜ì—, Gaussianì˜ SDF(Signed Distance Function)ë¥¼ ì´ëŒì–´ë‚´ëŠ” ê²ƒ      optimizedëœ ê°€ìš°ì‹œì•ˆìœ¼ë¡œë¶€í„° ì˜ˆì¸¡ëœ SDFì™€ ì‹¤ì œì˜ SDFê°„ì˜ ì°¨ì´ë¥¼ ìµœì†Œí™”í•¨ìœ¼ë¡œì¨ ê°€ìš°ì‹œì•ˆë“¤ì´ í‰í‰í•˜ê²Œ surface alignëœ íŠ¹ì„±ì„ ê°–ì„ ìˆ˜ ìˆë„ë¡ encourage        ìµœì í™”ëœ Gaussian Splatting Sceneì´ ì£¼ì–´ì ¸ìˆëŠ” ìƒí™©ì—ì„œ ì‹œì‘    Gaussianì˜ density function $d(p)$ :\\[d(p) = \\sum_g \\alpha_g exp(-\\frac{1}{2}(p-\\mu_g)^T\\sigma_g^{-1}(p-\\mu_g))\\]  &lt; Property 1 &gt;1ï¸âƒ£surfaceì— ê°€ê¹Œìš´ point $p$ì— ê°€ê¹Œì´ ìœ„ì¹˜í•œ Gaussian $g^*$ì´ density function $d(p)$ì— ê¸°ì—¬í•˜ëŠ” ì •ë„ê°€ í¬ë‹¤\\[g^* = \\arg\\min_g(p-\\mu_g)^T\\sigma_g^{-1}(p-\\mu_g)\\]í•´ì„ = g*ë§ê³  ë‚˜ë¨¸ì§€ ê°€ìš°ì‹œì•ˆë“¤, gë“¤ì— ëŒ€í•œ ë°€ë„ê°€ ìµœì†Œê°€ ë˜ê²Œ í•˜ë©´ ëœë‹¤.â‡’ ì´ ì„±ì§ˆì„ ë§Œì¡±í•˜ë©´, ê°€ìš°ì‹œì•ˆë“¤ì´ sceneì—ì„œ ì˜ spreadë˜ì–´ìˆë‹¤, ì¦‰ sceneì— ê°€ìš°ì‹œì•ˆë“¤ì´ ì˜ í¼ì ¸ìˆë‹¤ëŠ” ê°€ì •ì„ ë§Œì¡±&lt; Property 2 &gt;2ï¸âƒ£ì˜ ìµœì í™”ëœ 3DGS sceneì—ì„œëŠ” Gaussianë“¤ì´ í‰í‰í•˜ë‹¤ = scaling factor 3ë°©í–¥ ë²¡í„° ì¤‘ì—ì„œ í•˜ë‚˜ëŠ” 0ì— ê°€ê¹Œì›Œì•¼ í•¨, (ê¸¸ì´ ì§§ì•„ì•¼ í•¨)\\[(p-\\mu_g)^T\\Sigma_g^{-1}(p-\\mu_g) \\approx \\frac{1}{s_g^2}&lt;p-\\mu_g, n_g&gt;\\][notation]  $s_g$: ê°€ì¥ ì§§ì€ scaling factor  $n_g :$ scaling factorì— ëŒ€ì‘ë˜ëŠ” ì¶•ì— ëŒ€í•œ ë°©í–¥, normal(ë²•ì„  ë²¡í„°)ì²˜ëŸ¼ ìƒê°í•´ë„ ë¨â‡’ ê²°ê³¼ì ìœ¼ë¡œ surface-aligní•œ density function $\\overline{d}(p)$\\[\\overline{d}(p) = exp(-\\frac{1}{2s_{g^*}^2} &lt;p-\\mu_{g^*}, n_{g^*}&gt;^2)\\]  A : d(p) ë°€ë„í•¨ìˆ˜ë¥¼ ë”°ë¥´ëŠ” ê°€ìš°ì‹œì•ˆ,  B : $\\overline{d}(p)$ ë°€ë„í•¨ìˆ˜ë¥¼ ë”°ë¥´ëŠ” ê°€ìš°ì‹œì•ˆ&lt; Optimize Term &gt;  $|d(p) - \\overline{d}(p)|$: ìœ„ì˜ density volumeì„ ì´ìš©í•œ optimization term ì„ 3DGS lossì— ì¶”ê°€          ë°€ë„ë¥¼ ì´ìš©í•˜ëŠ” ì§€ê¸ˆ optimize term ì¼ë‹¨ ì¢‹ê¸´ ì¢‹ì€ë°,,,densityë§ê³  SDF(Signed Distance Function) í™œìš©í•˜ëŠ” ê²ƒë„ ì¶”ê°€ì‹œí‚¤ë©´ surface-align Gaussianì„ ì–»ëŠ” ê²ƒì— ë” ì¢‹ë‹¤ê³  í•¨    - í‰í‰í•œ ê°€ìš°ì‹œì•ˆì´ ì£¼ì–´ì¡Œì„ ë•Œ, ì¦‰ Gaussian $g$ì˜ scaling factorë“¤ì´ $s_g$ = 0 ì¸ ìƒí™©ì—ì„œ, point $p$ì™€ true surfaceì™€ì˜ ê±°ë¦¬ : $|&lt;p-\\mu_{gâ€™}, n_{gâ€™}&gt;|$      \\[SDF : \\overline{f}(p) = \\pm s_{g^*}\\sqrt{-2log(\\overline{d}(p))}\\]\\[ideal-SDF : {f}(p) = \\pm s_{g^*}\\sqrt{-2log({d}(p))}\\]   $|\\overline{f}(p)-f(p)|$ : ìœ„ì˜ SDFë¥¼ ì´ìš©í•œ optimization termì„ í†µí•´ í‘œë©´ì— ë” ì˜ ì •ë ¬ëœ ê°€ìš°ì‹œì•ˆë“¤ì„ ì–»ì„ ìˆ˜ ìˆì—ˆë‹¤.   Regularization term $R$ :\\[R =  \\frac{1}{|P|} \\sum_{p \\in P} |\\overline{f}(p) - f(p)|\\]      SDFì˜ normal(ë²•ì„  ë²¡í„°)ì— ëŒ€í•œ regularization termë„ ìˆìŒ\\[R_{Norm} = \\frac{1}{|P|}  \\sum_{p\\in P} || \\frac{\\nabla f(p)}{|| \\nabla f(p) ||^2} - n_{g^*} ||_2^2\\]  2. Efficient Mesh Extraction (=Poisson Reconstruction)  ìµœì í™”ëœ 3DGS sceneì—ì„œ ê³„ì‚°ëœ ê°€ìš°ì‹œì•ˆë“¤ì˜ densityë¡œë¶€í„° 3D pointsë¥¼ ì¼ì • level setì— ëŒ€í•˜ì—¬ ìƒ˜í”Œë§í•¨ =&gt; point clouds êµ¬í•¨                  ì´ ë•Œ, level setì€ level parameterì¸ $\\lambda$ì— ì˜í•´ ê²°ì •ë¨                          ìƒ˜í”Œë§ëœ Points ê¸°ë°˜ìœ¼ë¡œ Poisson reconstruction ìˆ˜í–‰í•˜ì—¬ mesh ì¶”ì¶œ    ì°¸ê³ . Poisson Reconstruction ì •ë¦¬ ê¸€  3. Binding New Gaussians to the Mesh (=Refinement)  Barycentric ì¢Œí‘œê³„ :  ì‚¼ê°í˜• ë˜ëŠ” ë‹¤ë©´ì²´ ë‚´ë¶€ì˜ ì ì„ í•´ë‹¹ ë„í˜•ì˜ ê¼­ì§“ì ì— ëŒ€í•œ ê°€ì¤‘ì¹˜ë¡œ í‘œí˜„í•˜ëŠ” ì¢Œí‘œê³„          (ex) ì‚¼ê°í˜•ì˜ ê²½ìš°:                              ì‚¼ê°í˜•ì˜ ê¼­ì§“ì ì„ A, B, Cë¼ í•  ë•Œ, ë‚´ë¶€ì˜ ì„ì˜ì˜ ì  PëŠ” ë‹¤ìŒê³¼ ê°™ì´ í‘œí˜„ë©ë‹ˆë‹¤:            $P = \\alpha A + \\beta B + \\gamma C$                                ì—¬ê¸°ì„œ Î±,Î²,Î³ëŠ” ê°€ì¤‘ì¹˜ë¡œ, ì•„ë˜ ì¡°ê±´ì„ ë§Œì¡±í•©ë‹ˆë‹¤:            $\\alpha + \\beta + \\gamma = 1$                                    ë…¼ë¬¸ í‘œí˜„ :    Also, the Gaussians have only 2 learnable scaling factors instead  of 3 and only 1 learnable 2D rotation encoded with a complex number rather than a quaternion, to keep the Gaussians flat and aligned with the mesh triangles.        quaternionì´ë€: 3D íšŒì „ì„ í‘œí˜„í•˜ê¸° ìœ„í•´ ì‚¬ìš©ë˜ëŠ” ìˆ˜í•™ì  êµ¬ì¡°ë¡œ, ë³µì†Œìˆ˜ì˜ í™•ì¥ëœ í˜•íƒœ    $q=w+xi+yj+zk$  Experiment  single GPU Nvidia Tesla V100 SXM2 32 GoëŠë‚€ì   3DGSì—ì„œ ê±°ì˜ ìµœì´ˆë¡œ mesh reconstructioníƒœìŠ¤í¬ë¥¼ ìˆ˜í–‰í•´ì„œ ì„±ëŠ¥ì´ ì¢‹ê²Œ ë‚˜ì™”ë‹¤ëŠ” ê²ƒì´ ì˜ì˜  ìš”ì¦˜ ëª¨ë¸ë“¤ì˜ ê±°ì˜ baseline ì‹œì´ˆê¸‰(?)ìœ¼ë¡œ ë´ë„ ë¬´ë°©í•˜ë‹¤  í¬ì•„ì†¡ ì¬ê±´ë°©ë²•ì´ ì•„ì§ ë­”ì§€ ì˜ ëª¨ë¥´ê² ë‹¤. marching cubeê³µë¶€í•  ë•Œ ê°™ì´ ê³µë¶€  ì–´ë µê¸´ í•œë° ì¬ë°Œë‹¤."
  },
  
  {
    "title": "GS2Mesh, ECCV 2024",
    "url": "/posts/GS2Mesh/",
    "categories": "Paper Review",
    "tags": "Mesh reconstruction, Surface reconstruction, 3D Gaussian Splatting",
    "date": "2025-01-19 15:00:00 +0900",
    





    
    "snippet": "GS2Mesh :Surface Reconstruction from Gaussian Splatting via Novel Stereo Views&lt; ì„ ì • ì´ìœ  &gt;  SuGaR (CVPR 2024)ë…¼ë¬¸ ì´í›„ë¡œ ìœ ì˜ë¯¸í•˜ê²Œ 3dgsì˜ mesh recon íƒœìŠ¤í¬ì—ì„œ ì„±ëŠ¥ì´ sotaë‹¬ì„±í•˜ì˜€ë‹¤ëŠ” ì ,  baselineì— SuGaRê°€ ì¡´ì¬í•œë‹¤ëŠ” ì Abstra...",
    "content": "GS2Mesh :Surface Reconstruction from Gaussian Splatting via Novel Stereo Views&lt; ì„ ì • ì´ìœ  &gt;  SuGaR (CVPR 2024)ë…¼ë¬¸ ì´í›„ë¡œ ìœ ì˜ë¯¸í•˜ê²Œ 3dgsì˜ mesh recon íƒœìŠ¤í¬ì—ì„œ ì„±ëŠ¥ì´ sotaë‹¬ì„±í•˜ì˜€ë‹¤ëŠ” ì ,  baselineì— SuGaRê°€ ì¡´ì¬í•œë‹¤ëŠ” ì Abstract  noisyí•œ 3DGS representationìœ¼ë¡œë¶€í„° smoothí•œ 3D mesh representationì„ ì–»ëŠ” ê²ƒ ì–´ë ¤ì›€  pre-trained stereo-matching modelì‚¬ìš©í•´ì„œ sceneì— ëŒ€í•œ geometry í™œìš©í•¨          stereo-aligned ë˜ì–´ìˆëŠ” image pairë¥¼ ì–»ê³ , ì´ë¥¼ ì•ì„  stereo matchingëª¨ë¸ì— ë„£ì–´ì„œ depthì¶”ì¶œí•˜ì—¬ geometry ì´ìš©í•¨        more smoother, more accurate mesh extraction ê°€ëŠ¥          Mesh Extraction ì•Œê³ ë¦¬ì¦˜ : TSDF(Truncated Signed Distance Function) ì´ìš©í•œ Marching cube      Contributions  pre-trained stereo-matching ëª¨ë¸ì„ í†µí•´ Image pairì˜ geometry í™œìš©í•´ì„œ mesh reconstruction íƒœìŠ¤í¬ì˜ sotaì„±ëŠ¥ì„ ë‹¬ì„±í•˜ì˜€ë‹¤.          ì‚¬ìš©í•œ ìŠ¤í…Œë ˆì˜¤ ë§¤ì¹­ ëª¨ë¸ : DLNR                  stereo calibrated image pairë¥¼ ëª¨ë¸ inputìœ¼ë¡œ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ ìŒì— ëŒ€í•œ  correspondence ë¬¸ì œë¥¼ í•´ê²° + depth ì¶”ì¶œ                      TSDF(Truncated Signed Distance Function)ì™€ depth ì •ë³´ë¥¼ í™œìš©í•´ì„œ mesh reconí•˜ëŠ” ì•Œê³ ë¦¬ì¦˜ (marching cubeê¸°ë°˜) ì‚¬ìš©í•˜ì˜€ë‹¤. Introduction  Gaussianì˜ explicití•œ ìš”ì†Œë§Œìœ¼ë¡œ geometrically consistentí•œ surfaceë¥¼ ì¶”ì¶œí•˜ëŠ” ê²ƒì€ ì–´ë ¤ì›€          image plane(2D)ì— back projected ë˜ì—ˆì„ë•Œ best matchingë˜ê²Œë” ìµœì í™”ëœ ê°€ìš°ì‹œì•ˆì´ê¸° ë•Œë¬¸ì—, mesh reconstruction ì—ì„œëŠ” ì˜¤íˆë ¤ ê°€ìš°ì‹œì•ˆ representationì´ ë‹¨ì ì´ ë¨            stereo-alignedëœ ì´ë¯¸ì§€ ìŒì—ì„œ stereo-matching ëª¨ë¸(DLNR)ì„ ì‚¬ìš©í•´ì„œ ì •í™•í•œ depth ì¸¡ì •í•œ í›„, TSDF í™œìš©í•œ Depth-fusionê¸°ë°˜ mesh extraction ì•Œê³ ë¦¬ì¦˜ (Marching cube) ì‚¬ìš©í•˜ëŠ” íŒŒì´í”„ë¼ì¸    ë°ì´í„°ì…‹ : TnT(Tanks and Temples) &amp; DTU(ì‘ì€ object mesh ë°ì´í„°ì…‹ì„) ì—ì„œ sotaì„±ëŠ¥ì„ ë³´ì—¬ì£¼ì—ˆë‹¤.MethodStep 1. Scene Capture &amp; Pose Estimation  COLMAPì˜ SFM(Structure From Motion)ì„ í†µí•´ ì¹´ë©”ë¼ íŒŒë¼ë¯¸í„°ë“¤ì„ ì–»ì–´ë‚´ê³ , sparseí•œ 3D point cloudë¥¼ ì¬ê±´í•œë‹¤.Step 2. Stereo-aligned Image Pairs ìƒì„±  3DGSì—ì„œ photometric lossë¥¼ í†µí•´ ìµœì í™”ë˜ì–´ì„œ image planeì— back-projectedëœ ê°€ìš°ì‹œì•ˆë“¤ ê¸°ë°˜ìœ¼ë¡œ stereo-aligned(ê°™ì€ ë² ì´ìŠ¤ë¼ì¸b ì„ ìƒì— ì¡´ì¬í•˜ëŠ”, ì¹´ë©”ë¼ í¬ì¦ˆ(rotation, translation)ì€ ê·¸ëŒ€ë¡œì— baseline bê¸¸ì´ë§Œí¼ë§Œ ë–¨ì–´ì§„) í•œ ìŒìœ¼ë¡œ ë§Œë“œëŠ” ê³¼ì •ì„ ìˆ˜í–‰í•œë‹¤.          \\[R_R = R_L\\]\\[T_R = T_L + (R_L \\times [b, 0, 0])\\]   ìˆ˜ì‹ Notation ì„¤ëª…   - $R_R$: ì˜¤ë¥¸ìª½ ì¹´ë©”ë¼ì˜ rotation matrix    - $R_L$: ì™¼ìª½ ì¹´ë©”ë¼ì˜ rotation matrix    - $T_R$: ì˜¤ë¥¸ìª½ ì¹´ë©”ë¼ì˜ translation matrix    - $T_L$: ì™¼ìª½ ì¹´ë©”ë¼ì˜ translation matrix  Step 3. Stereo Depth Estimation  input : a pair of stereo-calibrated cameras      DLNR(High Frequency Stereo matching Network) ëª¨ë¸ ì´ìš©        DLNR pipeline          multiscale decouple LSTM êµ¬ì¡°ë¥¼ ë”°ë¦„ + Disparity Normalization ìˆ˜í–‰í•˜ëŠ” ê²ƒì´ í•µì‹¬      ë…¼ë¬¸ê¹Œì§€ ìì„¸íŒ ì•„ì§ ì•ˆì½ì–´ë´„, ê± stereo matching model ì„±ëŠ¥ ì¤‘ì— sotaë¼ê³  í•¨            ì´ ëª¨ë¸ outputì—ë‹¤ê°€ ì•„ë˜ì˜ mask 2ê°œ ì •ë„ ì¶”ê°€ì‹œì¼œ reconstructionì„±ëŠ¥ í–¥ìƒ              occlusion mask                  left-to-right disparityë‘ right-to-left disparity ì°¨ì´ ì´ ë‘ê°œ ì‚¬ì´ì—ì„œ thresholdingí•´ì„œ êµ¬í•´ì§                    depth-shading                  stereo-matching error $\\epsilon(Z)$        \\[\\epsilon(Z) = \\frac{\\epsilon(d)}{f_x \\cdot B} Z^2\\]                  $Z$ :  ground-truth depth          $d$ : disparity          $f_x$ : ìˆ˜í‰ì¶• ì¹´ë©”ë¼ focal length       - errorê°€ baseline B ê¸¸ì´ ê°’ì´ ì»¤ì§ˆìˆ˜ë¡, ì¦‰ stereo-paired image ì‚¬ì´ì˜ ê°„ê²©ì´ í´ìˆ˜ë¡ ì—ëŸ¬ê°€ ì‘ì•„ì§€ëŠ” ë°˜ë©´, occlusionì´ ì‹¬í•´ì§ˆ ìˆ˜ ìˆìŒ          4B â‰¤ Z â‰¤ 20B ì— ì†í•˜ëŠ” ê¹Šì´ë§Œì„ ê³ ë ¤í•¨                    Step 4. Depth Fusion into Triangulated Surface (mesh)  ì¶”ì¶œëœ depth ì •ë³´ë“¤ì„ TSDF(Truncated Signed Distance Function) ê¸°ë°˜ mesh reconstrucction ë°©ë²•ì— í†µí•©ì‹œí‚¨ë‹¤                  TSDF Cube Modelì´ë€?        : ê¹Šì´ ì˜ìƒ ìœ¼ë¡œë¶€í„° 3ì°¨ì› ê³µê°„ í‘œë©´ì„ íš¨ê³¼ì ìœ¼ë¡œ í‘œí˜„í•˜ê¸° ìœ„í•´,        ì „ì²´ ê³µê°„ì„ ì¼ì •í•œ í¬ê¸°ì˜ ì •ìœ¡ë©´ì²´ ë³µì…€(voxel)ë“¤ë¡œ êµ¬ì„±ëœ ì»¤ë‹¤ë€ í•˜ë‚˜ì˜ íë¸Œ(cube)ë¡œ í‘œí˜„í•˜ê³ , ê° ë³µì…€ì—ëŠ” ë¬¼ì²´ í‘œë©´ê³¼ì˜ ê±°ë¦¬ë¥¼ ë‚˜íƒ€ë‚´ëŠ” TSDFê°’ê³¼ ê·¸ ê°’ì˜ ì‹ ë¢°ë„ë¥¼ ë‚˜íƒ€ ë‚´ëŠ” ê°€ì¤‘ì¹˜(weight)ë¥¼ í•¨ê»˜ ì €ì¥í•˜ëŠ” ë°©ì‹                    etcì— TSDF ê°œë… ê°„ë‹¨í•˜ê²Œ ì¶”ê°€              Marching cube : mesh ë§Œë“¤ì–´ì£¼ëŠ” ì•Œê³ ë¦¬ì¦˜          sdfë‚˜ tsdfê°™ì€ í•¨ìˆ˜ í™œìš©ë˜ë©°, surface representation ë°©ì‹ ê¸°ë°˜ìœ¼ë¡œ mesh ë½‘ì•„ëƒ„      Experiment  ground truth point cloudë‘ reconstructed point cloudê°„ì˜ Chamfer Distance(CD)ê³„ì‚°ì„ í†µí•´ evaluation  Baseline : SuGaR(CVPR 2024), BakedSDF, Neuralangelo, VolSDF, NeuS, MVSformer,  ë°ì´í„°ë³„ë¡œ ì‹¤í—˜ ì§„í–‰ ì–˜ê¸°  í‰ê°€ ì§€í‘œ : Chamfer-Distance(CD): ë‘ point cloud ì§‘í•©ê°„ì˜ ê±°ë¦¬ ì¸¡ì •, F1, AccuracyLimitation  ì˜¤ë¥¸ìª½ ìŠ¤í…Œë ˆì˜¤ ë§¤ì¹­ ëª¨ë¸ì€ íˆ¬ëª…í•œ í‘œë©´ì—ì„œ ì–´ë ¤ì›€ì„ ê²ªëŠ”ë‹¤.  (ì™¼ìª½) ì›ë˜ í•™ìŠµ ì´ë¯¸ì§€ì—ì„œ ì¶©ë¶„íˆ ë‹¤ë£¨ì–´ì§€ì§€ ì•Šì€ ì˜ì—­ì—ì„œ floaterë¥¼ ìƒì„±í•œë‹¤.  TSDF í“¨ì „ì€ í° ì¥ë©´(ë„“ì€ baseline B)ì— ë§ê²Œ í™•ì¥ë˜ì§€ ì•ŠëŠ”ë‹¤.etc., (Preliminaries)ê¸°ì´ˆê°œë… ì •ë¦¬ê¸°ì´ˆ ê°œë…      Meshë€?    : 3D ê³µê°„ìƒì— ì¡´ì¬í•˜ëŠ” ì ë“¤(Vertex/ Point) ê³¼ ê·¸ ì  3 ê°œì˜ ì§‘í•©ì¸ ë©´(Polygon/face)ë“¤ë¡œ ì´ë£¨ì–´ì§„ 3D ê³µê°„ í‘œí˜„ë°©ë²•        Voxelì´ë€?    :ì´ë¯¸ì§€ì˜ pixel ì²˜ëŸ¼ 3D ê³µê°„ì„ í‘œí˜„í•˜ê¸° ìœ„í•´ì„œ 3Dê³µê°„ì„ ì‘ì€ ë‹¨ìœ„ ê³µê°„ìœ¼ë¡œ ìª¼ê°  ê²ƒ â€“&gt; 3ì°¨ì› ê³µê°„ì„ gridë¡œ ìª¼ê°°ë‹¤ê³  ë³´ë©´ í¸í•¨  TSDF (Truncated Signed Distance Function)  3D scene reconstructionì˜ ëª©ì ì€ Surface ë¥¼ ì°¾ì•„ recon í•˜ëŠ” ê²ƒì¸ë° ì´ë•Œ surface ë¥¼ í‘œí˜„í•˜ëŠ” í•¨ìˆ˜ë¥¼ SDF(Signed Distance Function) ë¼ê³  í•¨      Voxel í˜•íƒœë¡œ ë‹¨ìœ„ê³µê°„ì„ ë‚˜ëˆ„ì–´ surface ë¼ê³  íŒë‹¨ë˜ëŠ” ê³³ì€ 0, Surface ì•ˆìª½ì€ ìŒìˆ˜ , Surface ë°”ê¹¥ìª½ì€ ì–‘ìˆ˜ë¡œ í‘œí˜„í•˜ëŠ” ë°©ì‹      Marching Cube (SIGGRAPH 1987)  ê³¼ì • ë‹¤ ìƒëµí•˜ê³  í•œ ì¤„ ìš”ì•½ : 3D point cloudë¡œë¶€í„° Mesh ìƒì„± ì•Œê³ ë¦¬ì¦˜2ì°¨ì› image planeì—ì„œ ë¬¼ì²´ê°€ ë¹¨ê°„ìƒ‰ ì„ ì²˜ëŸ¼ ìƒê²¼ë‹¤ê³  ìƒê°í•´ë³´ì, (3ì°¨ì›ì—ì„œëŠ” voxelì„)ì´ê²ƒì„ 2ì°¨ì› ë„íŠ¸ë¡œ í‘œí˜„í•˜ë©´ ì•„ë˜ì™€ ê°™ìŒâ‡’ ì›í˜•ì˜ ë¬¼ì²´ë‘ ë„ˆë¬´ ë‹¬ë¼ì§, í•´ìƒë„ ì°¨ì´ ë°œìƒ, ëª¨ì–‘ ì´ìƒí•´ì§€ëŠ” ê²°ê³¼ë”°ë¼ì„œ, ë§ˆì¹­ íë¸Œ ì•Œê³ ë¦¬ì¦˜ìœ¼ë¡œ surface reconstructionì„ ì§„í–‰í•œë‹¤. (â€¦TLDR)  About Marching Cube Algorithm, tistory=&gt; ë§ˆì¹­ íë¸Œ ì•Œê³ ë¦¬ì¦˜ ë‹¤ìŒ ê²Œì‹œë¬¼ì— ì •ë¦¬ ì´ì–´ì„œ,, ëŠë‚€ì   Marching Cube ì•Œê³ ë¦¬ì¦˜ë¶€í„° ì™„ë²½í•˜ê²Œ ì´í•´ë¥¼ í•´ë³´ì          í•­ìƒ ê°„ë‹¨í•œ ì •ë¦¬ê¸€ë¡œë§Œ ì½ê³  ë„˜ì–´ê°€ë‹ˆê¹Œ ê·¸ëƒ¥ point cloudë„£ê³  meshë½‘ì•„ì£¼ëŠ” ê·¸ë˜í”½ìŠ¤ ì•Œê³ ë¦¬ì¦˜ì´ë‹¤ì •ë„ë¼ê³ ë§Œ ì•Œê³  ë„˜ì–´ê°€ì„œ ëª¨í˜¸í•˜ë‹¤, ì•Œì§œë°°ê¸°ë¥¼ ëª¨ë¥´ëŠ” ëŠë‚Œ      SuGaRì—ì„œëŠ” Poisson reconstructionê¸°ë°˜ì˜ mesh reconì•Œê³ ë¦¬ì¦˜ì„ ì¼ë‹¤ê³  ë˜ì–´ìˆì—ˆëŠ”ë°, ì´ê²Œ ë‚˜ëŠ” ë§ˆì¹­ íë¸Œë‘ ì™„ì „ ë‹¤ë¥¸ ê±´ ì¤„ ì•Œì•˜ëŠ”ë° ë˜ ì½ë‹¤ë³´ë‹ˆ í¬ì•„ì†¡ì¬ê±´ë„ ë§ˆì¹­íë¸Œê¸°ë°˜ì´ë¼ëŠ” ì†Œë¦¬ë„ ìˆê³  ì¶œì²˜ê°€ ì •í™•í•˜ì§€ ì•Šìœ¼ë‹ˆê¹Œ í˜¼ë™ëœë‹¤, ê·¸ë˜ì„œ Poisson Reconstruction ë…¼ë¬¸ë„ ì½ì–´ì•¼ê² ë‹¤        eccvë…¼ë¬¸ì¸ë° ìƒê°ë³´ë‹¤ ë…¸ë²¨í‹°ê°€ ë­ê°€ ì—†ë‹¤          ê·¸ëƒ¥ stereo-matching ëª¨ë¸ ì¨ì„œ depthì¶”ì¶œí•˜ê³  ì´ê±° ê¸°ë°˜ìœ¼ë¡œ point cloudë¥¼ ë” ì •í™•í•˜ê³  ë°€ë„ìˆê²Œ ë½‘ì•„ë‚´ê³  ê·¸ í›„ë¡œëŠ” ê·¸ëƒ¥ ì•Œê³ ë¦¬ì¦˜ ì‚¬ìš©í•´ì„œ ë©”ì‰¬ì¶”ì¶œí•œê±´ë°,, ì„±ëŠ¥ì´ ì¢‹ì•˜ë‹¤ëŠ”ê²Œ ì‹ ê¸°í•˜ë‹¤.      ëŒ€ì‹  ë‹¨ì ì´ ëª…í™•í•˜ë‹¤, stereo ê¸°ë²•ì´ë‹¤ë³´ë‹ˆ ìœ„ì˜ triangulationì‚¬ì§„ì„ ë³´ë‹¤ì‹œí”¼ ë² ì´ìŠ¤ë¼ì¸ ê¸¸ì´ì— í•œì •ëœ ì”¬ë§Œ ì‚¬ìš©ë  ê²ƒì´ë¯€ë¡œ ë„“ì€ ì¦‰ í° ë°˜ê²½ì˜ sceneì— ëŒ€í•œ mesh reconì€ ì˜ ì•ˆë  ê²ƒì´ë‹¤ (ì‹¤ì œë¡œ ì‚¬ìš©í•œ ë°ì´í„°ì…‹ë“¤ë„ ë‹¤ ì‘ì€ object based ë²¤ì¹˜ë§ˆí¬ë“¤ì´ë‹¤)      3DGSë„ ê·¸ë ‡ê³ , mesh reconë„ ê·¸ë ‡ê³  ê³ ì§ˆì ì¸ ë¬¸ì œê°€ íˆ¬ëª…í•œ transparentí•œ ë¬¼ì²´ê°€ ì˜ ë³µì›ì´ ì–´ë µë‹¤ëŠ” ì ì¸ë°, ì´ë¶€ë¶„ì˜ ê°œì„ ì€ ì™œ ì•ˆë˜ê³  ìˆëŠ”ì§€ ë Œë”ë§ ì¸¡ë©´ì—ì„œ ê³µë¶€ë¥¼ ì¢€ ë” í•´ë´ì•¼ê² ë‹¤.      "
  },
  
  {
    "title": "ë¸”ë¡œê·¸ ì˜¤í”ˆ",
    "url": "/posts/First_Blog/",
    "categories": "Blogging, Tutorial",
    "tags": "personal",
    "date": "2025-01-18 02:34:00 +0900",
    





    
    "snippet": "First Blogì•ˆë…•~! ë°ìŠ¤í¬íƒ‘ ìš´ì˜ì²´ì œê°€ ë¦¬ëˆ…ìŠ¤ì—¬ì„œ ë„ì»¤ ì—°ë™ì´ ìƒê°ë§Œí¼ ì˜ ë˜ì§€ ì•Šì•„ ê¹ƒí—™ ë¸”ë¡œê·¸ë¥¼ ë§Œë“œëŠ” ê±¸ ê³„ì† ë¯¸ë¤„ì™”ì—ˆë‹¤. ì˜¤ëŠ˜ ë§¥ë¶ì´ ìƒˆë¡œ ì™€ì„œ ì‹¬ì‹¬í•´ê°€ì§€ê³  ë¸”ë¡œê·¸ ë¯¸ë¤„ë’€ë˜ ê±¸ ë‹¤ì‹œ ë„ì „í•´ë´¤ë‹¤. ì•„ì§ faviconì€ ë°˜ì˜ì€ ë­ë•œì‹œ ì•„ì§ ì•ˆë˜ê³  ìˆê³ ,, ê·¸ëŒ€ë¡œ í…Œë§ˆ ê°–ë‹¤ ì“°ëŠ”ê±´ë°ë„ ìƒê°ë³´ë‹¤ ë­ê°€ ì˜ ì•ˆë˜ì„œ..ìƒê°ë³´ë‹¤ ì˜¤ë˜ê±¸ë ¸ë‹¤. ê¸€ ì“°ê³  ...",
    "content": "First Blogì•ˆë…•~! ë°ìŠ¤í¬íƒ‘ ìš´ì˜ì²´ì œê°€ ë¦¬ëˆ…ìŠ¤ì—¬ì„œ ë„ì»¤ ì—°ë™ì´ ìƒê°ë§Œí¼ ì˜ ë˜ì§€ ì•Šì•„ ê¹ƒí—™ ë¸”ë¡œê·¸ë¥¼ ë§Œë“œëŠ” ê±¸ ê³„ì† ë¯¸ë¤„ì™”ì—ˆë‹¤. ì˜¤ëŠ˜ ë§¥ë¶ì´ ìƒˆë¡œ ì™€ì„œ ì‹¬ì‹¬í•´ê°€ì§€ê³  ë¸”ë¡œê·¸ ë¯¸ë¤„ë’€ë˜ ê±¸ ë‹¤ì‹œ ë„ì „í•´ë´¤ë‹¤. ì•„ì§ faviconì€ ë°˜ì˜ì€ ë­ë•œì‹œ ì•„ì§ ì•ˆë˜ê³  ìˆê³ ,, ê·¸ëŒ€ë¡œ í…Œë§ˆ ê°–ë‹¤ ì“°ëŠ”ê±´ë°ë„ ìƒê°ë³´ë‹¤ ë­ê°€ ì˜ ì•ˆë˜ì„œ..ìƒê°ë³´ë‹¤ ì˜¤ë˜ê±¸ë ¸ë‹¤. ê¸€ ì“°ê³  ì˜¬ë¦¬ëŠ” ê±´ ìë™í™”ê°€ ì˜ë¼ìˆì–´ì„œ ê´œì°®ì„ ê²ƒ ê°™ì•„ ê¾¸ì¤€íˆ ìŠ¤í„°ë”” ê²¸ ê·¼í™©ì„ ì´ê³³ì— ì˜¬ë¦¬ë„ë¡ í•˜ê² ë‹¤.ë§¥ë„ ì•„ì§ ìµìˆ™í•˜ì§€ ì•Šì•„ì„œ ë‹¤ì†Œ í—¤ë§¸ì§€ë§Œ ì¢€ ë” ìµìˆ™í•´ì§€ë©´ í™œìš©ë„ê°€ ë§¤ìš° ë†’ì„ ê²ƒ ê°™ì•„ ë§Œì¡±í•œë‹¤!  WELCOME MY GITHUB BLOG, I am a Master student in Computer Vision Lab, Korea UniversityNext time you visit our site, this place will be much more developed and awesome."
  }
  
]

