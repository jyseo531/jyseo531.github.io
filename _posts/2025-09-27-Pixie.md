---
title: Pixie, arxiv preprint 2025
author: jiyoung
date: 2025-09-27 12:00:00 +0800
categories: [Study,Paper-review]
tags: [3D Physics prediction]
---

<script type="text/javascript">
  MathJax = {
    tex: {
      inlineMath: [['$', '$'], ['\\(', '\\)']]
    }
  };
</script>
<script type="text/javascript" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

[paper link](https://arxiv.org/abs/2508.17437)
<div align="center">
<table>

<img src="/assets/img/posts_storage/Pixie/image.png" width="800" alt="teaser">
</table>
</div>

## Abstract

- 태스크: 3D scene의 물리적 특성 복원
- Novel method that trains a generalizable neural network to predict physical properties across multiple scenes from 3D visual features purely using supervised losses
- 학습시키고 나면, 우리의 feed-forward network는 빠르고 정확하게 “material fields”를 추론할 수 있다
- 가우시안 스플래팅으로 표현된 정적인 static scene을 현실적으로 물리기반 시뮬레이션하는 scene으로 변형 가능
- PixieVerse 데이터셋 ⇒ 3D assets + physical material annotation포함
- CLIP같은 pretrained visual features 활용해서 zero-shot일반화
    - real-world scene + synthetic data(이게 더 학습되나봄)

---

## Introduction

- NeRF + 3DGS ⇒ learning-based scene reconstruction 네트워크
    - sparse camera 뷰로부터 3D geometry와 장면을 사실적으로 복원할 수 있음
    - visual appearance에만 집중해서 표현함
        - geoemtry와 scene의 color만
        - physical properties 부재함
- 기존 3D scnee의 physical properties복원의 메소드를 크게 두가지로 분류됨
    1. 사용자가 도메인 지식을 바탕으로 장면 전체에 대한 재질 파라미터를 직접 지정하도록 요구(?)
    2. 테스트 시점 최적화(test-time optimization)를 통해 재질 추출 과정을 자동화
- PIXIE : geometry + appearance + physical learning 통합해서 예측
- PixieVerse 데이터 :  1,624개의 paired 3D objects & annotated materials
    - spanning 10 semantic classes

### Contributions

- 3D Physics Prediction에서의 새로운 프레임워크 제안
    - 이산적인 물질의 타입을 예측 &
    - 연속적인 physical parameter (*Young’s modulus, Poisson’s ratio, density*)를 예측
- PIXIEVERSE 데이터셋 제안
    - 3D objects (from Objaverse) + physical material annotations 제공
    - 1624종류의 물체 + 10개의 semantic한 클래스
- Inference가 빠르고 generalizable함
    - CLIP의 pretrained visual feature와 3D U-Net의 feed-forward활용하여 빠른 테스트타임 최적화
- Real scene에서의 zero-shot generalization 성능
    - 합성데이터로만 학습함에도 ㅂ루구하고, real-world scene에 잘 작동함
    - sim-to-real gap완화
- MPM(material point-method) Solver와 함께 Seamless integration 성능
    - 물리 시뮬레이션을 위해, 예측된 material field는 Gaussian Splatting모델이랑 같이 합쳐져서 렌더링될 수 있음 ⇒ wind, gravity같은 애니메이션

---

## Method

- 기본 논지: 3D 시각적 외형(기존 NeRF와 3DGS같은 뉴럴렌더링(i.e., volumetric reconstruction model)으로 얻어지는 texture, shading, shape featrue 포함) 만으로도 객체의 물리적 파라미터를 복원하기에 충분한 정보를 제공한다는 것
- Young’s modulus(영률) & Poisson’s ratio(포아송비)같은 물성 예측
    - 영률: 물체를 잡아당겼을 때, **얼마나 단단하게 버티는지**를 나타내는 값(뻣뻣함의 정도)
    - 포아송비: 물체를 잡아당겼을 때, **옆으로 얼마나 퍼지는지**를 나타내는 값 (길게 늘릴 때 옆으로 줄어드는 비율)
- 3DGS같은 reconstruction model에 point-wise한 물질 추정을 같이 augment함
- CLIP visual prior 활용하고 physics solver에게 물체가 외부 요소(wind, gravity)에 의해 반응할 수 있도록 애니메이션 주입시키는 데에 사용함
- pixieverse 데이터를 제안해서 우리 모델 학습하는데 사용했음

<div align="center">
<table>
<img src="/assets/img/posts_storage/Pixie/method.png" width="800" alt="method_overview">
</table>
</div>

$$
\begin{align} f_{\theta} : (\mathcal{I}, \Pi) \longrightarrow \hat{\mathcal{M}}
\end{align}
$$

- 여기서 $\mathcal{I}={I_k}_{k=1}^K $는 정적인 3D scene을 의미함
- 통합된 카메라 파라미터인 $\Pi$ 를 연속적인 3차원의 "material field" $\hat{\mathcal{M}}$로 매핑하는 것이 목표인 것

- 각 3차원 포인트 p는 아래의 재질 필드(material field)을 반환한다
$$
\begin{align}
\hat{\mathcal{M}} = \left( 
  \hat{\mathcal{l}}(p),\; 
  \hat{E}(p),\; 
  \hat{\mathcal{v}}(p),\; 
  \hat{\mathcal{d}}(p) 
\right)
\end{align}
$$
  
- 여기서 l은 이산적인 material의 종류를 나타내는 클래스가 무엇인지에 대한 거 
- E는 연속적인 영률(Young's modulus), v는 포아송비, d는 밀도값을 각각 나타냄

- l: 이산적인 material의 종류를 나타내는 클래스 => "constitutive law(구성법칙)"로도 알려짐
- ***<Material Point Method***>에 의하면, 이산적인 재료 클래스(즉, 구성 법칙)는 전문가가 정의한 초탄성 에너지 함수 $\mathcal{E}$와 리턴 매핑(return mapping, $\mathcal{P}$)의 조합으로 게산됨
- 이러한 point-mapping기반 방법은 fine-grained한 각 공간적 위치마다 물질의 재료 segmentation을 제공해줌
- 우리는 그래서 그 위치에 "semantic material label"과 함께 "physical parameter"를 같이 할당함
  
1.  2D image 로부터 물성 바로 알기 쉽지않음, 따라서 우리는 **"distilled feature field"**를 활용해서 더 많은 visual prior를 표현할 수 있게 했음
2.  또한 3D visual feature와 physical material사이의 매핑을 계산하기 위해 **U-Net 아키텍처를 분리**했음


### 3D Visual Feature Distilaltion


